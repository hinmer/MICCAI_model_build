{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e985b5-f732-458d-b4a6-e067e71f719c",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae0d9f4-76a2-4e57-a46a-1c6ee41aa28b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import gc\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from functools import lru_cache\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import timm\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.distributed as dist\n",
    "from torch import nn, einsum\n",
    "from torch.nn import functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "from typing import Iterable, Optional\n",
    "from timm.models import create_model\n",
    "from timm.optim import create_optimizer\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.data import Mixup,create_transform\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.utils import accuracy, ModelEma,NativeScaler, get_state_dict, ModelEma\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader\n",
    "\n",
    "from functools import partial\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8a818-fb98-4311-b3dd-28d899a3a0b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# modle build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd7fb3-7d29-44ff-b266-4c56d4b495df",
   "metadata": {},
   "source": [
    "## device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4423620c-f6aa-41e4-9a05-9985d3aeb580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420eff9-d270-4191-8b29-cc82f266a195",
   "metadata": {},
   "source": [
    "## cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b440ef09-2e00-4494-9f3e-8f8aa30c946b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Next-ViT training and evaluation script', add_help=False)\n",
    "    parser.add_argument('--batch-size', default=16, type=int)\n",
    "    parser.add_argument('--epochs', default=300, type=int)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--model', default='pvt_small', type=str, metavar='MODEL',\n",
    "                        help='Name of model to train')\n",
    "    parser.add_argument('--input-Hsize', default=1280, type=int, help='images input size')\n",
    "    parser.add_argument('--input-Wsize', default=640, type=int, help='images input size')\n",
    "    parser.add_argument('--drop', type=float, default=0.0, metavar='PCT',\n",
    "                        help='Dropout rate (default: 0.)')\n",
    "    parser.add_argument('--drop-path', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "    parser.add_argument('--flops', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--opt', default='adamw', type=str, metavar='OPTIMIZER',\n",
    "                        help='Optimizer (default: \"adamw\"')\n",
    "    parser.add_argument('--opt-eps', default=1e-8, type=float, metavar='EPSILON',\n",
    "                        help='Optimizer Epsilon (default: 1e-8)')\n",
    "    parser.add_argument('--opt-betas', default=None, type=float, nargs='+', metavar='BETA',\n",
    "                        help='Optimizer Betas (default: None, use opt default)')\n",
    "    parser.add_argument('--clip-grad', type=float, default=5, metavar='NORM',\n",
    "                        help='Clip gradient norm (default: None, no clipping)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                        help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--weight-decay', type=float, default=0.05,\n",
    "                        help='weight decay (default: 0.05)')\n",
    "    # Learning rate schedule parameters\n",
    "    parser.add_argument('--sched', default='sched', type=str, metavar='SCHEDULER',\n",
    "                        help='LR scheduler (default: \"cosine\"')\n",
    "    parser.add_argument('--lr', type=float, default=5e-6, metavar='LR',\n",
    "                        help='learning rate (default: 5e-4)')\n",
    "    parser.add_argument('--lr-noise', type=float, nargs='+', default=None, metavar='pct, pct',\n",
    "                        help='learning rate noise on/off epoch percentages')\n",
    "    parser.add_argument('--lr-noise-pct', type=float, default=0.67, metavar='PERCENT',\n",
    "                        help='learning rate noise limit percent (default: 0.67)')\n",
    "    parser.add_argument('--lr-noise-std', type=float, default=1.0, metavar='STDDEV',\n",
    "                        help='learning rate noise std-dev (default: 1.0)')\n",
    "    parser.add_argument('--warmup-lr', type=float, default=1e-6, metavar='LR',\n",
    "                        help='warmup learning rate (default: 1e-6)')\n",
    "    parser.add_argument('--min-lr', type=float, default=1e-5, metavar='LR',\n",
    "                        help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')\n",
    "\n",
    "    parser.add_argument('--decay-epochs', type=float, default=40, metavar='N',\n",
    "                        help='epoch interval to decay LR')\n",
    "    parser.add_argument('--warmup-epochs', type=int, default=10, metavar='N',\n",
    "                        help='epochs to warmup LR, if scheduler supports')\n",
    "    parser.add_argument('--cooldown-epochs', type=int, default=10, metavar='N',\n",
    "                        help='epochs to cooldown LR at min_lr, after cyclic schedule ends')\n",
    "    parser.add_argument('--patience-epochs', type=int, default=10, metavar='N',\n",
    "                        help='patience epochs for Plateau LR scheduler (default: 10')\n",
    "    parser.add_argument('--decay-rate', '--dr', type=float, default=0.1, metavar='RATE',\n",
    "                        help='LR decay rate (default: 0.1)')\n",
    "\n",
    "    # Augmentation parameters\n",
    "    parser.add_argument('--color-jitter', type=float, default=0.4, metavar='PCT',\n",
    "                        help='Color jitter factor (default: 0.4)')\n",
    "    parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                        help='Use AutoAugment policy. \"v0\" or \"original\". \" + \\\n",
    "                             \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "    parser.add_argument('--smoothing', type=float, default=0.1, help='Label smoothing (default: 0.1)')\n",
    "    parser.add_argument('--train-interpolation', type=str, default='bicubic',\n",
    "                        help='Training interpolation (random, bilinear, bicubic default: \"bicubic\")')\n",
    "\n",
    "    parser.add_argument('--repeated-aug', action='store_true')\n",
    "    parser.add_argument('--no-repeated-aug', action='store_false', dest='repeated_aug')\n",
    "    parser.set_defaults(repeated_aug=False)\n",
    "\n",
    "    # * Random Erase params\n",
    "    parser.add_argument('--reprob', type=float, default=0.25, metavar='PCT',\n",
    "                        help='Random erase prob (default: 0.25)')\n",
    "    parser.add_argument('--remode', type=str, default='pixel',\n",
    "                        help='Random erase mode (default: \"pixel\")')\n",
    "    parser.add_argument('--recount', type=int, default=1,\n",
    "                        help='Random erase count (default: 1)')\n",
    "    parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                        help='Do not random erase first (clean) augmentation split')\n",
    "\n",
    "    # * Mixup params\n",
    "    parser.add_argument('--mixup', type=float, default=0.8,\n",
    "                        help='mixup alpha, mixup enabled if > 0. (default: 0.8)')\n",
    "    parser.add_argument('--cutmix', type=float, default=1.0,\n",
    "                        help='cutmix alpha, cutmix enabled if > 0. (default: 1.0)')\n",
    "    parser.add_argument('--cutmix-minmax', type=float, nargs='+', default=None,\n",
    "                        help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "    parser.add_argument('--mixup-prob', type=float, default=1.0,\n",
    "                        help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "    parser.add_argument('--mixup-switch-prob', type=float, default=0.5,\n",
    "                        help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "    parser.add_argument('--mixup-mode', type=str, default='batch',\n",
    "                        help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "\n",
    "    # * Finetuning params\n",
    "    parser.add_argument('--finetune', action='store_true', help='Perform finetune.')\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--data-path', default='../../datasets/imagenet_full_size/061417/', type=str,\n",
    "                        help='dataset path')\n",
    "    parser.add_argument('--data-set', default='IMNET', choices=['CIFAR', 'IMNET', 'INAT', 'INAT19'],\n",
    "                        type=str, help='Image Net dataset path')\n",
    "    parser.add_argument('--use-mcloader', action='store_true', default=False, help='Use mcloader')\n",
    "    parser.add_argument('--inat-category', default='name',\n",
    "                        choices=['kingdom', 'phylum', 'class', 'order', 'supercategory', 'family', 'genus', 'name'],\n",
    "                        type=str, help='semantic granularity')\n",
    "\n",
    "    parser.add_argument('--output-dir', default='../../outputdir',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--resume', default='./nextvit_small_in1k6m_384.pth', help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
    "    parser.add_argument('--dist-eval', action='store_true', default=False, help='Enabling distributed evaluation')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--pin-mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.add_argument('--no-pin-mem', action='store_false', dest='pin_mem',\n",
    "                        help='')\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')\n",
    "\n",
    "    # test throught\n",
    "    parser.add_argument('--throughout', action='store_true', help='Perform throughout only')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753174d-0754-4dc9-aeb3-e1f2aede0388",
   "metadata": {},
   "source": [
    "## Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3bfd000-89ca-4e08-a5df-327da9c12b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Backbone, self).__init__()\n",
    "        self.register_buffer('mean', torch.FloatTensor([0.5, 0.5, 0.5]).reshape(1,3,1,1))\n",
    "        self.register_buffer('std',  torch.FloatTensor([0.5, 0.5, 0.5]).reshape(1,3,1,1))\n",
    "        self.encoder = timm.create_model ('efficientnetv2_m',pretrained=False, drop_rate = 0.2, drop_path_rate = 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features=[]\n",
    "        def hook(module, input, output):\n",
    "            features.append(input)\n",
    "            return None\n",
    "        x = (x - self.mean) / self.std\n",
    "        self.encoder.blocks[4].register_forward_hook(hook)\n",
    "        self.encoder.blocks[5].register_forward_hook(hook)\n",
    "        self.encoder.blocks[6].register_forward_hook(hook)\n",
    "        x = self.encoder.forward_features(x)\n",
    "        return x,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f0a88e-17e0-452e-a2cf-121bc747dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Backbone().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55036526-d19a-47b4-97c3-5b456f1dde1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 1024, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_m = np.random.random(size=(4, 3, 1024, 512))\n",
    "# i_a = np.random.random(size=(1, 160, 32, 16))\n",
    "i_m = torch.tensor(i_m).to(device).to(torch.float32)\n",
    "# i_a = torch.tensor(i_a).to(device).to(torch.float32)\n",
    "i_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9d382dd-414f-4b43-841e-5cbc9f4fa993",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = net(i_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b8bf1a1-400a-400e-8d56-c81f1cfcc2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1280, 32, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84bbdd67-326a-425a-914a-d4c81b58d497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 160, 64, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae8ed763-abf5-4e37-ba96-6a532eb48e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 176, 64, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ab7f83b-7656-42c1-8d82-662a64b80695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 304, 32, 16])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bb6357-5ec8-4f97-b6fe-a0b162e6353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalConsistency(nn.Module):\n",
    "    def __init__(self,dim):\n",
    "        super(GlobalConsistency, self).__init__()\n",
    "        self.pj = nn.Linear(dim,128)\n",
    "        self.project = nn.Linear(dim,dim) #<todo> try mlp?\n",
    "\n",
    "    def forward(self, u_m, u_a):\n",
    "        B, C, H, W = u_m.shape\n",
    "\n",
    "        g_m = F.adaptive_max_pool2d(u_m,1)\n",
    "        g_a = F.adaptive_max_pool2d(u_a,1)\n",
    "        g_m = torch.flatten(g_m, 1)\n",
    "        g_a = torch.flatten(g_a, 1)\n",
    "        pj_m = self.pj(g_m)\n",
    "        pj_a = self.pj(g_a)\n",
    "        p_a = self.project(g_m)\n",
    "        p_m = self.project(g_a)\n",
    "\n",
    "        return g_a, p_a ,pj_m,pj_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e14231b-3950-484f-88f4-e1ffff0e5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_MHCA(nn.Module):\n",
    "    \"\"\"\n",
    "    Efficient Multi-Head Cross Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, out_dim=None, head_dim=16, #随着H*W变化 16/32\n",
    "                 qkv_bias=True, qk_scale=None,\n",
    "                 attn_drop=0, proj_drop=0., sr_ratio=1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.out_dim = out_dim if out_dim is not None else dim\n",
    "        self.num_heads = self.dim // head_dim\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.q_m = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.k_m = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.v_m = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.proj_m = nn.Linear(self.dim, self.out_dim)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.q_a = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.k_a = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.v_a = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.proj_a = nn.Linear(self.dim, self.out_dim)\n",
    "        \n",
    "\n",
    "        self.sr_ratio = sr_ratio\n",
    "        self.N_ratio = sr_ratio ** 2\n",
    "        if sr_ratio > 1:\n",
    "            self.sr = nn.AvgPool1d(kernel_size=self.N_ratio, stride=self.N_ratio)\n",
    "            self.norm = nn.BatchNorm1d(dim, eps=NORM_EPS)\n",
    "        self.is_bn_merged = False\n",
    "\n",
    "    def merge_bn(self, pre_bn):\n",
    "        merge_pre_bn(self.q, pre_bn)\n",
    "        if self.sr_ratio > 1:\n",
    "            merge_pre_bn(self.k, pre_bn, self.norm)\n",
    "            merge_pre_bn(self.v, pre_bn, self.norm)\n",
    "        else:\n",
    "            merge_pre_bn(self.k, pre_bn)\n",
    "            merge_pre_bn(self.v, pre_bn)\n",
    "        self.is_bn_merged = True\n",
    "\n",
    "    def forward(self, x_mh,x_ah,x_mv,x_av):\n",
    "        B, N, C = x_m.shape\n",
    "        # B, N, C = x_a.shape\n",
    "        q_m = self.q_m(x_m)\n",
    "        q_m = q_m.reshape(B, N, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "        v_m = self.v_m(x_m)\n",
    "        v_m = v_m.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "        k_m = self.k_m(x_m)\n",
    "        k_m = k_m.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 3, 1)\n",
    "        \n",
    "        q_a = self.q_a(x_a)\n",
    "        q_a = q_a.reshape(B, N, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "\n",
    "        k_a = self.k_a(x_a)\n",
    "        k_a = k_a.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 3, 1)\n",
    "        v_a = self.v_a(x_a)\n",
    "        v_a = v_a.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "        print(q_m.shape)\n",
    "        print(k_a.shape)\n",
    "        attn_m = (q_m @ k_a.transpose(-2, -1)) * self.scale\n",
    "        attn_m = attn_m.softmax(dim=-1)\n",
    "        attn_m = self.attn_drop(attn_m)\n",
    "\n",
    "        attn_a = (q_a @ k_m.transpose(-2, -1)) * self.scale\n",
    "        attn_a = attn_a.softmax(dim=-1)\n",
    "        attn_a = self.attn_drop(attn_a)\n",
    "\n",
    "\n",
    "        x_m = (attn_m @ v_m).transpose(1, 2).reshape(B, N, C)\n",
    "        x_m = self.proj_m(x_m)\n",
    "        x_m = self.proj_drop(x_m)\n",
    "\n",
    "        x_a = (attn_a @ v_a).transpose(1, 2).reshape(B, N, C)\n",
    "        x_a = self.proj_a(x_a)\n",
    "        x_a = self.proj_drop(x_a)\n",
    "        return x_m, x_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7cd0dfa-fd48-42a2-8bf5-74d77220808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = E_MHCA(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0cc71b2-b531-45ea-ba08-d860e064aad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.random(size=(1, 16, 32))\n",
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e117a234-b00c-4037-a437-3fd117c8ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "# i.to(device)\n",
    "i = torch.tensor( i).to(device).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd0fdca-601f-466e-abe8-f659af24e6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 16, 16])\n",
      "torch.Size([1, 2, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "x,x2 = net(i,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "902c6e51-5596-47c7-9fd9-b5ac7e142def",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1570, -0.5715,  0.3364, -0.1431,  0.1250,  0.2233, -0.0127,\n",
       "          -0.1961, -0.0727, -0.2810,  0.1704,  0.2176, -0.2890,  0.0097,\n",
       "           0.1279,  0.0951,  0.2664,  0.1611,  0.2087,  0.3318, -0.2636,\n",
       "          -0.5694,  0.0494,  0.2268,  0.2702, -0.3870, -0.3487, -0.1708,\n",
       "          -0.5044,  0.0967,  0.0758, -0.0313],\n",
       "         [ 0.1592, -0.5733,  0.3386, -0.1478,  0.1278,  0.2261, -0.0143,\n",
       "          -0.1968, -0.0744, -0.2779,  0.1693,  0.2218, -0.2902,  0.0081,\n",
       "           0.1221,  0.0972,  0.2655,  0.1604,  0.2053,  0.3373, -0.2614,\n",
       "          -0.5762,  0.0426,  0.2278,  0.2748, -0.3941, -0.3523, -0.1711,\n",
       "          -0.5060,  0.0976,  0.0757, -0.0317],\n",
       "         [ 0.1563, -0.5721,  0.3366, -0.1450,  0.1259,  0.2239, -0.0133,\n",
       "          -0.1956, -0.0734, -0.2794,  0.1695,  0.2178, -0.2899,  0.0089,\n",
       "           0.1261,  0.0960,  0.2657,  0.1607,  0.2074,  0.3338, -0.2628,\n",
       "          -0.5711,  0.0475,  0.2278,  0.2720, -0.3891, -0.3494, -0.1713,\n",
       "          -0.5044,  0.0979,  0.0759, -0.0308],\n",
       "         [ 0.1548, -0.5750,  0.3364, -0.1465,  0.1279,  0.2241, -0.0143,\n",
       "          -0.1942, -0.0743, -0.2788,  0.1697,  0.2189, -0.2927,  0.0080,\n",
       "           0.1245,  0.0976,  0.2658,  0.1593,  0.2052,  0.3387, -0.2604,\n",
       "          -0.5742,  0.0452,  0.2270,  0.2749, -0.3941, -0.3494, -0.1737,\n",
       "          -0.5011,  0.0998,  0.0743, -0.0308],\n",
       "         [ 0.1569, -0.5687,  0.3363, -0.1416,  0.1230,  0.2231, -0.0129,\n",
       "          -0.1957, -0.0716, -0.2821,  0.1699,  0.2180, -0.2884,  0.0099,\n",
       "           0.1281,  0.0933,  0.2667,  0.1619,  0.2097,  0.3290, -0.2646,\n",
       "          -0.5676,  0.0505,  0.2270,  0.2690, -0.3847, -0.3481, -0.1706,\n",
       "          -0.5068,  0.0952,  0.0763, -0.0308],\n",
       "         [ 0.1582, -0.5705,  0.3370, -0.1430,  0.1253,  0.2239, -0.0134,\n",
       "          -0.1966, -0.0738, -0.2810,  0.1699,  0.2185, -0.2884,  0.0094,\n",
       "           0.1276,  0.0948,  0.2665,  0.1608,  0.2091,  0.3313, -0.2643,\n",
       "          -0.5698,  0.0484,  0.2272,  0.2702, -0.3870, -0.3494, -0.1703,\n",
       "          -0.5057,  0.0956,  0.0763, -0.0309],\n",
       "         [ 0.1574, -0.5719,  0.3369, -0.1440,  0.1263,  0.2239, -0.0129,\n",
       "          -0.1963, -0.0730, -0.2803,  0.1698,  0.2185, -0.2886,  0.0090,\n",
       "           0.1259,  0.0955,  0.2660,  0.1608,  0.2081,  0.3332, -0.2629,\n",
       "          -0.5704,  0.0468,  0.2275,  0.2716, -0.3888, -0.3492, -0.1705,\n",
       "          -0.5042,  0.0970,  0.0759, -0.0311],\n",
       "         [ 0.1548, -0.5721,  0.3360, -0.1441,  0.1266,  0.2225, -0.0116,\n",
       "          -0.1953, -0.0734, -0.2809,  0.1700,  0.2169, -0.2906,  0.0085,\n",
       "           0.1273,  0.0957,  0.2657,  0.1602,  0.2095,  0.3324, -0.2630,\n",
       "          -0.5680,  0.0498,  0.2278,  0.2714, -0.3862, -0.3481, -0.1721,\n",
       "          -0.5025,  0.0978,  0.0759, -0.0309],\n",
       "         [ 0.1555, -0.5729,  0.3367, -0.1458,  0.1277,  0.2242, -0.0135,\n",
       "          -0.1949, -0.0750, -0.2805,  0.1696,  0.2197, -0.2923,  0.0071,\n",
       "           0.1250,  0.0970,  0.2654,  0.1596,  0.2073,  0.3356, -0.2616,\n",
       "          -0.5721,  0.0460,  0.2272,  0.2739, -0.3906, -0.3497, -0.1731,\n",
       "          -0.5028,  0.0979,  0.0756, -0.0306],\n",
       "         [ 0.1576, -0.5730,  0.3378, -0.1464,  0.1280,  0.2246, -0.0145,\n",
       "          -0.1959, -0.0743, -0.2793,  0.1696,  0.2204, -0.2919,  0.0076,\n",
       "           0.1236,  0.0973,  0.2653,  0.1594,  0.2061,  0.3368, -0.2611,\n",
       "          -0.5738,  0.0438,  0.2269,  0.2747, -0.3933, -0.3508, -0.1728,\n",
       "          -0.5033,  0.0980,  0.0752, -0.0313],\n",
       "         [ 0.1586, -0.5713,  0.3375, -0.1448,  0.1266,  0.2249, -0.0134,\n",
       "          -0.1970, -0.0742, -0.2797,  0.1695,  0.2196, -0.2885,  0.0087,\n",
       "           0.1252,  0.0954,  0.2661,  0.1607,  0.2086,  0.3328, -0.2636,\n",
       "          -0.5715,  0.0463,  0.2280,  0.2719, -0.3888, -0.3504, -0.1701,\n",
       "          -0.5065,  0.0960,  0.0764, -0.0310],\n",
       "         [ 0.1540, -0.5723,  0.3352, -0.1432,  0.1248,  0.2226, -0.0119,\n",
       "          -0.1943, -0.0720, -0.2815,  0.1709,  0.2166, -0.2912,  0.0090,\n",
       "           0.1286,  0.0947,  0.2663,  0.1608,  0.2090,  0.3325, -0.2624,\n",
       "          -0.5676,  0.0512,  0.2270,  0.2710, -0.3869, -0.3469, -0.1731,\n",
       "          -0.5019,  0.0977,  0.0749, -0.0308],\n",
       "         [ 0.1566, -0.5722,  0.3365, -0.1451,  0.1261,  0.2238, -0.0130,\n",
       "          -0.1961, -0.0732, -0.2797,  0.1703,  0.2181, -0.2901,  0.0091,\n",
       "           0.1262,  0.0958,  0.2659,  0.1604,  0.2078,  0.3340, -0.2623,\n",
       "          -0.5706,  0.0481,  0.2271,  0.2716, -0.3890, -0.3489, -0.1717,\n",
       "          -0.5038,  0.0978,  0.0758, -0.0313],\n",
       "         [ 0.1553, -0.5706,  0.3355, -0.1422,  0.1246,  0.2221, -0.0114,\n",
       "          -0.1949, -0.0724, -0.2824,  0.1707,  0.2171, -0.2901,  0.0090,\n",
       "           0.1285,  0.0942,  0.2663,  0.1608,  0.2103,  0.3305, -0.2637,\n",
       "          -0.5668,  0.0513,  0.2269,  0.2703, -0.3850, -0.3472, -0.1722,\n",
       "          -0.5035,  0.0964,  0.0755, -0.0309],\n",
       "         [ 0.1555, -0.5748,  0.3362, -0.1471,  0.1277,  0.2237, -0.0146,\n",
       "          -0.1950, -0.0754, -0.2784,  0.1704,  0.2190, -0.2941,  0.0082,\n",
       "           0.1253,  0.0982,  0.2658,  0.1586,  0.2048,  0.3390, -0.2605,\n",
       "          -0.5749,  0.0462,  0.2259,  0.2749, -0.3939, -0.3498, -0.1748,\n",
       "          -0.5007,  0.0996,  0.0743, -0.0313],\n",
       "         [ 0.1572, -0.5720,  0.3365, -0.1447,  0.1263,  0.2239, -0.0131,\n",
       "          -0.1967, -0.0747, -0.2797,  0.1705,  0.2178, -0.2895,  0.0094,\n",
       "           0.1271,  0.0958,  0.2661,  0.1604,  0.2084,  0.3332, -0.2635,\n",
       "          -0.5712,  0.0490,  0.2270,  0.2708, -0.3879, -0.3496, -0.1708,\n",
       "          -0.5048,  0.0971,  0.0762, -0.0311]]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aad1ea-8ecf-4d9e-b26f-14976b8dbd0a",
   "metadata": {},
   "source": [
    "### torch.Size([1, 160, 64, 32])\n",
    "### torch.Size([1, 176, 64, 32])\n",
    "### torch.Size([1, 304, 32, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "773eb695-6cbe-4f93-9ef5-7f4485781517",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORM_EPS = 1e-5\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride=1,\n",
    "                 mode = \"V\"\n",
    "                ):\n",
    "        super(PatchEmbed, self).__init__()\n",
    "        norm_layer = partial(nn.BatchNorm2d, eps=NORM_EPS)\n",
    "        if stride == 4 and mode == \"V\":\n",
    "            self.avgpool = nn.AvgPool2d((4, 32), stride=4, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif stride == 2 and mode == \"V\":\n",
    "            self.avgpool = nn.AvgPool2d((2, 16), stride=2, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif stride == 2 and mode == \"H\":\n",
    "            self.avgpool = nn.AvgPool2d((64, 2), stride=2, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif stride == 1 and mode == \"H\":\n",
    "            self.avgpool = nn.AvgPool2d((32, 1), stride=1, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif in_channels != out_channels:\n",
    "            self.avgpool = nn.Identity()\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        else:\n",
    "            self.avgpool = nn.Identity()\n",
    "            self.conv = nn.Identity()\n",
    "            self.norm = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.norm(self.conv(self.avgpool(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "88a4c24a-5f35-4c41-a4de-45b0cb528a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PatchEmbed(160,32,1,\"H\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "72e50444-9bad-4f82-beee-7c46939e4906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 160, 32, 16])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.random(size=(1, 160, 32, 16))\n",
    "i = torch.tensor( i).to(device).to(torch.float32)\n",
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5f6053f8-c06a-4ba9-9661-bb183eda347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pe(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "874667ad-13d8-48d1-a652-23d2f3c216e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 1, 16])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73cf494-c9fb-4a2f-9c82-ab253f129379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShardExamine(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim,\n",
    "                 num_head=8, \n",
    "                 qkv_bias=False, \n",
    "                 attn_drop=0., \n",
    "                 proj_drop=0.,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride=1\n",
    "                ):\n",
    "        super(LocalCoccurrence, self).__init__()\n",
    "        self.PEV = PatchEmbed(in_channels,out_channels,stride*2,mode = \"V\")\n",
    "        self.PEH = PatchEmbed(in_channels,out_channels,stride,mode = \"H\")\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn  = CrossAttention(dim, num_head, qkv_bias, attn_drop, proj_drop)\n",
    "\n",
    "    def forward(self, u_m, u_a):\n",
    "        u_mv = self.PEV(u_m)\n",
    "        u_av = self.PEV(u_a)\n",
    "        u_m = self.PEH(u_m)\n",
    "        u_a = self.PEH(u_a)\n",
    "        B,C,H,W = u_mv.shape\n",
    "        L = H*W\n",
    "        dim = C\n",
    "\n",
    "        u_mv = u_mv.reshape(B,dim,L).permute(0,2,1)\n",
    "        u_av = u_av.reshape(B,dim,L).permute(0,2,1)\n",
    "        u_m = u_m.reshape(B,dim,L).permute(0,2,1)\n",
    "        u_a = u_a.reshape(B,dim,L).permute(0,2,1)\n",
    "\n",
    "        u_mv = self.norm1(u_mv)\n",
    "        u_av = self.norm1(u_av)\n",
    "        u_m = self.norm1(u_m)\n",
    "        u_a = self.norm1(u_a)\n",
    "        x_m, x_a = self.attn(x_m, x_a)\n",
    "        x_mv, x_av = self.attn(x_mv, x_a)\n",
    "        gap_m = x_m.mean(1)\n",
    "        gap_a = x_a.mean(1)\n",
    "        return gap_m, gap_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f499a1-d4f7-4e9a-8d6f-903b1e395c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCN(nn.Module)\n",
    "\"\"\"\n",
    "Shard Contrastive Net\n",
    "\"\"\"\n",
    "    def load_pretrain(self, ):\n",
    "        return\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(Net, self).__init__()\n",
    "        self.output_type = ['inference', 'loss']\n",
    "\n",
    "\n",
    "        self.backbone = Backbone()\n",
    "        dim = 1280\n",
    "\n",
    "        self.lc  = LocalCoccurrence(dim)\n",
    "        self.gl  = GlobalConsistency(dim)\n",
    "        self.ape = \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(dim*3),\n",
    "            nn.Linear(dim*3, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )#<todo> mlp needs to be deep if backbone is strong?\n",
    "        self.cancer = nn.Linear(dim,1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch['image']\n",
    "        batch_size,num_view,C,H,W = x.shape\n",
    "        x = x.reshape(-1, C, H, W)\n",
    "\n",
    "        u = self.backbone(x)\n",
    "        _,c,h,w = u.shape\n",
    "\n",
    "        u = u.reshape(batch_size,num_view,c,h,w)\n",
    "        u_m = u[:,0]\n",
    "        u_a = u[:,1]\n",
    "        gap_m, gap_a = self.lc(u_m, u_a)\n",
    "\n",
    "        g_m, p_m, g_a, p_a = self.gl(u_m, u_a)\n",
    "        gp_m = g_m + p_m\n",
    "\n",
    "        last = torch.cat([gp_m, gap_m, gap_a ],-1)\n",
    "        last = self.mlp(last)\n",
    "        cancer = self.cancer(last).reshape(-1)\n",
    "\n",
    "\n",
    "        output = {}\n",
    "        if  'loss' in self.output_type:\n",
    "            output['cancer_loss'] = F.binary_cross_entropy_with_logits(cancer, batch['cancer'])\n",
    "            output['global_loss'] = criterion_global_consistency(g_m, p_m, g_a, p_a)\n",
    "\n",
    "\n",
    "        if 'inference' in self.output_type:\n",
    "            output['cancer'] = torch.sigmoid(cancer)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33556e9c-f83e-4faf-a79e-58e9eced3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basNet(nn.Module):\n",
    "    \"\"\"\n",
    "    only two viwe\n",
    "    \"\"\"\n",
    "    def load_pretrain(self, ):\n",
    "        return\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(basNet, self).__init__()\n",
    "        # self.output_type = ['inference', 'loss']\n",
    "\n",
    "\n",
    "        self.backbone =timm.create_model ('efficientnetv2_m',\n",
    "                                          pretrained=False, \n",
    "                                          drop_rate = 0.2, \n",
    "                                          drop_path_rate = 0.1,\n",
    "                                          num_classes=512\n",
    "                                         )\n",
    "\n",
    "        # dim = 1280\n",
    "\n",
    "        # self.lc  = LocalCoccurrence(dim)\n",
    "        # self.gl  = GlobalConsistency(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 128),\n",
    "        )#<todo> mlp needs to be deep if backbone is strong?\n",
    "        self.cancer = nn.Linear(128,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = batch['image']\n",
    "        batch_size,C,H,W = x.shape\n",
    "        x = x.reshape(-1, C, H, W)\n",
    "        x_m =torch.tensor( np.array_split(batch,2,axis=3)[0])\n",
    "\n",
    "        # print(x_m.shape)\n",
    "        x_a = torch.tensor( np.array_split(batch,2,axis=3)[1])\n",
    "        x_m = self.backbone(x_m)\n",
    "        x_a = self.backbone(x_a)\n",
    "        last = torch.cat([x_m, x_a ],-1)\n",
    "        last = self.mlp(last)\n",
    "        cancer = self.cancer(last).reshape(-1)\n",
    "\n",
    "        return torch.sigmoid(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96798ea6-ce15-4807-b216-a6fbe20fc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = np.random.random(size=(1,3,1024,1024))\n",
    "batch = torch.tensor( batch).to(device).to(torch.float32)\n",
    "batch_size,C,H,W = batch.shape\n",
    "x = batch.reshape(-1, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0689feae-bf83-47fe-9529-919dd5913cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1024, 1024])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e0a3ec-a4c6-42d7-b5b1-b0f041dc17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0cd4aa6-c0e3-4bdc-96f1-6a3997fcdf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27919/2473585480.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_m =torch.tensor( np.array_split(batch,2,axis=3)[0])\n",
      "/tmp/ipykernel_27919/2473585480.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_a = torch.tensor( np.array_split(batch,2,axis=3)[1])\n"
     ]
    }
   ],
   "source": [
    "x = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36498aed-210f-426b-80d5-c4626d650606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a21fe7-a184-4b77-a09f-8bf254c3b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Backbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cda33cf8-c0f8-47bd-98c6-048f49744ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = np.random.random(size=(8,3,256,256))\n",
    "batch = torch.tensor( batch).to(device).to(torch.float32)\n",
    "batch_size,C,H,W = batch.shape\n",
    "x = batch.reshape(-1, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "586ec2db-9a99-48bc-911d-7516ee807778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 256, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efb391c8-27dd-47be-993a-77e3022b96b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1280, 8, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.to(device)\n",
    "x = m(x)\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373e8ff-4155-4059-af64-a0a7634e3374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
