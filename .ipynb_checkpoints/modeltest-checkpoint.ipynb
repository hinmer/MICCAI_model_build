{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc295f11-2b82-49d0-9a7e-df9237087cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import gc\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from functools import lru_cache\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import timm\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch import nn, einsum\n",
    "from torch.nn import functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "from typing import Iterable, Optional\n",
    "from timm.models import create_model\n",
    "from timm.optim import create_optimizer\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.data import Mixup,create_transform\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.utils import accuracy, ModelEma,NativeScaler, get_state_dict, ModelEma\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader\n",
    "\n",
    "from functools import partial\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b89aa8-6031-4d18-9fb0-c2bef4c028c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e11a302-260f-4177-82ec-046a29fde4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similiarity(x1,x2):\n",
    "\tp12 = (x1*x2).sum(-1)\n",
    "\tp1 = torch.sqrt((x1*x1).sum(-1))\n",
    "\tp2 = torch.sqrt((x2*x2).sum(-1))\n",
    "\ts = p12/(p1*p2+1e-6)\n",
    "\treturn s\n",
    "\n",
    "\n",
    "def criterion_global_consistency(g_m, p_m, g_a, p_a):\n",
    "\tloss =  -0.5*(similiarity(g_m, p_m)+similiarity(g_a, p_a))\n",
    "\tloss = loss.mean()\n",
    "\treturn loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d3bd3e6-867f-4f50-a65f-23864f3f9089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "\tdef __init__(self, ):\n",
    "\t\tsuper(Backbone, self).__init__()\n",
    "\t\tself.register_buffer('mean', torch.FloatTensor([0.5, 0.5, 0.5]).reshape(1,3,1,1))\n",
    "\t\tself.register_buffer('std',  torch.FloatTensor([0.5, 0.5, 0.5]).reshape(1,3,1,1))\n",
    "\t\tself.encoder = timm.create_model ('efficientnet_b4',pretrained=False, drop_rate = 0.2, drop_path_rate = 0.1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = (x - self.mean) / self.std\n",
    "\t\tx = self.encoder.forward_features(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3d75a-5fb8-4560-8e8a-0098d9bcf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_MHSA(nn.Module):\n",
    "    \"\"\"\n",
    "    Efficient Multi-Head Self Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, out_dim=None, head_dim=32, qkv_bias=True, qk_scale=None,\n",
    "                 attn_drop=0, proj_drop=0., sr_ratio=1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.out_dim = out_dim if out_dim is not None else dim\n",
    "        self.num_heads = self.dim // head_dim\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.q = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.k = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.v = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(self.dim, self.out_dim)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        self.sr_ratio = sr_ratio\n",
    "        self.N_ratio = sr_ratio ** 2\n",
    "        if sr_ratio > 1:\n",
    "            self.sr = nn.AvgPool1d(kernel_size=self.N_ratio, stride=self.N_ratio)\n",
    "            self.norm = nn.BatchNorm1d(dim, eps=NORM_EPS)\n",
    "        self.is_bn_merged = False\n",
    "\n",
    "    def merge_bn(self, pre_bn):\n",
    "        merge_pre_bn(self.q, pre_bn)\n",
    "        if self.sr_ratio > 1:\n",
    "            merge_pre_bn(self.k, pre_bn, self.norm)\n",
    "            merge_pre_bn(self.v, pre_bn, self.norm)\n",
    "        else:\n",
    "            merge_pre_bn(self.k, pre_bn)\n",
    "            merge_pre_bn(self.v, pre_bn)\n",
    "        self.is_bn_merged = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        q = self.q(x)\n",
    "        q = q.reshape(B, N, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "\n",
    "        if self.sr_ratio > 1:\n",
    "            x_ = x.transpose(1, 2)\n",
    "            x_ = self.sr(x_)\n",
    "            if not torch.onnx.is_in_onnx_export() and not self.is_bn_merged:\n",
    "                x_ = self.norm(x_)\n",
    "            x_ = x_.transpose(1, 2)\n",
    "            k = self.k(x_)\n",
    "            k = k.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 3, 1)\n",
    "            v = self.v(x_)\n",
    "            v = v.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "        else:\n",
    "            k = self.k(x)\n",
    "            k = k.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 3, 1)\n",
    "            v = self.v(x)\n",
    "            v = v.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "        attn = (q @ k) * self.scale\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9d79c5-e1c1-4c84-bd10-f9374dc5f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalConsistency(nn.Module):\n",
    "\tdef __init__(self,dim):\n",
    "\t\tsuper(GlobalConsistency, self).__init__()\n",
    "\n",
    "\t\tself.project = nn.Linear(dim,dim) #<todo> try mlp?\n",
    "\n",
    "\tdef forward(self, u_m, u_a):\n",
    "\t\tB, C, H, W = u_m.shape\n",
    "\n",
    "\t\tg_m = F.adaptive_max_pool2d(u_m,1)\n",
    "\t\tg_a = F.adaptive_max_pool2d(u_a,1)\n",
    "\t\tg_m = torch.flatten(g_m, 1)\n",
    "\t\tg_a = torch.flatten(g_a, 1)\n",
    "\n",
    "\t\tp_a = self.project(g_m)\n",
    "\t\tp_m = self.project(g_a)\n",
    "\n",
    "\t\treturn g_m, p_m, g_a, p_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f486c95-28f6-47de-93dc-766d1295df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "\tdef __init__(self, dim, num_head=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
    "\t\tsuper(CrossAttention, self).__init__()\n",
    "\n",
    "\t\tassert dim % num_head == 0, 'dim should be divisible by num_heads'\n",
    "\t\tself.num_head = num_head\n",
    "\t\thead_dim = dim // num_head\n",
    "\t\tself.scale = head_dim ** (-0.5)\n",
    "\n",
    "\t\tself.qkv_a = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "\t\tself.qkv_m = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "\t\tself.proj_a = nn.Linear(dim, dim)\n",
    "\t\tself.proj_m = nn.Linear(dim, dim)\n",
    "\n",
    "\t\tself.attn_drop = nn.Dropout(attn_drop)\n",
    "\t\tself.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "\tdef forward(self, u_m, u_a):\n",
    "\t\tB,L,dim = u_m.shape\n",
    "\n",
    "\t\tqkv_m = self.qkv_m(u_m)\n",
    "\t\tqkv_m = qkv_m.reshape(B, L, 3, self.num_head, dim // self.num_head).permute(2, 0, 3, 1, 4)\n",
    "\t\tq_m, k_m, v_m = qkv_m.unbind(0)\n",
    "\n",
    "\t\tqkv_a = self.qkv_m(u_a)\n",
    "\t\tqkv_a = qkv_a.reshape(B, L, 3, self.num_head, dim // self.num_head).permute(2, 0, 3, 1, 4)\n",
    "\t\tq_a, k_a, v_a = qkv_a.unbind(0)\n",
    "\n",
    "\t\tattn_m = (q_m @ k_a.transpose(-2, -1)) * self.scale\n",
    "\t\tattn_m = attn_m.softmax(dim=-1)\n",
    "\t\tattn_m = self.attn_drop(attn_m)\n",
    "\n",
    "\t\tattn_a = (q_a @ k_m.transpose(-2, -1)) * self.scale\n",
    "\t\tattn_a = attn_a.softmax(dim=-1)\n",
    "\t\tattn_a = self.attn_drop(attn_a)\n",
    "\n",
    "\n",
    "\t\tx_m = (attn_m @ v_m).transpose(1, 2).reshape(B, L, dim)\n",
    "\t\tx_m = self.proj_m(x_m)\n",
    "\t\tx_m = self.proj_drop(x_m)\n",
    "\n",
    "\t\tx_a = (attn_a @ v_a).transpose(1, 2).reshape(B, L, dim)\n",
    "\t\tx_a = self.proj_a(x_a)\n",
    "\t\tx_a = self.proj_drop(x_a)\n",
    "\n",
    "\t\treturn  x_m, x_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d6f67e-2eab-4101-9347-dad5f304e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalCoccurrence(nn.Module):\n",
    "\tdef __init__(self,dim, num_head=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
    "\t\tsuper(LocalCoccurrence, self).__init__()\n",
    "\n",
    "\t\tself.norm1 = nn.LayerNorm(dim)\n",
    "\t\tself.attn  = CrossAttention(dim, num_head, qkv_bias, attn_drop, proj_drop)\n",
    "\n",
    "\tdef forward(self, u_m, u_a):\n",
    "\t\tB,C,H,W = u_m.shape\n",
    "\t\tL = H*W\n",
    "\t\tdim = C\n",
    "\n",
    "\t\tu_m = u_m.reshape(B,dim,L).permute(0,2,1)\n",
    "\t\tu_a = u_a.reshape(B,dim,L).permute(0,2,1)\n",
    "\n",
    "\t\tx_m = self.norm1(u_m)\n",
    "\t\tx_a = self.norm1(u_a)\n",
    "\t\tx_m, x_a = self.attn(x_m, x_a)\n",
    "\n",
    "\t\tgap_m = x_m.mean(1)\n",
    "\t\tgap_a = x_a.mean(1)\n",
    "\t\treturn gap_m, gap_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f54ea458-4bb2-4c8b-b5cd-0ba2b5f77d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def load_pretrain(self, ):\n",
    "        return\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(Net, self).__init__()\n",
    "        self.output_type = ['inference', 'loss']\n",
    "\n",
    "        self.backbone_m = Backbone()\n",
    "        self.backbone_a = Backbone()\n",
    "        dim = 1792\n",
    "\n",
    "        self.lc  = LocalCoccurrence(dim)\n",
    "        self.gl  = GlobalConsistency(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(dim*3),\n",
    "            nn.Linear(dim*3, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )#<todo> mlp needs to be deep if backbone is strong?\n",
    "        self.cancer = nn.Linear(dim,1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch_size,C,H,W = batch.shape\n",
    "        x = batch.reshape(-1, C, H, W)\n",
    "        \n",
    "        x_m =torch.tensor( np.array_split(batch,2,axis=3)[0])\n",
    "\n",
    "        print(x_m.shape)\n",
    "        x_a = torch.tensor( np.array_split(batch,2,axis=3)[1])\n",
    "        x_m=x_m.to(torch.float32)\n",
    "        x_a=x_a.to(torch.float32)\n",
    "        u_m = self.backbone_m(x_m)\n",
    "        u_a = self.backbone_a(x_a)\n",
    "        # u_m=transforms.ToTensor()(u_m)\n",
    "        # u_a=transforms.ToTensor()(u_a)\n",
    "        \n",
    "        gap_m, gap_a = self.lc(u_m, u_a)\n",
    "\n",
    "        g_m, p_m, g_a, p_a = self.gl(u_m, u_a)\n",
    "        gp_m = g_m + p_m\n",
    "\n",
    "        last = torch.cat([gp_m, gap_m, gap_a ],-1)\n",
    "        last = self.mlp(last)\n",
    "        cancer = self.cancer(last).reshape(-1)\n",
    "\n",
    "\n",
    "#         output = {}\n",
    "#         if  'loss' in self.output_type:\n",
    "#             output['cancer_loss'] = F.binary_cross_entropy_with_logits(cancer, batch['cancer'])\n",
    "#             output['global_loss'] = criterion_global_consistency(g_m, p_m, g_a, p_a)\n",
    "\n",
    "\n",
    "#         if 'inference' in self.output_type:\n",
    "#             output['cancer'] = torch.sigmoid(cancer)\n",
    "\n",
    "        return torch.sigmoid(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65227454-c06a-4021-ab61-e2d226fc0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Backbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b67d14-4d37-4344-8a46-b8ebd53bc580",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 224, 244)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.random(size=(2,3,224,244))\n",
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f0037a3-8c21-4fdd-a312-3398792c9cc3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.38464261, 0.46320736, 0.61145453, ..., 0.46819271,\n",
       "          0.18384187, 0.90101315],\n",
       "         [0.88355105, 0.97715609, 0.67127237, ..., 0.25958449,\n",
       "          0.3163026 , 0.33735406],\n",
       "         [0.35323027, 0.53580653, 0.00715512, ..., 0.58359236,\n",
       "          0.01157855, 0.55406419],\n",
       "         ...,\n",
       "         [0.17377533, 0.81160282, 0.60284069, ..., 0.81813179,\n",
       "          0.65705578, 0.98685327],\n",
       "         [0.02567422, 0.9700891 , 0.78915417, ..., 0.89285247,\n",
       "          0.8561142 , 0.91111484],\n",
       "         [0.82085075, 0.5724535 , 0.49404456, ..., 0.1589009 ,\n",
       "          0.24159626, 0.00926558]],\n",
       "\n",
       "        [[0.65561241, 0.1739655 , 0.57881791, ..., 0.36489165,\n",
       "          0.41558476, 0.96555035],\n",
       "         [0.8779631 , 0.33989584, 0.36084426, ..., 0.32019588,\n",
       "          0.53391479, 0.27973365],\n",
       "         [0.37360957, 0.01129127, 0.51023136, ..., 0.10019709,\n",
       "          0.18003554, 0.13852194],\n",
       "         ...,\n",
       "         [0.77564426, 0.16624153, 0.85615421, ..., 0.88772624,\n",
       "          0.80879989, 0.01968431],\n",
       "         [0.29243925, 0.15412492, 0.01524907, ..., 0.17105386,\n",
       "          0.01292708, 0.46229015],\n",
       "         [0.08605333, 0.89468308, 0.31035149, ..., 0.68520424,\n",
       "          0.29603991, 0.50376434]],\n",
       "\n",
       "        [[0.66102541, 0.64374532, 0.81671274, ..., 0.03498277,\n",
       "          0.76668805, 0.42867328],\n",
       "         [0.29994853, 0.42119776, 0.04777601, ..., 0.90026149,\n",
       "          0.69509161, 0.35670537],\n",
       "         [0.07261347, 0.4364469 , 0.33171544, ..., 0.36452172,\n",
       "          0.70466413, 0.40711521],\n",
       "         ...,\n",
       "         [0.06005574, 0.59813633, 0.85074725, ..., 0.58263205,\n",
       "          0.93504882, 0.44501372],\n",
       "         [0.94177869, 0.75015469, 0.13079723, ..., 0.81506885,\n",
       "          0.97336858, 0.27095878],\n",
       "         [0.75234626, 0.61136283, 0.22749594, ..., 0.13748635,\n",
       "          0.77891054, 0.12939294]]],\n",
       "\n",
       "\n",
       "       [[[0.19210422, 0.93477532, 0.40630868, ..., 0.22825614,\n",
       "          0.96055006, 0.93188581],\n",
       "         [0.19964647, 0.21123451, 0.15560195, ..., 0.57811862,\n",
       "          0.0443946 , 0.25766213],\n",
       "         [0.18129071, 0.2127101 , 0.22290159, ..., 0.35335355,\n",
       "          0.17291784, 0.74004126],\n",
       "         ...,\n",
       "         [0.39354161, 0.81132476, 0.10428027, ..., 0.68125211,\n",
       "          0.32623877, 0.42261422],\n",
       "         [0.7771774 , 0.55359938, 0.66184193, ..., 0.83768298,\n",
       "          0.60728366, 0.91383874],\n",
       "         [0.66687208, 0.5612311 , 0.79388896, ..., 0.63673808,\n",
       "          0.51097299, 0.16783794]],\n",
       "\n",
       "        [[0.08653021, 0.46706607, 0.6439813 , ..., 0.79798607,\n",
       "          0.88900499, 0.51190356],\n",
       "         [0.88147872, 0.44217762, 0.2690852 , ..., 0.83043763,\n",
       "          0.71140578, 0.60307743],\n",
       "         [0.66919718, 0.65640782, 0.94626909, ..., 0.26856669,\n",
       "          0.20085953, 0.55759092],\n",
       "         ...,\n",
       "         [0.20948944, 0.05668411, 0.86903638, ..., 0.1359226 ,\n",
       "          0.92754389, 0.06190191],\n",
       "         [0.62594875, 0.0793742 , 0.27089769, ..., 0.90113419,\n",
       "          0.37274285, 0.38924151],\n",
       "         [0.85229854, 0.87653993, 0.57480658, ..., 0.69025286,\n",
       "          0.74212009, 0.84553718]],\n",
       "\n",
       "        [[0.59319836, 0.49509276, 0.08782084, ..., 0.89507391,\n",
       "          0.75770465, 0.82576616],\n",
       "         [0.71336054, 0.07843025, 0.59788685, ..., 0.07879743,\n",
       "          0.88341519, 0.86880421],\n",
       "         [0.74227887, 0.07264139, 0.86409608, ..., 0.38147744,\n",
       "          0.25062565, 0.11665023],\n",
       "         ...,\n",
       "         [0.98620411, 0.36892384, 0.30517751, ..., 0.61552492,\n",
       "          0.83647254, 0.72622905],\n",
       "         [0.72937058, 0.49585386, 0.30210491, ..., 0.11035043,\n",
       "          0.80001187, 0.56303525],\n",
       "         [0.29458233, 0.99604017, 0.49559932, ..., 0.93681398,\n",
       "          0.57863329, 0.23875878]]],\n",
       "\n",
       "\n",
       "       [[[0.93471206, 0.73524495, 0.23736763, ..., 0.69946737,\n",
       "          0.50237146, 0.18816678],\n",
       "         [0.16079491, 0.84571113, 0.06271358, ..., 0.39040476,\n",
       "          0.6322259 , 0.41495667],\n",
       "         [0.96385404, 0.88884851, 0.39407504, ..., 0.62895918,\n",
       "          0.03257425, 0.56447355],\n",
       "         ...,\n",
       "         [0.98141803, 0.51096363, 0.27577648, ..., 0.43527139,\n",
       "          0.29133691, 0.78961863],\n",
       "         [0.56767965, 0.15904276, 0.93548262, ..., 0.15702021,\n",
       "          0.4691736 , 0.0011201 ],\n",
       "         [0.21014239, 0.73913178, 0.93826784, ..., 0.89412272,\n",
       "          0.74757564, 0.73864644]],\n",
       "\n",
       "        [[0.59234556, 0.01212232, 0.59534543, ..., 0.33074233,\n",
       "          0.96221978, 0.04015919],\n",
       "         [0.61389004, 0.66927032, 0.10479891, ..., 0.34026317,\n",
       "          0.15262132, 0.48241174],\n",
       "         [0.75762008, 0.48652498, 0.22481037, ..., 0.07432671,\n",
       "          0.85254872, 0.48511878],\n",
       "         ...,\n",
       "         [0.82634892, 0.08657573, 0.12607526, ..., 0.93744805,\n",
       "          0.69926081, 0.37054392],\n",
       "         [0.73724562, 0.77761877, 0.90228295, ..., 0.16267034,\n",
       "          0.22088292, 0.89907378],\n",
       "         [0.03443959, 0.37612087, 0.73060643, ..., 0.90236511,\n",
       "          0.32490468, 0.82681904]],\n",
       "\n",
       "        [[0.96814563, 0.63617119, 0.89180709, ..., 0.92557122,\n",
       "          0.83446707, 0.3992813 ],\n",
       "         [0.08154051, 0.78943149, 0.07549188, ..., 0.1900309 ,\n",
       "          0.76349691, 0.88281524],\n",
       "         [0.19833288, 0.59571437, 0.05844239, ..., 0.2541823 ,\n",
       "          0.04836773, 0.34366639],\n",
       "         ...,\n",
       "         [0.67694125, 0.50282055, 0.44318144, ..., 0.42718958,\n",
       "          0.43221149, 0.61274362],\n",
       "         [0.84841797, 0.18878275, 0.47489177, ..., 0.324005  ,\n",
       "          0.78881621, 0.25962905],\n",
       "         [0.06862949, 0.69124249, 0.34837388, ..., 0.83820863,\n",
       "          0.06626714, 0.02506148]]],\n",
       "\n",
       "\n",
       "       [[[0.15731175, 0.94870244, 0.26247731, ..., 0.12223095,\n",
       "          0.87279595, 0.24867021],\n",
       "         [0.37864407, 0.25624976, 0.90308511, ..., 0.69443639,\n",
       "          0.16799866, 0.66988968],\n",
       "         [0.99140622, 0.80821268, 0.30364459, ..., 0.20481547,\n",
       "          0.91411865, 0.06171631],\n",
       "         ...,\n",
       "         [0.08261472, 0.60421652, 0.67684991, ..., 0.09238604,\n",
       "          0.59161102, 0.49182365],\n",
       "         [0.0605808 , 0.78365404, 0.17838001, ..., 0.31497446,\n",
       "          0.54761718, 0.47773935],\n",
       "         [0.13990265, 0.31167225, 0.10895436, ..., 0.27986353,\n",
       "          0.13709208, 0.03019989]],\n",
       "\n",
       "        [[0.09086315, 0.93647743, 0.36707542, ..., 0.48451457,\n",
       "          0.94588756, 0.33948782],\n",
       "         [0.93489112, 0.8155053 , 0.34030151, ..., 0.16507458,\n",
       "          0.28997494, 0.19641343],\n",
       "         [0.15150834, 0.71050208, 0.51561209, ..., 0.46697391,\n",
       "          0.05238884, 0.53285694],\n",
       "         ...,\n",
       "         [0.75378786, 0.46472242, 0.35360616, ..., 0.98600189,\n",
       "          0.66339495, 0.28796623],\n",
       "         [0.47546672, 0.55063989, 0.72069897, ..., 0.31581536,\n",
       "          0.43227254, 0.96793724],\n",
       "         [0.1529598 , 0.88702861, 0.47463708, ..., 0.29691891,\n",
       "          0.62619661, 0.71892998]],\n",
       "\n",
       "        [[0.7681479 , 0.90176869, 0.47456982, ..., 0.6202819 ,\n",
       "          0.80046586, 0.36954001],\n",
       "         [0.29673563, 0.72395664, 0.81421482, ..., 0.56454227,\n",
       "          0.91015748, 0.175362  ],\n",
       "         [0.37629318, 0.42213576, 0.88576615, ..., 0.50722548,\n",
       "          0.53417874, 0.09240502],\n",
       "         ...,\n",
       "         [0.99637795, 0.08336119, 0.27613721, ..., 0.35840651,\n",
       "          0.60182732, 0.80068242],\n",
       "         [0.03523968, 0.46751995, 0.36391885, ..., 0.25093386,\n",
       "          0.73135114, 0.0931043 ],\n",
       "         [0.5382543 , 0.28422601, 0.71743211, ..., 0.10349474,\n",
       "          0.57695255, 0.79418101]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np.array_split(i,2,axis=3)[0],np.array_split(i,2,axis=3)[1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4919b2d4-186b-4a6a-aac3-57aed587aaa3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.38464261, 0.46320736, 0.61145453, ..., 0.46819271,\n",
       "          0.18384187, 0.90101315],\n",
       "         [0.88355105, 0.97715609, 0.67127237, ..., 0.25958449,\n",
       "          0.3163026 , 0.33735406],\n",
       "         [0.35323027, 0.53580653, 0.00715512, ..., 0.58359236,\n",
       "          0.01157855, 0.55406419],\n",
       "         ...,\n",
       "         [0.17377533, 0.81160282, 0.60284069, ..., 0.81813179,\n",
       "          0.65705578, 0.98685327],\n",
       "         [0.02567422, 0.9700891 , 0.78915417, ..., 0.89285247,\n",
       "          0.8561142 , 0.91111484],\n",
       "         [0.82085075, 0.5724535 , 0.49404456, ..., 0.1589009 ,\n",
       "          0.24159626, 0.00926558]],\n",
       "\n",
       "        [[0.65561241, 0.1739655 , 0.57881791, ..., 0.36489165,\n",
       "          0.41558476, 0.96555035],\n",
       "         [0.8779631 , 0.33989584, 0.36084426, ..., 0.32019588,\n",
       "          0.53391479, 0.27973365],\n",
       "         [0.37360957, 0.01129127, 0.51023136, ..., 0.10019709,\n",
       "          0.18003554, 0.13852194],\n",
       "         ...,\n",
       "         [0.77564426, 0.16624153, 0.85615421, ..., 0.88772624,\n",
       "          0.80879989, 0.01968431],\n",
       "         [0.29243925, 0.15412492, 0.01524907, ..., 0.17105386,\n",
       "          0.01292708, 0.46229015],\n",
       "         [0.08605333, 0.89468308, 0.31035149, ..., 0.68520424,\n",
       "          0.29603991, 0.50376434]],\n",
       "\n",
       "        [[0.66102541, 0.64374532, 0.81671274, ..., 0.03498277,\n",
       "          0.76668805, 0.42867328],\n",
       "         [0.29994853, 0.42119776, 0.04777601, ..., 0.90026149,\n",
       "          0.69509161, 0.35670537],\n",
       "         [0.07261347, 0.4364469 , 0.33171544, ..., 0.36452172,\n",
       "          0.70466413, 0.40711521],\n",
       "         ...,\n",
       "         [0.06005574, 0.59813633, 0.85074725, ..., 0.58263205,\n",
       "          0.93504882, 0.44501372],\n",
       "         [0.94177869, 0.75015469, 0.13079723, ..., 0.81506885,\n",
       "          0.97336858, 0.27095878],\n",
       "         [0.75234626, 0.61136283, 0.22749594, ..., 0.13748635,\n",
       "          0.77891054, 0.12939294]]],\n",
       "\n",
       "\n",
       "       [[[0.19210422, 0.93477532, 0.40630868, ..., 0.22825614,\n",
       "          0.96055006, 0.93188581],\n",
       "         [0.19964647, 0.21123451, 0.15560195, ..., 0.57811862,\n",
       "          0.0443946 , 0.25766213],\n",
       "         [0.18129071, 0.2127101 , 0.22290159, ..., 0.35335355,\n",
       "          0.17291784, 0.74004126],\n",
       "         ...,\n",
       "         [0.39354161, 0.81132476, 0.10428027, ..., 0.68125211,\n",
       "          0.32623877, 0.42261422],\n",
       "         [0.7771774 , 0.55359938, 0.66184193, ..., 0.83768298,\n",
       "          0.60728366, 0.91383874],\n",
       "         [0.66687208, 0.5612311 , 0.79388896, ..., 0.63673808,\n",
       "          0.51097299, 0.16783794]],\n",
       "\n",
       "        [[0.08653021, 0.46706607, 0.6439813 , ..., 0.79798607,\n",
       "          0.88900499, 0.51190356],\n",
       "         [0.88147872, 0.44217762, 0.2690852 , ..., 0.83043763,\n",
       "          0.71140578, 0.60307743],\n",
       "         [0.66919718, 0.65640782, 0.94626909, ..., 0.26856669,\n",
       "          0.20085953, 0.55759092],\n",
       "         ...,\n",
       "         [0.20948944, 0.05668411, 0.86903638, ..., 0.1359226 ,\n",
       "          0.92754389, 0.06190191],\n",
       "         [0.62594875, 0.0793742 , 0.27089769, ..., 0.90113419,\n",
       "          0.37274285, 0.38924151],\n",
       "         [0.85229854, 0.87653993, 0.57480658, ..., 0.69025286,\n",
       "          0.74212009, 0.84553718]],\n",
       "\n",
       "        [[0.59319836, 0.49509276, 0.08782084, ..., 0.89507391,\n",
       "          0.75770465, 0.82576616],\n",
       "         [0.71336054, 0.07843025, 0.59788685, ..., 0.07879743,\n",
       "          0.88341519, 0.86880421],\n",
       "         [0.74227887, 0.07264139, 0.86409608, ..., 0.38147744,\n",
       "          0.25062565, 0.11665023],\n",
       "         ...,\n",
       "         [0.98620411, 0.36892384, 0.30517751, ..., 0.61552492,\n",
       "          0.83647254, 0.72622905],\n",
       "         [0.72937058, 0.49585386, 0.30210491, ..., 0.11035043,\n",
       "          0.80001187, 0.56303525],\n",
       "         [0.29458233, 0.99604017, 0.49559932, ..., 0.93681398,\n",
       "          0.57863329, 0.23875878]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_split(i,2,axis=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfd6b6bf-1eac-4bf3-92c3-2a50ff7b76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e2c1cf8-dd4e-48ba-9670-4095aebbe015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_560/2828784507.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  i = torch.tensor( i).to(device)\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "# i.to(device)\n",
    "i = torch.tensor( i).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78a312a9-bd17-44fa-a3d7-ed94931ecd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_560/2127465660.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_m =torch.tensor( np.array_split(batch,2,axis=3)[0])\n",
      "/tmp/ipykernel_560/2127465660.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_a = torch.tensor( np.array_split(batch,2,axis=3)[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 224, 122])\n"
     ]
    }
   ],
   "source": [
    "x = net(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec9b3e40-d28c-42d8-8939-7a2f6e50eb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5497, 0.5596], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f811d7b7-1d6f-4398-8d1a-7f566e7b341b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(is_train, args):\n",
    "    transform = build_transform(is_train, args)\n",
    "    if not args.use_mcloader:\n",
    "        root = os.path.join(args.data_path, 'train' if is_train else 'val')\n",
    "        print(f\"/n-----------------/n{root}\")\n",
    "        dataset = datasets.ImageFolder(root, transform=transform)\n",
    "        print(dataset)\n",
    "    else:\n",
    "        from mcloader import ClassificationDataset\n",
    "        dataset = ClassificationDataset(\n",
    "            'train' if is_train else 'val',\n",
    "            pipeline=transform\n",
    "        )\n",
    "    nb_classes = 2\n",
    "\n",
    "    return dataset, nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "957ba470-ce38-4680-8ecf-a6ff4fa4ac5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_transform(is_train, args):\n",
    "    resize_im = args.input_size > 32\n",
    "    if is_train:\n",
    "        train_transform = transforms.Compose([\n",
    "                transforms.Resize((args.input_size, args.input_size//1.2)),  # 缩放\n",
    "                # transforms.RandomCrop(32, padding=4),  # 随机裁剪\n",
    "                transforms.ToTensor(),  # 图片转张量，同时归一化0-255 ---》 0-1\n",
    "                transforms.Normalize(norm_mean, norm_std),  # 标准化均值为0标准差为1\n",
    "            ])\n",
    "        return train_transform\n",
    "\n",
    "    t = []\n",
    "    t.append(transforms.ToTensor())\n",
    "    t.append(transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD))\n",
    "    return transforms.Compose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e9d41-8a47-468e-aaaf-d5bd0aef67d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    init_distributed_mode(args)\n",
    "    print(args)\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    # fix the seed for reproducibility\n",
    "    seed = args.seed + get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    dataset_train, args.nb_classes = build_dataset(is_train=True, args=args)\n",
    "    dataset_val, _ = build_dataset(is_train=False, args=args)\n",
    "    args.distributed = False\n",
    "    # print(len(dataset_train))\n",
    "    tmp = build_weight(args.data_path)\n",
    "    sampler_train = torch.utils.data.WeightedRandomSampler(tmp,args.nb_classes*len(dataset_train))\n",
    "    sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "    \n",
    "    # for i in sampler_train:\n",
    "    #     print(i)\n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, sampler=sampler_train,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val, sampler=sampler_val,\n",
    "        batch_size=250,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=False\n",
    "    )\n",
    "    print(f\"Creating model: {args.model}\")\n",
    "    model = Model()\n",
    "\n",
    "    if not args.distributed or args.rank == 0:\n",
    "        print(model)\n",
    "        input_tensor = torch.zeros((1, 3, 1280, 640), dtype=torch.float32)\n",
    "        model.eval()\n",
    "        cal_flops_params_with_fvcore(model, input_tensor)\n",
    "\n",
    "    model.to(device)\n",
    "    model_ema = None\n",
    "\n",
    "\n",
    "    model_without_ddp = model\n",
    "\n",
    "    linear_scaled_lr = args.lr * args.batch_size * get_world_size() / 512.0\n",
    "\n",
    "    args.lr = linear_scaled_lr\n",
    "    optimizer = create_optimizer(args, model_without_ddp)\n",
    "\n",
    "    loss_scaler = NativeScaler()\n",
    "\n",
    "    lr_scheduler, _ = create_scheduler(args, optimizer)\n",
    "\n",
    "    criterion = LabelSmoothingCrossEntropy()\n",
    "\n",
    "    # if args.mixup > 0.:\n",
    "    #     # smoothing is handled with mixup label transform\n",
    "    #     criterion = SoftTargetCrossEntropy()\n",
    "    # elif args.smoothing:\n",
    "    #     criterion = LabelSmoothingCrossEntropy(smoothing=args.smoothing)\n",
    "    # else:\n",
    "    #     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # criterion = DistillationLoss(\n",
    "    #     criterion, None, 'none', 0, 0\n",
    "    # )\n",
    "    criterion = mixloss()\n",
    "    \n",
    "    if not args.output_dir:\n",
    "        args.output_dir = args.model\n",
    "        if is_main_process():\n",
    "            import os\n",
    "            if not os.path.exists(args.model):\n",
    "                os.mkdir(args.model)\n",
    "\n",
    "    output_dir = Path(args.output_dir)\n",
    "    if args.resume:\n",
    "        if args.resume.startswith('https'):\n",
    "            checkpoint = torch.hub.load_state_dict_from_url(\n",
    "                args.resume, map_location='cpu', check_hash=True)\n",
    "        else:\n",
    "            checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "        if 'model' in checkpoint:\n",
    "            model_without_ddp.load_state_dict(checkpoint['model'])\n",
    "        else:\n",
    "            model_without_ddp.load_state_dict(checkpoint)\n",
    "        if not args.finetune:\n",
    "            if not args.eval and 'optimizer' in checkpoint and 'lr_scheduler' in checkpoint and 'epoch' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                # lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "                if not args.finetune:\n",
    "                    args.start_epoch = checkpoint['epoch'] + 1\n",
    "                if 'scaler' in checkpoint:\n",
    "                    loss_scaler.load_state_dict(checkpoint['scaler'])\n",
    "\n",
    "    if args.eval:\n",
    "        if hasattr(model.module, \"merge_bn\"):\n",
    "            print(\"Merge pre bn to speedup inference.\")\n",
    "            model.module.merge_bn()\n",
    "        test_stats = evaluate(data_loader_val, model, device)\n",
    "        print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n",
    "        return\n",
    "\n",
    "    if args.throughout:\n",
    "        from logger import create_logger\n",
    "        logger = create_logger(output_dir=output_dir, dist_rank=get_rank(), name=args.model)\n",
    "        throughput(data_loader_val, model, logger)\n",
    "        return\n",
    "\n",
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "    start_time = time.time()\n",
    "    max_accuracy = 0.0\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            data_loader_train.sampler.set_epoch(epoch)\n",
    "\n",
    "        train_stats = train_one_epoch(\n",
    "            model, criterion, data_loader_train,\n",
    "            optimizer, device, epoch, loss_scaler,\n",
    "            args.clip_grad, model_ema, mixup_fn,\n",
    "            set_training_mode=True,\n",
    "        )\n",
    "\n",
    "        lr_scheduler.step(epoch)\n",
    "        if args.output_dir:\n",
    "            checkpoint_paths = [output_dir / 'checkpoint.pth']\n",
    "            for checkpoint_path in checkpoint_paths:\n",
    "                save_on_master({\n",
    "                    'model': model_without_ddp.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'scaler': loss_scaler.state_dict(),\n",
    "                    'args': args,\n",
    "                }, checkpoint_path)\n",
    "\n",
    "        test_stats = evaluate(data_loader_val, model, device)\n",
    "        print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n",
    "        if test_stats[\"acc1\"] > max_accuracy:\n",
    "            if args.output_dir:\n",
    "                checkpoint_paths = [output_dir / 'checkpoint_best.pth']\n",
    "                for checkpoint_path in checkpoint_paths:\n",
    "                    save_on_master({\n",
    "                        'model': model_without_ddp.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                        'epoch': epoch,\n",
    "                        'args': args,\n",
    "                    }, checkpoint_path)\n",
    "        max_accuracy = max(max_accuracy, test_stats[\"acc1\"])\n",
    "        print(f'Max accuracy: {max_accuracy:.2f}%')\n",
    "\n",
    "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                     **{f'test_{k}': v for k, v in test_stats.items()},\n",
    "                     'epoch': epoch}\n",
    "\n",
    "        if args.output_dir and is_main_process():\n",
    "            with (output_dir / \"log.txt\").open(\"a\") as f:\n",
    "                f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
