{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddf067f-1683-4b32-a316-add0519e0e54",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854a2ced-1113-40ec-bc51-12ac2934c65c",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9155f1dd-c478-4914-8af5-2661db7579ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch import nn, einsum\n",
    "from torch.nn import functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "from typing import Iterable, Optional\n",
    "from timm.models import create_model\n",
    "from timm.optim import create_optimizer\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.data import Mixup,create_transform\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.utils import accuracy, ModelEma,NativeScaler, get_state_dict, ModelEma\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from functools import partial\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d9b519-0065-4bd1-8c0a-9f0ba41a049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b15bf-98e1-49ea-892e-1c21faa6061e",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b82abec-ce9c-40bd-8647-6c18cbd7dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_world_size():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 1\n",
    "    return dist.get_world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e879db-a187-4f99-a8f0-099308802830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_flops_params_with_fvcore(model, inputs):\n",
    "    \"\"\"\n",
    "    print model's flops\n",
    "    \"\"\"\n",
    "    from fvcore.nn import FlopCountAnalysis, parameter_count_table, parameter_count\n",
    "    flops = FlopCountAnalysis(model, inputs)\n",
    "    params = parameter_count(model)\n",
    "    print('flops(fvcore): %f M' % (flops.total()/1000**2))\n",
    "    print('params(fvcore): %f M' % (params['']/1000**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de51e0c-925c-4567-a8b1-153e9c9ec680",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors.\n",
    "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "    \"\"\"\n",
    "    tensors_gather = [\n",
    "        torch.ones_like(tensor) for _ in range(torch.distributed.get_world_size())\n",
    "    ]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0e0ef57-4874-48f5-a627-c4669026d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_on_master(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    save model\n",
    "    \"\"\"\n",
    "    if is_main_process():\n",
    "        torch.save(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09a5f739-43b1-442e-8fed-86e4af378106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank():\n",
    "    \"\"\"\n",
    "    get gpu's num\n",
    "    \"\"\"\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 0\n",
    "    return dist.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600d82b5-671f-47c9-b969-d309122e3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 1234):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d764acd0-a96f-462e-b599-d5267f14eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimzier(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "\n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f514761-ae92-4542-af4c-cb7082de05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(is_train, args):\n",
    "    transform = build_transform(is_train, args)\n",
    "    if not args.use_mcloader:\n",
    "        root = os.path.join(args.data_path, 'train' if is_train else 'val')\n",
    "        dataset = datasets.ImageFolder(root, transform=transform)\n",
    "    else:\n",
    "        from mcloader import ClassificationDataset\n",
    "        dataset = ClassificationDataset(\n",
    "            'train' if is_train else 'val',\n",
    "            pipeline=transform\n",
    "        )\n",
    "    nb_classes = 2\n",
    "\n",
    "    return dataset, nb_classes\n",
    "\n",
    "\n",
    "def build_transform(is_train, args):\n",
    "    \"\"\"\n",
    "    is_train\n",
    "    \"\"\"\n",
    "    # 单独设置\n",
    "    \n",
    "    # 随机改变图像的色调\n",
    "    # hue_change = transforms.ColorJitter(hue=0.5)\n",
    "   \n",
    "    if is_train:\n",
    "        # 随机改变图像的亮度\n",
    "        brightness_change = transforms.ColorJitter(brightness=0.5)\n",
    "        # 随机改变图像的对比度\n",
    "        contrast_change = transforms.ColorJitter(contrast=0.5)\n",
    "        train_transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),  # 图片转张量，同时归一化0-255 ---》 0-1\n",
    "                    transforms.Normalize(norm_mean, norm_std),  # 标准化均值为0标准差为1\n",
    "                    brightness_change,\n",
    "                    contrast_change,\n",
    "                    transforms.RandomHorizontalFlip(p=0.5)#随机水平翻转\n",
    "\n",
    "                ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),  # 图片转张量，同时归一化0-255 ---》 0-1\n",
    "                    transforms.Normalize(norm_mean, norm_std),  # 标准化均值为0标准差为1\n",
    "                    # brightness_change,\n",
    "                    # contrast_change,\n",
    "                    transforms.RandomHorizontalFlip(p=0.5)#随机水平翻转\n",
    "                ])\n",
    "    \n",
    "    return train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f739af37-f2e0-4631-9e65-7726040b846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weight(path='',nu_class=1000):\n",
    "    \"\"\"\n",
    "    set \n",
    "    \"\"\"\n",
    "    ud_map={}\n",
    "    trian_path = glob.glob(path+'/train/*/*')\n",
    "    print()\n",
    "    for i in trian_path:\n",
    "        i = i.split('/')\n",
    "        if i[-2] in ud_map:\n",
    "            ud_map[i[-2]]+=1\n",
    "        else:\n",
    "            ud_map.update({i[-2]:1})\n",
    "    tol = len(trian_path)\n",
    "    weight = []\n",
    "    for k in ud_map:\n",
    "        for i in range(ud_map[k]):\n",
    "            weight.append(tol/ud_map[k])\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f8cc8a3-fb8c-4256-89b5-3f135b45a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLogger(object):\n",
    "    def __init__(self, delimiter=\"\\t\"):\n",
    "        self.meters = defaultdict(SmoothedValue)\n",
    "        self.delimiter = delimiter\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = v.item()\n",
    "            assert isinstance(v, (float, int))\n",
    "            self.meters[k].update(v)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.meters:\n",
    "            return self.meters[attr]\n",
    "        if attr in self.__dict__:\n",
    "            return self.__dict__[attr]\n",
    "        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
    "            type(self).__name__, attr))\n",
    "\n",
    "    def __str__(self):\n",
    "        loss_str = []\n",
    "        for name, meter in self.meters.items():\n",
    "            loss_str.append(\n",
    "                \"{}: {}\".format(name, str(meter))\n",
    "            )\n",
    "        return self.delimiter.join(loss_str)\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        for meter in self.meters.values():\n",
    "            meter.synchronize_between_processes()\n",
    "\n",
    "    def add_meter(self, name, meter):\n",
    "        self.meters[name] = meter\n",
    "\n",
    "    def log_every(self, iterable, print_freq, header=None):\n",
    "        i = 0\n",
    "        if not header:\n",
    "            header = ''\n",
    "        start_time = time.time()\n",
    "        end = time.time()\n",
    "        iter_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        data_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        space_fmt = ':' + str(len(str(len(iterable)))) + 'd'\n",
    "        log_msg = [\n",
    "            header,\n",
    "            '[{0' + space_fmt + '}/{1}]',\n",
    "            'eta: {eta}',\n",
    "            '{meters}',\n",
    "            'time: {time}',\n",
    "            'data: {data}'\n",
    "        ]\n",
    "        if torch.cuda.is_available():\n",
    "            log_msg.append('max mem: {memory:.0f}')\n",
    "        log_msg = self.delimiter.join(log_msg)\n",
    "        MB = 1024.0 * 1024.0\n",
    "        for obj in iterable:\n",
    "            data_time.update(time.time() - end)\n",
    "            yield obj\n",
    "            iter_time.update(time.time() - end)\n",
    "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
    "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
    "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "                if torch.cuda.is_available():\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time),\n",
    "                        memory=torch.cuda.max_memory_allocated() / MB))\n",
    "                else:\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time)))\n",
    "            i += 1\n",
    "            end = time.time()\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print('{} Total time: {} ({:.4f} s / it)'.format(\n",
    "            header, total_time_str, total_time / len(iterable)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28888e-7bf8-4e39-821a-309730283c2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# train&&eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ced93f4f-3788-4691-b653-39780dda1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model,class_criterion,nce_criterion\n",
    "                    data_loader, optimizer: torch.optim.Optimizer,\n",
    "                    device: torch.device, epoch: int, loss_scaler,warmup,warmupstep:int, max_norm: float = 0,\n",
    "                    model_ema: Optional[ModelEma] = None, mixup_fn: Optional[Mixup] = None,\n",
    "                    set_training_mode=True):\n",
    "    model.train(set_training_mode)\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    print_freq = 10\n",
    "    if epoch < warmupstep:\n",
    "            warmup_scheduler.step()\n",
    "    for samples, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        samples = samples.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        if mixup_fn is not None:\n",
    "            samples, targets = mixup_fn(samples, targets)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            cl,log,lab,fe,attn = model(samples)\n",
    "            loss_cls = class_criterion(cl,targets)\n",
    "            nce_loss = nce_criterion(log,lab)\n",
    "            sim_loss = similiarity()\n",
    "            aux_loss1= aux_similiarity(fe[0][0],fe[3][0])\n",
    "            aux_loss2= aux_similiarity(fe[1][0],fe[4][0])\n",
    "            aux_loss3= aux_similiarity(fe[2][0],fe[5][0])\n",
    "            #cancer,logits,labels,features,attn\n",
    "            loss = criterion(samples, outputs, targets)\n",
    "\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # this attribute is added by timm on one optimizer (adahessian)\n",
    "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
    "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
    "                    parameters=model.parameters(), create_graph=is_second_order)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        if model_ema is not None:\n",
    "            model_ema.update(model)\n",
    "\n",
    "        metric_logger.update(loss=loss_value)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print(\"Averaged stats:\", metric_logger)\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caabd028-40c0-4549-bf55-71796519cf54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, device):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    metric_logger = MetricLogger(delimiter=\"  \")\n",
    "    header = 'Test:'\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for images, target in metric_logger.log_every(data_loader, 10, header):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "        batch_size = images.shape[0]\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
    "        # metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print('* Acc@1 {top1.global_avg:.3f}  loss {losses.global_avg:.3f}'\n",
    "          .format(top1=metric_logger.acc1, losses=metric_logger.loss))\n",
    "\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb197b-42d2-496b-a143-e02878adfec6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 吞吐量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "205bb0c6-512b-4ff3-bcce-00edcbbeb724",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def throughput(data_loader, model, logger):\n",
    "    model.eval()\n",
    "\n",
    "    for idx, (images, _) in enumerate(data_loader):\n",
    "        images = images.cuda(non_blocking=True)\n",
    "        batch_size = images.shape[0]\n",
    "        for i in range(50):\n",
    "            model(images)\n",
    "        torch.cuda.synchronize()\n",
    "        logger.info(f\"throughput averaged with 30 times\")\n",
    "        tic1 = time.time()\n",
    "        for i in range(30):\n",
    "            model(images)\n",
    "        torch.cuda.synchronize()\n",
    "        tic2 = time.time()\n",
    "        logger.info(f\"batch_size {batch_size} throughput {30 * batch_size / (tic2 - tic1)}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797ac32-a10f-41b2-b021-3b6821497ca8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14107509-4dea-4b72-9238-d69a7837b1db",
   "metadata": {},
   "source": [
    "## embeding patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4805a16-318e-4657-ae29-d325c8a8dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORM_EPS = 1e-5\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride=1,\n",
    "                 mode = \"V\"\n",
    "                ):\n",
    "        super(PatchEmbed, self).__init__()\n",
    "        norm_layer = partial(nn.BatchNorm2d, eps=NORM_EPS)\n",
    "        if stride == 4 and mode == \"V\":\n",
    "            self.avgpool = nn.AvgPool2d((4, 32), stride=4, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif stride == 2 and mode == \"V\":\n",
    "            self.avgpool = nn.AvgPool2d((2, 16), stride=2, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif stride == 2 and mode == \"H\":\n",
    "            self.avgpool = nn.AvgPool2d((64, 2), stride=2, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif stride == 1 and mode == \"H\":\n",
    "            self.avgpool = nn.AvgPool2d((32, 1), stride=1, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif in_channels != out_channels:\n",
    "            self.avgpool = nn.Identity()\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        else:\n",
    "            self.avgpool = nn.Identity()\n",
    "            self.conv = nn.Identity()\n",
    "            self.norm = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.norm(self.conv(self.avgpool(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77116014-4b44-4a80-b0c1-752c2c0c71b1",
   "metadata": {},
   "source": [
    "## product QKV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd87e12-2fc1-4fa5-b50a-98ed6189ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_PQKV(nn.Module):\n",
    "    \"\"\"\n",
    "    product QKV\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, head_dim=32, out_dim=None, qkv_bias=True, qk_scale=None,\n",
    "                 attn_drop=0, proj_drop=0., sr_ratio=1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.out_dim = out_dim if out_dim is not None else dim\n",
    "        self.num_heads = self.dim // head_dim\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.q = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.k = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.v = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        q = self.q(x)\n",
    "        q = q.reshape(B, N, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "        k = self.k(x)\n",
    "        k = k.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 3, 1)\n",
    "        v = self.v(x)\n",
    "        v = v.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "        return q,k,v\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff460db0-8100-4c77-8cf5-ccf08ced2c99",
   "metadata": {},
   "source": [
    "## Efficient Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4b52fb-efae-4c7c-81e5-678caae6b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_MHA(nn.Module):\n",
    "    \"\"\"\n",
    "    Efficient Multi-Head Self Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, head_dim=32, qk_scale=None,attn_drop=0):\n",
    "        super().__init__()\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "    def forward(self, q,k,v,b,n,c):\n",
    "        attn = (q @ k) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        attn = (attn @ v).transpose(1, 2).reshape(b,n,c)\n",
    "        return attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a44d6-2360-487d-9706-32ad38319827",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLP and res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a663ad-3599-4d1f-ae7a-0660c9163ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1= x \n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        x+=x1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff5c5b-4fa1-453d-bc53-ae42b1a21f05",
   "metadata": {},
   "source": [
    "## Efficient Multi-Head Double-Viwe Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37319280-e5e6-443e-b924-54b087642c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_MTDVA(nn.Module):\n",
    "    \"\"\"\n",
    "    Efficient Multi-Head Double-Viwe Attention\n",
    "    x_mh,x_ah,x_mv,x_av->forward\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, head_dim=32, out_dim=None, qkv_bias=True, qk_scale=None,\n",
    "                 attn_drop=0, proj_drop=0., sr_ratio=1):\n",
    "        super(E_MTDVA,self).__init__()\n",
    "        self.dim = dim\n",
    "        self.out_dim = out_dim if out_dim is not None else dim\n",
    "        self.num_heads = self.dim // head_dim\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.qkv = E_PQKV( dim, head_dim, out_dim, qkv_bias, qk_scale,attn_drop, proj_drop, sr_ratio)\n",
    "        self.sa = E_MHA(head_dim,qk_scale,attn_drop)\n",
    "        self.ca = E_MHA(head_dim,qk_scale,attn_drop)\n",
    "        self.proj = Mlp(self.dim,self.dim*4, self.out_dim)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.sr_ratio = sr_ratio\n",
    "        self.N_ratio = sr_ratio ** 2\n",
    "        if sr_ratio > 1:\n",
    "            self.sr = nn.AvgPool1d(kernel_size=self.N_ratio, stride=self.N_ratio)\n",
    "            self.norm = nn.BatchNorm1d(dim, eps=NORM_EPS)\n",
    "        self.is_bn_merged = False\n",
    "\n",
    "    def merge_bn(self, pre_bn):\n",
    "        merge_pre_bn(self.q, pre_bn)\n",
    "        if self.sr_ratio > 1:\n",
    "            merge_pre_bn(self.k, pre_bn, self.norm)\n",
    "            merge_pre_bn(self.v, pre_bn, self.norm)\n",
    "        else:\n",
    "            merge_pre_bn(self.k, pre_bn)\n",
    "            merge_pre_bn(self.v, pre_bn)\n",
    "        self.is_bn_merged = True\n",
    "    # def pro_pkv(x_mh)\n",
    "\n",
    "    def forward(self, x_mh,x_ah,x_mv,x_av):\n",
    "        \n",
    "        h = torch.cat([x_mh,x_ah],dim = 1)\n",
    "        v = torch.cat([x_mv,x_av],dim = 1)\n",
    "        B, N, C = h.shape\n",
    "        #selfatt\n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        q_h,k_h,v_h = self.qkv(h)\n",
    "        q_v,k_v,v_v = self.qkv(v)\n",
    "        attn_h = self.sa(q_h,k_h,v_h, B, N, C)\n",
    "        attn_v = self.sa(q_v,k_v,v_v, B, N, C)\n",
    "        h+=attn_h\n",
    "        v+=attn_v\n",
    "        \n",
    "        ##ffn\n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        h = self.proj(h)\n",
    "        v = self.proj(v)\n",
    "        #crossatt\n",
    "        \n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        q_h,k_h,v_h = self.qkv(h)\n",
    "        q_v,k_v,v_v = self.qkv(v)\n",
    "        attn_h = self.sa(q_h,k_h,v_h, B, N, C)\n",
    "        attn_v = self.sa(q_v,k_v,v_v, B, N, C)\n",
    "        h+=attn_h\n",
    "        v+=attn_v\n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        q_h,k_h,v_h = self.qkv(h)\n",
    "        q_v,k_v,v_v = self.qkv(v)\n",
    "        attn_h=self.ca(q_h,k_v,v_h, B, N, C)\n",
    "        attn_v=self.ca(q_h,k_v,v_h, B, N, C)\n",
    "        h+=attn_h\n",
    "        v+=attn_v\n",
    "        ##ffn\n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        h = self.proj(h)\n",
    "        v = self.proj(v)\n",
    "        #output\n",
    "        attn_h = h.mean(1)\n",
    "        attn_v = v.mean(1)\n",
    "        x = torch.concat([attn_h,attn_v],dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d15b41-e14e-482e-a350-805ae52fe6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShardExamine(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 out_putdim,\n",
    "                 num_head=64, \n",
    "                 qkv_bias=False, \n",
    "                 attn_drop=0.1, \n",
    "                 proj_drop=0.1,\n",
    "                 stride=1\n",
    "                ):\n",
    "        super(ShardExamine,self).__init__()\n",
    "        # super(LocalCoccurrence, self).__init__()\n",
    "        self.PEV = PatchEmbed(in_channels,out_channels,stride*2,mode = \"V\")\n",
    "        self.PEH = PatchEmbed(in_channels,out_channels,stride,mode = \"H\")\n",
    "        self.proj = nn.Linear(out_channels*2, out_putdim)\n",
    "        self.attn  = E_MTDVA(dim,num_head,None,True,qkv_bias,attn_drop,proj_drop)\n",
    "\n",
    "    def forward(self, u_m, u_a):\n",
    "        u_mv = self.PEV(u_m)\n",
    "        u_av = self.PEV(u_a)\n",
    "        u_m = self.PEH(u_m)\n",
    "        u_a = self.PEH(u_a)\n",
    "        B,C,H,W = u_mv.shape\n",
    "        L = H*W\n",
    "        dim = C\n",
    "\n",
    "        u_mv = u_mv.reshape(B,dim,L).permute(0,2,1)\n",
    "        u_av = u_av.reshape(B,dim,L).permute(0,2,1)\n",
    "        u_m  = u_m.reshape(B,dim,L).permute(0,2,1)\n",
    "        u_a  = u_a.reshape(B,dim,L).permute(0,2,1)\n",
    "\n",
    "\n",
    "        x = self.attn(u_m, u_a,u_mv, u_av)# x_mh,x_ah,x_mv,x_av\n",
    "        # x_m, x_a = self.attn(u_m, u_a)\n",
    "        # x_mv, x_av = self.attn(u_mv, u_a)\n",
    "        # gap_m = x_m.mean(1)\n",
    "        # x = x.mean(1)\n",
    "        x = self.proj(x)\n",
    "        \n",
    "        return  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cabaf972-fea3-425d-8179-5bef13a1fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basNet(nn.Module):\n",
    "    \"\"\"\n",
    "    only two viwe\n",
    "    \"\"\"\n",
    "    def load_pretrain(self, ):\n",
    "        return\n",
    "\n",
    "    def __init__(self,K=8192, m=0.999, T=0.07,dim=128,nc=512):\n",
    "        super(basNet, self).__init__()\n",
    "        # self.output_type = ['inference', 'loss']\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.encoder_q = timm.create_model ('efficientnetv2_m',#m 512 s 256\n",
    "                                          pretrained=False, \n",
    "                                          drop_rate = 0.2, \n",
    "                                          drop_path_rate = 0.1,\n",
    "                                          num_classes=nc\n",
    "                                         )\n",
    "        self.encoder_k = timm.create_model ('efficientnetv2_m',\n",
    "                                          pretrained=False, \n",
    "                                          drop_rate = 0.2, \n",
    "                                          drop_path_rate = 0.1,\n",
    "                                          num_classes=nc\n",
    "                                         )\n",
    "        \n",
    "        \n",
    "        # dim_mlp = self.encoder_q.fc.weight.shape[1]\n",
    "        self.encoder_q.fc = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 128),\n",
    "        )\n",
    "        self.encoder_k.fc =nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 128),\n",
    "        )\n",
    "        for param_q, param_k in zip(\n",
    "            self.encoder_q.parameters(), self.encoder_k.parameters()\n",
    "        ):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "        # dim = 1280\n",
    "\n",
    "        # self.lc  = LocalCoccurrence(dim)\n",
    "        # self.gl  = GlobalConsistency(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(1280),\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 128),\n",
    "        )#<todo> mlp needs to be deep if backbone is strong?\n",
    "        self.att = ShardExamine(128,512,128,256)\n",
    "        self.cancer = nn.Linear(128,1)\n",
    "        # self.labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(\n",
    "            self.encoder_q.parameters(), self.encoder_k.parameters()\n",
    "        ):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        # gather keys before updating queue\n",
    "        # keys = concat_all_gather(keys)\n",
    "\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr : ptr + batch_size] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_ddp(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(batch_size_all).cuda()\n",
    "\n",
    "        # broadcast to all gpus\n",
    "        torch.distributed.broadcast(idx_shuffle, src=0)\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        # shuffled index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_ddp(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # restored index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this]\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "        Output:\n",
    "            logits, targets\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size,C,H,W = x.shape\n",
    "        x = x.reshape(-1, C, H, W)\n",
    "        x_m =torch.split(x,H//2,dim=-1)[0]\n",
    "\n",
    "        # print(x_m.shape)\n",
    "        x_a =torch.split(x,H//2,dim=-1)[1]\n",
    "        features=[]\n",
    "        def hook(module, input, output):\n",
    "            features.append(input)\n",
    "            return None\n",
    "        # x = (x - self.mean) / self.std\n",
    "        self.encoder_q.conv_head.register_forward_hook(hook)\n",
    "        self.encoder_q.blocks[5].register_forward_hook(hook)\n",
    "        self.encoder_q.blocks[6].register_forward_hook(hook)\n",
    "        \n",
    "        \n",
    "        # compute query features\n",
    "        q_m = self.encoder_q(x_m)  # queries: NxC\n",
    "        q_a = self.encoder_q(x_a)  # queries: NxC\n",
    "        \n",
    "        # print(features[0][2].shape)\n",
    "        # print(features[1][2].shape)\n",
    "        attn= self.att(features[2][0],features[5][0])\n",
    "        \n",
    "        q_m = nn.functional.normalize(q_m, dim=1)\n",
    "        q_a = nn.functional.normalize(q_a, dim=1)\n",
    "        \n",
    "        last = torch.cat([q_a,q_m,attn],-1)\n",
    "        last = self.mlp(last)\n",
    "        cancer = self.cancer(last).reshape(-1)\n",
    "        cancer = torch.sigmoid(cancer)\n",
    "        q_m = self.encoder_q.fc(q_m)\n",
    "        q_a = self.encoder_q.fc(q_a)\n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()  # update the key encoder\n",
    "            k_m = self.encoder_k(x_m)  # keys: NxC\n",
    "            k_m = nn.functional.normalize(k_m, dim=1)\n",
    "            k_m = self.encoder_k.fc(k_m) \n",
    "            k_a = self.encoder_k(x_a)  # keys: NxC\n",
    "            k_a = nn.functional.normalize(k_a, dim=1)\n",
    "            k_a = self.encoder_k.fc(k_a)\n",
    "\n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        l_pos1 = torch.einsum(\"nc,nc->n\", [q_m, k_m]).unsqueeze(-1)\n",
    "        l_pos2 = torch.einsum(\"nc,nc->n\", [q_m, k_a]).unsqueeze(-1)\n",
    "        l_pos3 = torch.einsum(\"nc,nc->n\", [q_a, k_m]).unsqueeze(-1)\n",
    "        l_pos4 = torch.einsum(\"nc,nc->n\", [q_a, k_a]).unsqueeze(-1)\n",
    "        # negative logits: NxK\n",
    "        l_neg_m = torch.einsum(\"nc,ck->nk\", [q_m, self.queue.clone().detach()])\n",
    "        l_neg_a = torch.einsum(\"nc,ck->nk\", [q_a, self.queue.clone().detach()])\n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos1,l_pos2,l_pos3,l_pos4, l_neg_m,l_neg_a], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[1], dtype=torch.long).cuda()\n",
    "        labels[1],labels[2],labels[3]=1,2,3\n",
    "        \n",
    "        \n",
    "        # dequeue and enqueue\n",
    "        self._dequeue_and_enqueue(k_m)\n",
    "        self._dequeue_and_enqueue(k_a)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return cancer,logits,labels,features,attn\n",
    "        # return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf8e2bf-7a25-4569-b76d-363f33838e8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1c930-3962-4cae-8f60-2869e6434794",
   "metadata": {},
   "source": [
    "## 辅助损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3990f7f4-6c83-4086-aa83-8a0abfcdbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_similiarity(x1,x2):#features[0/1/2][0],features[3/4/5][0]\n",
    "    p12 = (x1*x2).sum(-1)\n",
    "    p1 = torch.sqrt((x1*x1).sum(-1))\n",
    "    p2 = torch.sqrt((x2*x2).sum(-1))\n",
    "    s = sum(nn.Flatten()(p12/(p1*p2+1e-6)))/2\n",
    "    s = s.sum()/len(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31384a16-c887-44d8-89ff-8a1da7bfe598",
   "metadata": {},
   "source": [
    "# 相似度损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5026056-6ddf-4226-ba1c-dc5eb69dff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similiarity(x):#features[0/1/2][0],features[3/4/5][0]\n",
    "    x1 = torch.split(x,len(x)//2,dim=-1)[0]\n",
    "    x2 = torch.split(x,len(x)//2,dim=-1)[1]\n",
    "    p12 = (x1*x2).sum(-1)\n",
    "    p1 = torch.sqrt((x1*x1).sum(-1))\n",
    "    p2 = torch.sqrt((x2*x2).sum(-1))\n",
    "    s = p12/(p1*p2+1e-6)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd959f63-b4e2-4a0d-a286-6105c7b5562b",
   "metadata": {},
   "source": [
    "## 对比学习损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f14b4025-5be0-455f-abbc-3c1fcfc227d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def infoNCE():\n",
    "#     criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "# NEC_loss = criterion(output, target)#logits,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca982bc9-433e-4013-a119-a500a02e5b28",
   "metadata": {},
   "source": [
    "## 损失函数比例待定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7efb27d-5e90-492b-a86d-3f7b0adbad97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class_criterion = nn.BCEWithLogitsLoss().cuda(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc35ebc-39aa-4a86-ab10-8aae3a62f203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b7280ad-e651-40b8-89d2-8cf250b4fb91",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f216827-2ccf-485c-9230-2a998464bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RASampler(torch.utils.data.Sampler):\n",
    "    \"\"\"Sampler that restricts data loading to a subset of the dataset for distributed,\n",
    "    with repeated augmentation.\n",
    "    It ensures that different each augmented version of a sample will be visible to a\n",
    "    different process (GPU)\n",
    "    Heavily based on torch.utils.data.DistributedSampler\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, num_replicas=None, rank=None, shuffle=True):\n",
    "        if num_replicas is None:\n",
    "            if not dist.is_available():\n",
    "                raise RuntimeError(\"Requires distributed package to be available\")\n",
    "            num_replicas = dist.get_world_size()\n",
    "        if rank is None:\n",
    "            if not dist.is_available():\n",
    "                raise RuntimeError(\"Requires distributed package to be available\")\n",
    "            rank = dist.get_rank()\n",
    "        self.dataset = dataset\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "        self.epoch = 0\n",
    "        self.num_samples = int(math.ceil(len(self.dataset) * 3.0 / self.num_replicas))\n",
    "        self.total_size = self.num_samples * self.num_replicas\n",
    "        # self.num_selected_samples = int(math.ceil(len(self.dataset) / self.num_replicas))\n",
    "        self.num_selected_samples = int(math.floor(len(self.dataset) // 256 * 256 / self.num_replicas))\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        # deterministically shuffle based on epoch\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(self.epoch)\n",
    "        if self.shuffle:\n",
    "            indices = torch.randperm(len(self.dataset), generator=g).tolist()\n",
    "        else:\n",
    "            indices = list(range(len(self.dataset)))\n",
    "\n",
    "        # add extra samples to make it evenly divisible\n",
    "        indices = [ele for ele in indices for i in range(3)]\n",
    "        indices += indices[:(self.total_size - len(indices))]\n",
    "        assert len(indices) == self.total_size\n",
    "\n",
    "        # subsample\n",
    "        indices = indices[self.rank:self.total_size:self.num_replicas]\n",
    "        assert len(indices) == self.num_samples\n",
    "\n",
    "        return iter(indices[:self.num_selected_samples])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_selected_samples\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dbfa2d-b624-4e00-bbce-278d2920bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedRandomSamplerDDP(DistributedSampler):\n",
    "    r\"\"\"Samples elements from ``[0,..,len(weights)-1]`` with given probabilities (weights).\n",
    "\n",
    "    Args:\n",
    "        data_set: Dataset used for sampling.\n",
    "        weights (sequence)   : a sequence of weights, not necessary summing up to one\n",
    "        num_replicas (int, optional): Number of processes participating in\n",
    "            distributed training. By default, :attr:`world_size` is retrieved from the\n",
    "            current distributed group.\n",
    "        rank (int, optional): Rank of the current process within :attr:`num_replicas`.\n",
    "            By default, :attr:`rank` is retrieved from the current distributed\n",
    "            group.\n",
    "        num_samples (int): number of samples to draw\n",
    "        replacement (bool): if ``True``, samples are drawn with replacement.\n",
    "            If not, they are drawn without replacement, which means that when a\n",
    "            sample index is drawn for a row, it cannot be drawn again for that row.\n",
    "        generator (Generator): Generator used in sampling.\n",
    "    \"\"\"\n",
    "    # weights: Tensor\n",
    "    # num_samples: int\n",
    "    # replacement: bool\n",
    "\n",
    "    def __init__(self, data_set, weights: Sequence[float], num_replicas: int, rank: int,\n",
    "                 replacement: bool = True, generator=None) -> None:\n",
    "        super(WeightedRandomSamplerDDP, self).__init__(data_set, num_replicas, rank)\n",
    "        if not isinstance(num_samples, int) or isinstance(num_samples, bool) or \\\n",
    "                num_samples <= 0:\n",
    "            raise ValueError(\"num_samples should be a positive integer \"\n",
    "                             \"value, but got num_samples={}\".format(num_samples))\n",
    "        if not isinstance(replacement, bool):\n",
    "            raise ValueError(\"replacement should be a boolean value, but got \"\n",
    "                             \"replacement={}\".format(replacement))\n",
    "        self.weights = torch.as_tensor(weights, dtype=torch.double)\n",
    "        self.num_samples = int(math.ceil(len(self.dataset) * 3.0 / self.num_replicas))\n",
    "        self.replacement = replacement\n",
    "        self.generator = generator\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "        self.weights = self.weights[self.rank::self.num_replicas]\n",
    "        self.num_samples = self.num_samples // self.num_replicas\n",
    "\n",
    "    def __iter__(self):\n",
    "        rand_tensor = torch.multinomial(self.weights, self.num_samples, self.replacement, generator=self.generator)\n",
    "        rand_tensor =  self.rank + rand_tensor * self.num_replicas\n",
    "        return iter(rand_tensor.tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47748770-236e-46ef-b6bf-9fb93284c416",
   "metadata": {},
   "source": [
    "# train_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c288fb-8138-4998-b1a9-c25dd7b40559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    init_distributed_mode(args)\n",
    "    print(args)\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    # fix the seed for reproducibility\n",
    "    seed = args.seed + get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    dataset_train, args.nb_classes = build_dataset(is_train=True, args=args)\n",
    "    dataset_val, _ = build_dataset(is_train=False, args=args)\n",
    "    tmp = build_weight(args.data_path)\n",
    "    if args.distributed:\n",
    "        num_tasks = get_world_size()\n",
    "        global_rank = get_rank()\n",
    "        if args.repeated_aug:\n",
    "            sampler_train = WeightedRandomSamplerDDP(\n",
    "                dataset_train, tmp ,num_replicas=num_tasks, rank=global_rank, shuffle=True\n",
    "            )\n",
    "        else:\n",
    "            sampler_train = torch.utils.data.DistributedSampler(\n",
    "                dataset_train, num_replicas=num_tasks, rank=global_rank, shuffle=True\n",
    "            )\n",
    "        if args.dist_eval:\n",
    "            if len(dataset_val) % num_tasks != 0:\n",
    "                print('Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. '\n",
    "                      'This will slightly alter validation results as extra duplicate entries are added to achieve '\n",
    "                      'equal num of samples per-process.')\n",
    "            sampler_val = torch.utils.data.DistributedSampler(\n",
    "                dataset_val, num_replicas=num_tasks, rank=global_rank, shuffle=False)\n",
    "        else:\n",
    "            sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "    else:\n",
    "        \n",
    "        sampler_train = torch.utils.data.WeightedRandomSampler(tmp,args.nb_classes*len(dataset_train))\n",
    "        sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, sampler=sampler_train,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val, sampler=sampler_val,\n",
    "        batch_size=250,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=False\n",
    "    )\n",
    "    # 细粒度分类不需要\n",
    "    # mixup_fn = None\n",
    "    # mixup_active = args.mixup > 0 or args.cutmix > 0. or args.cutmix_minmax is not None\n",
    "    # if mixup_active:\n",
    "    #     mixup_fn = Mixup(\n",
    "    #         mixup_alpha=args.mixup, cutmix_alpha=args.cutmix, cutmix_minmax=args.cutmix_minmax,\n",
    "    #         prob=args.mixup_prob, switch_prob=args.mixup_switch_prob, mode=args.mixup_mode,\n",
    "    #         label_smoothing=args.smoothing, num_classes=args.nb_classes)\n",
    "\n",
    "    print(f\"Creating model: {args.model}\")\n",
    "    model = basNet()\n",
    "\n",
    "    if not args.distributed or args.rank == 0:\n",
    "        print(model)\n",
    "        input_tensor = torch.zeros((1, 3, 224, 224), dtype=torch.float32)\n",
    "        model.eval()\n",
    "        cal_flops_params_with_fvcore(model, input_tensor)\n",
    "\n",
    "    model.to(device)\n",
    "    model_ema = None\n",
    "\n",
    "\n",
    "    if args.distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], find_unused_parameters=False)\n",
    "        model_without_ddp = model.module\n",
    "    else:\n",
    "        model_without_ddp = model\n",
    "\n",
    "    linear_scaled_lr = args.lr * args.batch_size * get_world_size() / 512.0\n",
    "\n",
    "    args.lr = linear_scaled_lr\n",
    "    optimizer = create_optimizer(args, model_without_ddp)\n",
    "\n",
    "    loss_scaler = NativeScaler()\n",
    "\n",
    "    lr_scheduler, _ = create_scheduler(args, optimizer)\n",
    "\n",
    "    class_criterion = nn.BCEWithLogitsLoss().cuda(args.gpu)\n",
    "    NCE_criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "    if not args.output_dir:\n",
    "        args.output_dir = args.model\n",
    "        if is_main_process():\n",
    "            import os\n",
    "            if not os.path.exists(args.model):\n",
    "                os.mkdir(args.model)\n",
    "\n",
    "    output_dir = Path(args.output_dir)\n",
    "    if args.resume:\n",
    "        if args.resume.startswith('https'):\n",
    "            checkpoint = torch.hub.load_state_dict_from_url(\n",
    "                args.resume, map_location='cpu', check_hash=True)\n",
    "        else:\n",
    "            checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "        if 'model' in checkpoint:\n",
    "            model_without_ddp.load_state_dict(checkpoint['model'])\n",
    "        else:\n",
    "            model_without_ddp.load_state_dict(checkpoint)\n",
    "        if not args.finetune:\n",
    "            if not args.eval and 'optimizer' in checkpoint and 'lr_scheduler' in checkpoint and 'epoch' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "                lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "                if not args.finetune:\n",
    "                    args.start_epoch = checkpoint['epoch'] + 1\n",
    "                if 'scaler' in checkpoint:\n",
    "                    loss_scaler.load_state_dict(checkpoint['scaler'])\n",
    "\n",
    "    if args.eval:\n",
    "        if hasattr(model.module, \"merge_bn\"):\n",
    "            print(\"Merge pre bn to speedup inference.\")\n",
    "            model.module.merge_bn()\n",
    "        test_stats = evaluate(data_loader_val, model, device)\n",
    "        print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n",
    "        return\n",
    "\n",
    "    if args.throughout:\n",
    "        from logger import create_logger\n",
    "        logger = create_logger(output_dir=output_dir, dist_rank=get_rank(), name=args.model)\n",
    "        throughput(data_loader_val, model, logger)\n",
    "        return\n",
    "\n",
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "    start_time = time.time()\n",
    "    max_accuracy = 0.0\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            data_loader_train.sampler.set_epoch(epoch)\n",
    "\n",
    "        train_stats = train_one_epoch(\n",
    "            model, class_criterion,nce_criterion, data_loader_train,\n",
    "            optimizer, device, epoch, loss_scaler,\n",
    "            args.clip_grad, model_ema, mixup_fn,\n",
    "            set_training_mode=True,\n",
    "        )\n",
    "\n",
    "        lr_scheduler.step(epoch)\n",
    "        if args.output_dir:\n",
    "            checkpoint_paths = [output_dir / 'checkpoint.pth']\n",
    "            for checkpoint_path in checkpoint_paths:\n",
    "                save_on_master({\n",
    "                    'model': model_without_ddp.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'scaler': loss_scaler.state_dict(),\n",
    "                    'args': args,\n",
    "                }, checkpoint_path)\n",
    "\n",
    "        test_stats = evaluate(data_loader_val, model, device)\n",
    "        print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n",
    "        if test_stats[\"acc1\"] > max_accuracy:\n",
    "            if args.output_dir:\n",
    "                checkpoint_paths = [output_dir / 'checkpoint_best.pth']\n",
    "                for checkpoint_path in checkpoint_paths:\n",
    "                    save_on_master({\n",
    "                        'model': model_without_ddp.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                        'epoch': epoch,\n",
    "                        'args': args,\n",
    "                    }, checkpoint_path)\n",
    "        max_accuracy = max(max_accuracy, test_stats[\"acc1\"])\n",
    "        print(f'Max accuracy: {max_accuracy:.2f}%')\n",
    "\n",
    "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                     **{f'test_{k}': v for k, v in test_stats.items()},\n",
    "                     'epoch': epoch}\n",
    "\n",
    "        if args.output_dir and is_main_process():\n",
    "            with (output_dir / \"log.txt\").open(\"a\") as f:\n",
    "                f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7c7ccdc-26dc-4105-9390-b5acd60d5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Next-ViT training and evaluation script', add_help=False)\n",
    "    parser.add_argument('--batch-size', default=16, type=int)\n",
    "    parser.add_argument('--epochs', default=300, type=int)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--model', default='pvt_small', type=str, metavar='MODEL',\n",
    "                        help='Name of model to train')\n",
    "    parser.add_argument('--input-size', default=2048, type=int, help='images input size')\n",
    "\n",
    "    parser.add_argument('--drop', type=float, default=0.0, metavar='PCT',\n",
    "                        help='Dropout rate (default: 0.)')\n",
    "    parser.add_argument('--drop-path', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "    parser.add_argument('--flops', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--opt', default='adamw', type=str, metavar='OPTIMIZER',\n",
    "                        help='Optimizer (default: \"adamw\"')\n",
    "    parser.add_argument('--opt-eps', default=1e-8, type=float, metavar='EPSILON',\n",
    "                        help='Optimizer Epsilon (default: 1e-8)')\n",
    "    parser.add_argument('--opt-betas', default=None, type=float, nargs='+', metavar='BETA',\n",
    "                        help='Optimizer Betas (default: None, use opt default)')\n",
    "    parser.add_argument('--clip-grad', type=float, default=5, metavar='NORM',\n",
    "                        help='Clip gradient norm (default: None, no clipping)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                        help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--weight-decay', type=float, default=0.05,\n",
    "                        help='weight decay (default: 0.05)')\n",
    "    # Learning rate schedule parameters\n",
    "    parser.add_argument('--sched', default='sched', type=str, metavar='SCHEDULER',\n",
    "                        help='LR scheduler (default: \"cosine\"')\n",
    "    parser.add_argument('--lr', type=float, default=5e-6, metavar='LR',\n",
    "                        help='learning rate (default: 5e-4)')\n",
    "    parser.add_argument('--lr-noise', type=float, nargs='+', default=None, metavar='pct, pct',\n",
    "                        help='learning rate noise on/off epoch percentages')\n",
    "    parser.add_argument('--lr-noise-pct', type=float, default=0.67, metavar='PERCENT',\n",
    "                        help='learning rate noise limit percent (default: 0.67)')\n",
    "    parser.add_argument('--lr-noise-std', type=float, default=1.0, metavar='STDDEV',\n",
    "                        help='learning rate noise std-dev (default: 1.0)')\n",
    "    parser.add_argument('--warmup-lr', type=float, default=1e-6, metavar='LR',\n",
    "                        help='warmup learning rate (default: 1e-6)')\n",
    "    parser.add_argument('--min-lr', type=float, default=1e-5, metavar='LR',\n",
    "                        help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')\n",
    "\n",
    "    parser.add_argument('--decay-epochs', type=float, default=40, metavar='N',\n",
    "                        help='epoch interval to decay LR')\n",
    "    parser.add_argument('--warmup-epochs', type=int, default=10, metavar='N',\n",
    "                        help='epochs to warmup LR, if scheduler supports')\n",
    "    parser.add_argument('--cooldown-epochs', type=int, default=10, metavar='N',\n",
    "                        help='epochs to cooldown LR at min_lr, after cyclic schedule ends')\n",
    "    parser.add_argument('--patience-epochs', type=int, default=10, metavar='N',\n",
    "                        help='patience epochs for Plateau LR scheduler (default: 10')\n",
    "    parser.add_argument('--decay-rate', '--dr', type=float, default=0.1, metavar='RATE',\n",
    "                        help='LR decay rate (default: 0.1)')\n",
    "\n",
    "    # Augmentation parameters\n",
    "    parser.add_argument('--color-jitter', type=float, default=0.4, metavar='PCT',\n",
    "                        help='Color jitter factor (default: 0.4)')\n",
    "    parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                        help='Use AutoAugment policy. \"v0\" or \"original\". \" + \\\n",
    "                             \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "    parser.add_argument('--smoothing', type=float, default=0.1, help='Label smoothing (default: 0.1)')\n",
    "    parser.add_argument('--train-interpolation', type=str, default='bicubic',\n",
    "                        help='Training interpolation (random, bilinear, bicubic default: \"bicubic\")')\n",
    "\n",
    "    parser.add_argument('--repeated-aug', action='store_true')\n",
    "    parser.add_argument('--no-repeated-aug', action='store_false', dest='repeated_aug')\n",
    "    parser.set_defaults(repeated_aug=False)\n",
    "\n",
    "    # * Random Erase params\n",
    "    parser.add_argument('--reprob', type=float, default=0.25, metavar='PCT',\n",
    "                        help='Random erase prob (default: 0.25)')\n",
    "    parser.add_argument('--remode', type=str, default='pixel',\n",
    "                        help='Random erase mode (default: \"pixel\")')\n",
    "    parser.add_argument('--recount', type=int, default=1,\n",
    "                        help='Random erase count (default: 1)')\n",
    "    parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                        help='Do not random erase first (clean) augmentation split')\n",
    "\n",
    "    # * Mixup params\n",
    "    parser.add_argument('--mixup', type=float, default=0.8,\n",
    "                        help='mixup alpha, mixup enabled if > 0. (default: 0.8)')\n",
    "    parser.add_argument('--cutmix', type=float, default=1.0,\n",
    "                        help='cutmix alpha, cutmix enabled if > 0. (default: 1.0)')\n",
    "    parser.add_argument('--cutmix-minmax', type=float, nargs='+', default=None,\n",
    "                        help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "    parser.add_argument('--mixup-prob', type=float, default=1.0,\n",
    "                        help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "    parser.add_argument('--mixup-switch-prob', type=float, default=0.5,\n",
    "                        help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "    parser.add_argument('--mixup-mode', type=str, default='batch',\n",
    "                        help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "\n",
    "    # * Finetuning params\n",
    "    parser.add_argument('--finetune', action='store_true', help='Perform finetune.')\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--data-path', default='../../datasets/imagenet_full_size/061417/', type=str,\n",
    "                        help='dataset path')\n",
    "    parser.add_argument('--data-set', default='IMNET', choices=['CIFAR', 'IMNET', 'INAT', 'INAT19'],\n",
    "                        type=str, help='Image Net dataset path')\n",
    "    parser.add_argument('--use-mcloader', action='store_true', default=False, help='Use mcloader')\n",
    "    parser.add_argument('--inat-category', default='name',\n",
    "                        choices=['kingdom', 'phylum', 'class', 'order', 'supercategory', 'family', 'genus', 'name'],\n",
    "                        type=str, help='semantic granularity')\n",
    "\n",
    "    parser.add_argument('--output-dir', default='../../outputdir',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--resume', default='./nextvit_small_in1k6m_384.pth', help='resume from checkpoint')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
    "    parser.add_argument('--dist-eval', action='store_true', default=False, help='Enabling distributed evaluation')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--pin-mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.add_argument('--no-pin-mem', action='store_false', dest='pin_mem',\n",
    "                        help='')\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')\n",
    "\n",
    "    # test throught\n",
    "    parser.add_argument('--throughout', action='store_true', help='Perform throughout only')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a226a29-acde-47fa-8741-2a3ecaf8d41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
