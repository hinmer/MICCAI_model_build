{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c04481-c806-4c79-b704-e62238be883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import gc\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from functools import lru_cache\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import timm\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.distributed as dist\n",
    "from torch import nn, einsum\n",
    "from torch.nn import functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "from typing import Iterable, Optional\n",
    "from timm.models import create_model\n",
    "from timm.optim import create_optimizer\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.data import Mixup,create_transform\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.utils import accuracy, ModelEma,NativeScaler, get_state_dict, ModelEma\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader\n",
    "\n",
    "from functools import partial\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204c2ee4-840d-45dc-b0cb-0c3ed480d6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934a6cfd-9140-44fd-a894-1b13cb21f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basNet(nn.Module):\n",
    "    \"\"\"\n",
    "    only two viwe\n",
    "    \"\"\"\n",
    "    def load_pretrain(self, ):\n",
    "        return\n",
    "\n",
    "    def __init__(self,):\n",
    "        super(basNet, self).__init__()\n",
    "        # self.output_type = ['inference', 'loss']\n",
    "\n",
    "\n",
    "        self.backbone =timm.create_model ('efficientnetv2_m',\n",
    "                                          pretrained=False, \n",
    "                                          drop_rate = 0.2, \n",
    "                                          drop_path_rate = 0.1,\n",
    "                                          num_classes=512\n",
    "                                         )\n",
    "\n",
    "        # dim = 1280\n",
    "\n",
    "        # self.lc  = LocalCoccurrence(dim)\n",
    "        # self.gl  = GlobalConsistency(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 128),\n",
    "        )#<todo> mlp needs to be deep if backbone is strong?\n",
    "        self.cancer = nn.Linear(128,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = batch['image']\n",
    "        batch_size,C,H,W = x.shape\n",
    "        x = x.reshape(-1, C, H, W)\n",
    "        x_m =torch.tensor( np.array_split(batch,2,axis=3)[0])\n",
    "\n",
    "        # print(x_m.shape)\n",
    "        x_a = torch.tensor( np.array_split(batch,2,axis=3)[1])\n",
    "        x_m = self.backbone(x_m)\n",
    "        x_a = self.backbone(x_a)\n",
    "        last = torch.cat([x_m, x_a ],-1)\n",
    "        last = self.mlp(last)\n",
    "        cancer = self.cancer(last).reshape(-1)\n",
    "\n",
    "        return torch.sigmoid(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0d6728-fe64-4df4-ac64-05afa2112a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = np.random.random(size=(1,3,1024,1024))\n",
    "batch = torch.tensor( batch).to(device).to(torch.float32)\n",
    "batch_size,C,H,W = batch.shape\n",
    "x = batch.reshape(-1, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f241e6-6ef7-44c7-b7cf-d2ecaa0ba804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1024, 1024])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f03b7f-1132-4190-bbc8-7534fc5fb8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b361fc63-68c1-47ce-8800-5e19e7e35074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29220/2473585480.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_m =torch.tensor( np.array_split(batch,2,axis=3)[0])\n",
      "/tmp/ipykernel_29220/2473585480.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_a = torch.tensor( np.array_split(batch,2,axis=3)[1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b39feb-40fb-4b16-94b1-74ac360befa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
