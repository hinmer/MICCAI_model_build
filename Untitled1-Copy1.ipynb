{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "279f1c93-42f7-4332-bd1e-afef40673886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#time:      2023-02-12\n",
    "#by :       wangzhonging\n",
    "#source :   MICCAI\n",
    "#code:      some code Modify on nextVIT&&swinT&&moco\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961d8583-5a2d-415b-bc5f-5f5450879dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import gc\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from functools import lru_cache\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import timm\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.distributed as dist\n",
    "from torch import nn, einsum\n",
    "from torch.nn import functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "from typing import Iterable, Optional\n",
    "from timm.models import create_model\n",
    "from timm.optim import create_optimizer\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.data import Mixup,create_transform\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.utils import accuracy, ModelEma,NativeScaler, get_state_dict, ModelEma\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader\n",
    "\n",
    "from functools import partial\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f2148e-2077-4a85-b04c-bc440be902b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634a571-9f36-487c-b748-86be06f75a69",
   "metadata": {
    "tags": []
   },
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe5e8e79-cd4e-4573-88d3-ace7145f9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors.\n",
    "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "    \"\"\"\n",
    "    tensors_gather = [\n",
    "        torch.ones_like(tensor) for _ in range(torch.distributed.get_world_size())\n",
    "    ]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe4f37-c8bc-4169-b8b6-560257978a25",
   "metadata": {},
   "source": [
    "# build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589f8ab-1724-452c-99c3-50cf9e8bfba7",
   "metadata": {},
   "source": [
    "## embeding patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b826bf-d9bd-4f07-8845-ba2d975f7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORM_EPS = 1e-5\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride=1,\n",
    "                 mode = \"V\"\n",
    "                ):\n",
    "        super(PatchEmbed, self).__init__()\n",
    "        norm_layer = partial(nn.BatchNorm2d, eps=NORM_EPS)\n",
    "        if stride == 4 and mode == \"V\":\n",
    "            self.avgpool = nn.AvgPool2d((4, 32), stride=4, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif stride == 2 and mode == \"V\":\n",
    "            self.avgpool = nn.AvgPool2d((2, 16), stride=2, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif stride == 2 and mode == \"H\":\n",
    "            self.avgpool = nn.AvgPool2d((64, 2), stride=2, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif stride == 1 and mode == \"H\":\n",
    "            self.avgpool = nn.AvgPool2d((32, 1), stride=1, ceil_mode=True, count_include_pad=False)\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        elif in_channels != out_channels:\n",
    "            self.avgpool = nn.Identity()\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "            self.norm = norm_layer(out_channels)\n",
    "        else:\n",
    "            self.avgpool = nn.Identity()\n",
    "            self.conv = nn.Identity()\n",
    "            self.norm = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.norm(self.conv(self.avgpool(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b104c2-b3fc-4acd-813b-c2550b992a47",
   "metadata": {},
   "source": [
    "## product QKV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8370b866-e1c1-4428-852b-6ba3ea8dbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_PQKV(nn.Module):\n",
    "    \"\"\"\n",
    "    product QKV\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, head_dim=32, out_dim=None, qkv_bias=True, qk_scale=None,\n",
    "                 attn_drop=0, proj_drop=0., sr_ratio=1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.out_dim = out_dim if out_dim is not None else dim\n",
    "        self.num_heads = self.dim // head_dim\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.q = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.k = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "        self.v = nn.Linear(dim, self.dim, bias=qkv_bias)\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        q = self.q(x)\n",
    "        q = q.reshape(B, N, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "        k = self.k(x)\n",
    "        k = k.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 3, 1)\n",
    "        v = self.v(x)\n",
    "        v = v.reshape(B, -1, self.num_heads, int(C // self.num_heads)).permute(0, 2, 1, 3)\n",
    "        return q,k,v\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d60368e-13cc-4e04-b27a-d60398b0162a",
   "metadata": {},
   "source": [
    "## Efficient Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d738c557-a6bb-4c78-a8e2-b461c12d0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_MHA(nn.Module):\n",
    "    \"\"\"\n",
    "    Efficient Multi-Head Self Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, head_dim=32, qk_scale=None,attn_drop=0):\n",
    "        super().__init__()\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "    def forward(self, q,k,v,b,n,c):\n",
    "        attn = (q @ k) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        attn = (attn @ v).transpose(1, 2).reshape(b,n,c)\n",
    "        return attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48a359-ee0f-47ec-af20-2ccc9133d701",
   "metadata": {},
   "source": [
    "## Efficient cross attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e7aece8-a743-4923-aa4c-29b50805ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class E_CA(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Efficient cross attention\n",
    "#     \"\"\"\n",
    "#     def __init__(self, head_dim=32,qk_scale=None):\n",
    "#         super().__init__()\n",
    "#         self.scale = qk_scale or head_dim ** -0.5\n",
    "#         self.attn_drop = nn.Dropout(attn_drop)\n",
    "#     def forward(self, q,k,v,b,n,c):\n",
    "#         attn = (q @ k) * self.scale\n",
    "#         attn = attn.softmax(dim=-1)\n",
    "#         attn = self.attn_drop(attn)\n",
    "#         attn = (attn @ v).transpose(1, 2).reshape(b,n,c)\n",
    "#         return attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed9995-0d98-433b-bf28-ce05866e56a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP and res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd29205-1e69-404b-8b7b-d60871591551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1= x \n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        x+=x1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c0be1-a5df-4d2c-b1c4-4fae48121ced",
   "metadata": {},
   "source": [
    "## Efficient Multi-Head Double-Viwe Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c141bdaf-e325-4897-b1c1-e9325df74400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E_MTDVA(nn.Module):\n",
    "    \"\"\"\n",
    "    Efficient Multi-Head Double-Viwe Attention\n",
    "    x_mh,x_ah,x_mv,x_av->forward\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, head_dim=32, out_dim=None, qkv_bias=True, qk_scale=None,\n",
    "                 attn_drop=0, proj_drop=0., sr_ratio=1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.out_dim = out_dim if out_dim is not None else dim\n",
    "        self.num_heads = self.dim // head_dim\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.qkv = E_PQKV( dim, head_dim, out_dim, qkv_bias, qk_scale,attn_drop, proj_drop, sr_ratio)\n",
    "        self.sa = E_MHA(head_dim,qk_scale,attn_drop)\n",
    "        self.ca = E_MHA(head_dim,qk_scale,attn_drop)\n",
    "        self.proj = Mlp(self.dim,self.dim*4, self.out_dim)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.sr_ratio = sr_ratio\n",
    "        self.N_ratio = sr_ratio ** 2\n",
    "        if sr_ratio > 1:\n",
    "            self.sr = nn.AvgPool1d(kernel_size=self.N_ratio, stride=self.N_ratio)\n",
    "            self.norm = nn.BatchNorm1d(dim, eps=NORM_EPS)\n",
    "        self.is_bn_merged = False\n",
    "\n",
    "    def merge_bn(self, pre_bn):\n",
    "        merge_pre_bn(self.q, pre_bn)\n",
    "        if self.sr_ratio > 1:\n",
    "            merge_pre_bn(self.k, pre_bn, self.norm)\n",
    "            merge_pre_bn(self.v, pre_bn, self.norm)\n",
    "        else:\n",
    "            merge_pre_bn(self.k, pre_bn)\n",
    "            merge_pre_bn(self.v, pre_bn)\n",
    "        self.is_bn_merged = True\n",
    "    # def pro_pkv(x_mh)\n",
    "\n",
    "    def forward(self, x_mh,x_ah,x_mv,x_av):\n",
    "        \n",
    "        h = torch.cat([x_mh,x_ah],dim = 1)\n",
    "        v = torch.cat([x_mv,x_av],dim = 1)\n",
    "        B, N, C = h.shape\n",
    "        #selfatt\n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        q_h,k_h,v_h = self.qkv(h)\n",
    "        q_v,k_v,v_v = self.qkv(v)\n",
    "        attn_h = self.sa(q_h,k_h,v_h, B, N, C)\n",
    "        attn_v = self.sa(q_v,k_v,v_v, B, N, C)\n",
    "        h+=attn_h\n",
    "        v+=attn_v\n",
    "        \n",
    "        ##ffn\n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        h = self.proj(h)\n",
    "        v = self.proj(v)\n",
    "        #crossatt\n",
    "        \n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        q_h,k_h,v_h = self.qkv(h)\n",
    "        q_v,k_v,v_v = self.qkv(v)\n",
    "        attn_h = self.sa(q_h,k_h,v_h, B, N, C)\n",
    "        attn_v = self.sa(q_v,k_v,v_v, B, N, C)\n",
    "        h+=attn_h\n",
    "        v+=attn_v\n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        q_h,k_h,v_h = self.qkv(h)\n",
    "        q_v,k_v,v_v = self.qkv(v)\n",
    "        attn_h=self.ca(q_h,k_v,v_h, B, N, C)\n",
    "        attn_v=self.ca(q_h,k_v,v_h, B, N, C)\n",
    "        h+=attn_h\n",
    "        v+=attn_v\n",
    "        ##ffn\n",
    "        h = self.norm(h)\n",
    "        v = self.norm(v)\n",
    "        h = self.proj(h)\n",
    "        v = self.proj(v)\n",
    "        #output\n",
    "        attn_h = h.mean(1)\n",
    "        attn_v = v.mean(1)\n",
    "        x = torch.concat([attn_h,attn_v],dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c25c13-24ea-4c3a-b82b-73543e00ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShardExamine(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 out_putdim,\n",
    "                 num_head=64, \n",
    "                 qkv_bias=False, \n",
    "                 attn_drop=0.1, \n",
    "                 proj_drop=0.1,\n",
    "                 stride=1\n",
    "                ):\n",
    "        super().__init__()\n",
    "        # super(LocalCoccurrence, self).__init__()\n",
    "        self.PEV = PatchEmbed(in_channels,out_channels,stride*2,mode = \"V\")\n",
    "        self.PEH = PatchEmbed(in_channels,out_channels,stride,mode = \"H\")\n",
    "        self.proj = nn.Linear(out_channels*2, out_putdim)\n",
    "        self.attn  = E_MTDVA(dim,num_head,None,True,qkv_bias,attn_drop,proj_drop)\n",
    "\n",
    "    def forward(self, u_m, u_a):\n",
    "        u_mv = self.PEV(u_m)\n",
    "        u_av = self.PEV(u_a)\n",
    "        u_m = self.PEH(u_m)\n",
    "        u_a = self.PEH(u_a)\n",
    "        B,C,H,W = u_mv.shape\n",
    "        L = H*W\n",
    "        dim = C\n",
    "\n",
    "        u_mv = u_mv.reshape(B,dim,L).permute(0,2,1)\n",
    "        u_av = u_av.reshape(B,dim,L).permute(0,2,1)\n",
    "        u_m  = u_m.reshape(B,dim,L).permute(0,2,1)\n",
    "        u_a  = u_a.reshape(B,dim,L).permute(0,2,1)\n",
    "\n",
    "\n",
    "        x = self.attn(u_m, u_a,u_mv, u_av)# x_mh,x_ah,x_mv,x_av\n",
    "        # x_m, x_a = self.attn(u_m, u_a)\n",
    "        # x_mv, x_av = self.attn(u_mv, u_a)\n",
    "        # gap_m = x_m.mean(1)\n",
    "        # x = x.mean(1)\n",
    "        x = self.proj(x)\n",
    "        \n",
    "        return  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18be5931-f411-40ee-aacd-2b1ee183de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basNet(nn.Module):\n",
    "    \"\"\"\n",
    "    only two viwe\n",
    "    \"\"\"\n",
    "    def load_pretrain(self, ):\n",
    "        return\n",
    "\n",
    "    def __init__(self,K=8192, m=0.999, T=0.07,dim=128,nc=512):\n",
    "        super(basNet, self).__init__()\n",
    "        # self.output_type = ['inference', 'loss']\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.encoder_q = timm.create_model ('efficientnetv2_m',#m 512 s 256\n",
    "                                          pretrained=False, \n",
    "                                          drop_rate = 0.2, \n",
    "                                          drop_path_rate = 0.1,\n",
    "                                          num_classes=nc\n",
    "                                         )\n",
    "        self.encoder_k = timm.create_model ('efficientnetv2_m',\n",
    "                                          pretrained=False, \n",
    "                                          drop_rate = 0.2, \n",
    "                                          drop_path_rate = 0.1,\n",
    "                                          num_classes=nc\n",
    "                                         )\n",
    "        \n",
    "        \n",
    "        # dim_mlp = self.encoder_q.fc.weight.shape[1]\n",
    "        self.encoder_q.fc = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 128),\n",
    "        )\n",
    "        self.encoder_k.fc =nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 128),\n",
    "        )\n",
    "        for param_q, param_k in zip(\n",
    "            self.encoder_q.parameters(), self.encoder_k.parameters()\n",
    "        ):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "        # dim = 1280\n",
    "\n",
    "        # self.lc  = LocalCoccurrence(dim)\n",
    "        # self.gl  = GlobalConsistency(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(1280),\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 128),\n",
    "        )#<todo> mlp needs to be deep if backbone is strong?\n",
    "        self.att = ShardExamine(128,512,128,256)\n",
    "        self.cancer = nn.Linear(128,1)\n",
    "        # self.labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(\n",
    "            self.encoder_q.parameters(), self.encoder_k.parameters()\n",
    "        ):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        # gather keys before updating queue\n",
    "        # keys = concat_all_gather(keys)\n",
    "\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr : ptr + batch_size] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_ddp(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(batch_size_all).cuda()\n",
    "\n",
    "        # broadcast to all gpus\n",
    "        torch.distributed.broadcast(idx_shuffle, src=0)\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        # shuffled index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_ddp(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # restored index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this]\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query images\n",
    "            im_k: a batch of key images\n",
    "        Output:\n",
    "            logits, targets\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size,C,H,W = x.shape\n",
    "        x = x.reshape(-1, C, H, W)\n",
    "        x_m =torch.split(x,512,dim=-1)[0]\n",
    "\n",
    "        # print(x_m.shape)\n",
    "        x_a =torch.split(x,512,dim=-1)[1]\n",
    "        features=[]\n",
    "        def hook(module, input, output):\n",
    "            features.append(input)\n",
    "            return None\n",
    "        # x = (x - self.mean) / self.std\n",
    "        self.encoder_q.conv_head.register_forward_hook(hook)\n",
    "        self.encoder_q.blocks[5].register_forward_hook(hook)\n",
    "        self.encoder_q.blocks[6].register_forward_hook(hook)\n",
    "        \n",
    "        \n",
    "        # compute query features\n",
    "        q_m = self.encoder_q(x_m)  # queries: NxC\n",
    "        q_a = self.encoder_q(x_a)  # queries: NxC\n",
    "        \n",
    "        # print(features[0][2].shape)\n",
    "        # print(features[1][2].shape)\n",
    "        attn= self.att(features[2][0],features[5][0])\n",
    "        \n",
    "        q_m = nn.functional.normalize(q_m, dim=1)\n",
    "        q_a = nn.functional.normalize(q_a, dim=1)\n",
    "        \n",
    "        last = torch.cat([q_a,q_m,attn],-1)\n",
    "        last = self.mlp(last)\n",
    "        cancer = self.cancer(last).reshape(-1)\n",
    "        cancer = torch.sigmoid(cancer)\n",
    "        q_m = self.encoder_q.fc(q_m)\n",
    "        q_a = self.encoder_q.fc(q_a)\n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()  # update the key encoder\n",
    "            k_m = self.encoder_k(x_m)  # keys: NxC\n",
    "            k_m = nn.functional.normalize(k_m, dim=1)\n",
    "            k_m = self.encoder_k.fc(k_m) \n",
    "            k_a = self.encoder_k(x_a)  # keys: NxC\n",
    "            k_a = nn.functional.normalize(k_a, dim=1)\n",
    "            k_a = self.encoder_k.fc(k_a)\n",
    "\n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        l_pos1 = torch.einsum(\"nc,nc->n\", [q_m, k_m]).unsqueeze(-1)\n",
    "        l_pos2 = torch.einsum(\"nc,nc->n\", [q_m, k_a]).unsqueeze(-1)\n",
    "        l_pos3 = torch.einsum(\"nc,nc->n\", [q_a, k_m]).unsqueeze(-1)\n",
    "        l_pos4 = torch.einsum(\"nc,nc->n\", [q_a, k_a]).unsqueeze(-1)\n",
    "        # negative logits: NxK\n",
    "        l_neg_m = torch.einsum(\"nc,ck->nk\", [q_m, self.queue.clone().detach()])\n",
    "        l_neg_a = torch.einsum(\"nc,ck->nk\", [q_a, self.queue.clone().detach()])\n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos1,l_pos2,l_pos3,l_pos4, l_neg_m,l_neg_a], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[1], dtype=torch.long).cuda()\n",
    "        labels[1],labels[2],labels[3]=1,2,3\n",
    "        \n",
    "        \n",
    "        # dequeue and enqueue\n",
    "        self._dequeue_and_enqueue(k_m)\n",
    "        self._dequeue_and_enqueue(k_a)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return cancer,logits,labels,features\n",
    "        # return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2f420-c19a-4aa7-b7f4-774e4672c368",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83adb3f-1798-4d4d-b5b1-9500f40648f7",
   "metadata": {},
   "source": [
    "## 辅助损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11aa76b-a33f-4aaf-8924-5d640025e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similiarity(x1,x2):#features[0/1/2][0],features[3/4/5][0]\n",
    "    p12 = (x1*x2).sum(-1)\n",
    "    p1 = torch.sqrt((x1*x1).sum(-1))\n",
    "    p2 = torch.sqrt((x2*x2).sum(-1))\n",
    "    s = p12/(p1*p2+1e-6)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1281a30-1416-4398-81a5-fe0a1dc71725",
   "metadata": {},
   "source": [
    "## 对比学习损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373783b3-00dc-4382-b770-1d48d61386f8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25033/3837109568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "loss_C = criterion(output, target)#logits,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b85dde4-cea5-48a9-87ac-416554a19658",
   "metadata": {},
   "source": [
    "## 分类损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7346258a-a66a-459f-aa2d-ea4f05db3cc6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25033/1525243606.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().cuda(args.gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19f43dc-7f54-4135-84f9-91bee1c7f6e0",
   "metadata": {},
   "source": [
    "## 损失函数比例待定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd00a26-423a-4fa6-9aec-cbcf7bf816f4",
   "metadata": {},
   "source": [
    "train_one_epoch 算数量级对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5822f7-bfcf-46e1-ab74-68d347b1e012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a3da2-2a79-4abf-a9d5-c04a22df9332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3a384-b396-4323-b494-b7e3f9cdd7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd34e41-f5dc-40d3-80c6-08454c1c7281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b76888-d08a-46ba-9491-82dd02335869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97998409-347c-4f49-b77d-4c1e0ca99967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f53ca8-2510-4dd0-8dd6-274d877ac314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = ShardExamine(64,304,64,512).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e5b3e-e4af-4a73-a357-13b02ac933be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_m = np.random.random(size=(2, 304, 32, 16))\n",
    "# i_a = np.random.random(size=(2, 304, 32, 16))\n",
    "# i_m = torch.tensor(i_m).to(device).to(torch.float32)\n",
    "# i_a = torch.tensor(i_a).to(device).to(torch.float32)\n",
    "# i_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df198da7-abdf-41e1-9b76-e0b8e31d0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e= net(i_m,i_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7fa99-c0a5-4f6f-b0e6-477536794fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c501613-a07a-4f78-b254-13c809ae28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ba183a-6b8d-408c-b704-09b6a58cf8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0218cd91-f578-4d18-b9c8-e24326499008",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc0cdb35-c165-48ab-98d3-656c86c6c7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1024, 1024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random(size=(2, 3, 1024, 1024))\n",
    "# x_a = np.random.random(size=(2, 3, 1024, 512))\n",
    "x = torch.as_tensor(x).to(device).to(torch.float32)\n",
    "# x_a = torch.as_tensor(i_a).to(device).to(torch.float32)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "486285c7-dee1-4a89-bbb4-31cbd2c98f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1024, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(x,512,dim=-1)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fb1f1d0-99c3-44bd-a0ce-808197462787",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "109f4fe9-849f-44d6-ae56-cc9edc9011a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5160, 0.5373], device='cuda:0', grad_fn=<SigmoidBackward0>),\n",
       " tensor([[ 75.1090, 168.8110,  57.6349,  ...,  -2.4054,   1.1447,   0.5437],\n",
       "         [130.8557, 170.4622,  22.5927,  ...,   0.8941,  -9.2274,  -9.5387]],\n",
       "        device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0, 1, 2,  ..., 0, 0, 0], device='cuda:0'),\n",
       " [(tensor([[[[  0.4200,  -3.3421,  -6.9819,  ...,  -0.0327,   0.8521,  -1.0240],\n",
       "             [ -2.3487,  -0.2992,  -1.3549,  ...,  -1.7887,   0.3788,  -0.1278],\n",
       "             [ -2.6191,   2.1593,   2.9415,  ...,  -2.8458,   3.3491,  -4.1408],\n",
       "             ...,\n",
       "             [ -1.6449, -12.2571, -10.7170,  ...,   3.1370,  -1.9376,   0.5970],\n",
       "             [ -3.3689,  -3.4910,  -2.2186,  ...,  -3.9257,  -4.0602,  -3.2227],\n",
       "             [ -0.7109,  -3.0199,  -2.2512,  ...,  -1.6706,  -0.9532,  -0.8998]],\n",
       "   \n",
       "            [[ -1.5225,  -1.1381,   1.8372,  ...,  -1.6260,  -1.1652,  -2.8704],\n",
       "             [ -3.9050,   2.4136,   3.5249,  ...,   2.2393,   3.9911,  -0.7568],\n",
       "             [ -2.0458,  -3.6630,  -2.8333,  ...,   3.9489,  -1.3655,  -2.8751],\n",
       "             ...,\n",
       "             [ -6.1269,  -1.1220,  -1.4053,  ...,   0.4011,   2.6305,  -4.4355],\n",
       "             [ -1.9198,   2.5706,   2.9845,  ...,  -0.7211,  -2.9004,  -2.0588],\n",
       "             [ -3.4551,  -1.4885,  -2.1803,  ...,  -4.1137,  -3.5825,  -6.1545]],\n",
       "   \n",
       "            [[ -0.3229,  -1.2367,   0.3387,  ...,  -2.0908,   0.9119,  -0.1850],\n",
       "             [  1.8536,  -4.1200,   0.9713,  ...,  -5.7383,   1.4824,   0.6935],\n",
       "             [  4.4741,  -0.7030,   3.6934,  ...,  -2.0345,  -4.8163,  -2.2218],\n",
       "             ...,\n",
       "             [ -1.6269,  -7.3717,  -1.2803,  ...,   0.8044,   4.0052,   1.9010],\n",
       "             [  0.1335,  -0.1787,   2.6387,  ...,  -1.7253,   2.0181,   0.3531],\n",
       "             [  1.5687,  -2.1112,   2.5865,  ...,   0.3453,   1.6269,   0.4210]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[  1.4086,   0.9132,   1.3270,  ...,   0.9666,   1.4844,  -0.4632],\n",
       "             [  3.5890,   2.7749,   0.2043,  ...,   1.5106,   2.1271,   3.9287],\n",
       "             [ -1.4193,  -1.9229,  -3.1027,  ...,   5.5332,   0.7442,  -1.9777],\n",
       "             ...,\n",
       "             [  1.5192,   0.1169,  -1.9971,  ...,   1.4197,   0.3618,  -0.3052],\n",
       "             [  2.7204,  -0.3466,  -1.9592,  ...,   0.2459,   0.7977,   0.8937],\n",
       "             [  0.4318,   5.2094,  -1.1696,  ...,   2.7007,   0.7907,   0.9467]],\n",
       "   \n",
       "            [[ -0.7327,   1.4648,  -4.6006,  ...,   0.2848,  -1.6066,  -2.8043],\n",
       "             [ -3.4871,  -4.6471,  -6.0872,  ...,  -3.5126,  -4.9630,  -5.4707],\n",
       "             [ -4.1970,  -0.2797,  -0.6982,  ...,  -1.8839,  -1.1840,   0.9619],\n",
       "             ...,\n",
       "             [  3.4769,   7.2055,  -1.1414,  ...,   1.9886,  -0.9072,   2.0238],\n",
       "             [ -3.2910,  -1.4267,   0.1594,  ...,   4.0251,   0.4980,  -1.8365],\n",
       "             [  1.3711,   5.4331,  -7.1525,  ...,   1.2140,  -1.9400,  -1.9020]],\n",
       "   \n",
       "            [[ -1.2169,   1.8109,   0.4794,  ...,  -0.0603,  -0.0827,  -0.4636],\n",
       "             [ -2.6382,  -2.7046,  -0.5116,  ...,  -0.8492,  -3.2985,   0.0982],\n",
       "             [  1.4505,  -3.7425,   2.2738,  ...,  -0.6634,   2.2729,  -2.9488],\n",
       "             ...,\n",
       "             [ -2.3458,  10.0093,  -1.1657,  ...,   0.2960,  -1.2266,  -3.9412],\n",
       "             [ -0.7759,   7.2805,   0.2214,  ...,  -0.6438,  -0.3449,  -0.8764],\n",
       "             [ -0.4043,  -1.3695,   6.3087,  ...,   2.4111,   1.4871,  -1.5128]]],\n",
       "   \n",
       "   \n",
       "           [[[ -0.2752,  -2.7546,  -1.9674,  ...,   0.4679,  -2.1026,  -0.9083],\n",
       "             [ -2.3748,   1.4647,  -1.2771,  ...,  -0.3380,  -1.8211,   2.1931],\n",
       "             [ -1.5794,  -0.4192,   1.2501,  ...,  -0.1597,  -1.5488,   0.5047],\n",
       "             ...,\n",
       "             [ -2.0671,   1.0733,  -7.9506,  ...,  -2.8435,  -0.1036,   0.1947],\n",
       "             [ -2.7899,  -1.9078,  -1.2981,  ...,   0.8986,   1.8413,   1.5457],\n",
       "             [ -1.9566,  -2.0109,  -2.8266,  ...,   1.7156,  -0.1443,   0.2575]],\n",
       "   \n",
       "            [[ -2.3910,  -0.0354,   0.7166,  ...,   1.1899,   1.4938,  -1.0021],\n",
       "             [ -1.4845,  -0.0790,  -0.7480,  ...,  -1.4587,  -0.5056,  -2.3374],\n",
       "             [ -3.4618,  -2.3656,  -0.5431,  ...,  -1.5785,  -3.3462,  -3.8760],\n",
       "             ...,\n",
       "             [  0.1793,  -1.0719,  -3.1626,  ...,  -5.6272,  -4.4756,  -3.6642],\n",
       "             [ -3.8059,  -1.6634,   1.2540,  ...,   1.2440,  -3.9604,  -3.1306],\n",
       "             [ -1.2663,  -2.9360,  -1.1841,  ...,  -3.4408,   1.7180,  -1.2526]],\n",
       "   \n",
       "            [[ -0.0866,  -1.9669,   1.1323,  ...,  -0.6742,  -0.6910,  -0.3484],\n",
       "             [ -0.4169,  -0.9546,  -2.4255,  ...,  -5.5084,  -5.8851,  -0.3677],\n",
       "             [ -3.9952,   0.3616,   1.1301,  ...,   3.1474,  -1.9935,   1.6450],\n",
       "             ...,\n",
       "             [  0.9580,  -0.2358,  -3.8264,  ...,   1.9735,  -3.6152,   3.9576],\n",
       "             [ -2.1402,   1.8770,  -0.4313,  ...,  -0.4893,   0.6249,  -1.6912],\n",
       "             [ -0.3479,   0.8973,  -2.9045,  ...,   1.2773,   2.1161,   0.7787]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[ -0.6171,   0.5241,  -0.0714,  ...,   0.9784,   0.5405,   1.6549],\n",
       "             [  1.4882,   2.1029,   1.0255,  ...,  -0.2373,   1.6077,   0.1655],\n",
       "             [  3.5177,   1.6038,   2.6904,  ...,   4.4574,   3.2463,  -1.3186],\n",
       "             ...,\n",
       "             [  3.9820,   4.2995,   4.4566,  ...,  -1.6967,   3.5445,  -1.5894],\n",
       "             [  2.1990,   6.0458,   0.2700,  ...,   2.4898,  -0.2420,   1.5251],\n",
       "             [  2.8686,   0.6710,   2.8686,  ...,  -1.8681,   1.7999,  -0.8520]],\n",
       "   \n",
       "            [[ -0.0508,   0.3508,  -1.2065,  ...,   2.0986,  -0.4920,  -3.8538],\n",
       "             [ -2.0698,  -2.4118,  -2.7891,  ...,  -3.8701,   0.4439,  -1.4815],\n",
       "             [ -2.9667,  -3.9926,  -3.0879,  ...,  -2.4289,   0.2654,  -2.3116],\n",
       "             ...,\n",
       "             [ -0.8978,  -2.9432,   0.2645,  ...,   1.6349,  -3.4398,   0.3356],\n",
       "             [  1.3094,   3.3242,   0.3998,  ...,   4.0221,  -0.6208,  -3.0273],\n",
       "             [ -2.9426,  -0.7098,  -0.6399,  ...,  -0.4302,   1.6715,  -3.1480]],\n",
       "   \n",
       "            [[ -1.0793,  -1.8851,  -1.3815,  ...,   0.9458,   0.3176,   0.6805],\n",
       "             [ -0.7204,  -2.6427,  -0.2952,  ...,   0.2362,   1.1165,  -1.1780],\n",
       "             [  0.8019,   2.6750,  -2.0685,  ...,  -6.1833,  -0.4023,  -1.9267],\n",
       "             ...,\n",
       "             [ -0.4929,  -0.1607,  -1.0238,  ...,  -6.7548,   1.6613,  -2.0883],\n",
       "             [ -0.2729,   1.4365,  -0.3891,  ...,   1.6952,   0.6859,  -2.2370],\n",
       "             [  1.1520,  -0.6872,  -0.6076,  ...,  -0.1826,  -0.0943,  -0.2966]]]],\n",
       "          device='cuda:0', grad_fn=<AddBackward0>),),\n",
       "  (tensor([[[[-3.0327e-01, -1.9296e+00, -2.2783e+00,  ...,  3.3680e+00,\n",
       "               1.6710e-01, -2.9743e+00],\n",
       "             [-2.6522e+00, -1.0221e+01, -9.9596e-01,  ..., -9.3960e+00,\n",
       "               2.8145e-01, -1.7060e+00],\n",
       "             [ 1.7617e-01, -3.4221e+00,  5.1727e+00,  ...,  4.4533e+00,\n",
       "               6.7186e+00,  3.3606e+00],\n",
       "             ...,\n",
       "             [-2.7595e+00, -4.1556e+00,  6.3500e+00,  ..., -6.0221e-01,\n",
       "              -4.2872e-01, -8.8640e+00],\n",
       "             [ 3.2803e-01,  4.2879e+00,  2.4390e+00,  ..., -2.3853e+00,\n",
       "              -8.9422e-01, -5.5544e+00],\n",
       "             [-1.6604e-01, -3.0262e-01, -2.2728e-01,  ..., -1.3920e+00,\n",
       "              -2.4139e+00, -3.5656e+00]],\n",
       "   \n",
       "            [[ 5.1224e+00,  7.1881e+00,  6.5311e+00,  ...,  2.1132e+00,\n",
       "               1.7675e+00,  3.9291e+00],\n",
       "             [ 3.8621e+00,  4.4734e-01, -3.1796e+00,  ...,  6.3186e+00,\n",
       "              -3.0340e+00,  2.7345e+00],\n",
       "             [ 9.3632e-01,  1.0094e+00,  9.4965e+00,  ...,  1.2300e+01,\n",
       "              -3.1577e-01, -1.0200e+00],\n",
       "             ...,\n",
       "             [ 2.0492e+00,  4.5008e-01, -8.7526e+00,  ...,  2.0935e-03,\n",
       "              -3.6478e+00,  6.3721e-01],\n",
       "             [ 9.7687e-01,  6.2622e+00,  3.0815e-01,  ..., -1.6527e+00,\n",
       "               1.9677e+00,  3.7534e+00],\n",
       "             [ 1.4962e+00,  4.0629e+00, -8.5861e-01,  ..., -2.5420e+00,\n",
       "               8.8406e-01,  1.0952e+00]],\n",
       "   \n",
       "            [[ 1.2262e+00, -1.2125e+00, -1.5756e-02,  ...,  3.3743e+00,\n",
       "              -1.0734e+00, -7.3256e-02],\n",
       "             [ 5.7281e+00,  5.0225e+00,  6.8198e+00,  ...,  2.3790e+00,\n",
       "               1.0849e+00,  1.4524e+00],\n",
       "             [-5.0650e+00,  1.2540e-01,  4.8338e+00,  ...,  9.6042e-01,\n",
       "               9.8319e+00,  4.4026e+00],\n",
       "             ...,\n",
       "             [-1.7459e+00,  6.2254e+00,  6.4003e+00,  ..., -3.6633e+00,\n",
       "              -1.6882e+00,  1.5898e+00],\n",
       "             [-8.0847e-02, -4.0719e+00,  2.2583e+00,  ...,  2.0896e+00,\n",
       "               5.9802e+00,  7.5074e-02],\n",
       "             [-1.4096e+00, -1.7329e+00,  4.3058e+00,  ..., -8.2576e+00,\n",
       "               1.7762e-01, -1.7417e+00]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[-5.0045e-01,  6.3470e-01,  3.7320e-01,  ..., -2.9959e+00,\n",
       "              -3.3464e+00, -2.3216e-01],\n",
       "             [-8.8256e-01, -5.4103e+00, -3.5594e+00,  ..., -2.3618e+00,\n",
       "              -2.0757e+00,  3.1059e+00],\n",
       "             [ 2.9145e+00, -1.2102e+00, -5.9024e-01,  ..., -3.4306e+00,\n",
       "              -5.7879e+00, -3.2423e+00],\n",
       "             ...,\n",
       "             [ 8.1836e-01,  8.4690e-01,  5.3681e+00,  ...,  6.9588e+00,\n",
       "              -2.1727e+00, -1.7923e+00],\n",
       "             [-5.0936e+00, -2.4513e-01, -3.1053e+00,  ...,  1.1430e+00,\n",
       "              -3.7690e+00, -9.5160e+00],\n",
       "             [ 8.0079e-01, -1.8583e+00, -1.9154e+00,  ...,  4.4459e+00,\n",
       "               1.5340e-01, -1.8559e+00]],\n",
       "   \n",
       "            [[ 1.3230e+00,  1.4340e+00,  2.4741e-01,  ..., -3.0751e+00,\n",
       "               4.5254e-01, -4.2170e+00],\n",
       "             [-2.3360e+00, -1.2641e+00, -2.4715e+00,  ...,  7.5693e-01,\n",
       "               3.1022e+00,  1.3569e+00],\n",
       "             [-1.9018e+00, -2.1828e-01, -1.5373e+00,  ...,  2.5686e+00,\n",
       "               9.3122e+00,  1.2285e+00],\n",
       "             ...,\n",
       "             [-2.5889e+00, -3.6130e+00,  7.9651e+00,  ..., -2.0181e+00,\n",
       "               3.5683e+00, -2.1932e+00],\n",
       "             [-5.2908e-01, -1.2768e+00, -4.0020e+00,  ..., -2.2443e+00,\n",
       "              -1.2756e+00, -5.1733e+00],\n",
       "             [ 5.9188e-01, -3.2609e+00, -1.4931e+00,  ..., -1.9033e+00,\n",
       "              -3.4808e-01, -1.1335e+00]],\n",
       "   \n",
       "            [[ 2.2932e-01,  8.0129e-01, -5.1542e+00,  ...,  3.0996e+00,\n",
       "               2.8864e+00, -3.4153e+00],\n",
       "             [ 3.2735e-01,  5.3428e-01, -1.4151e+01,  ...,  4.3990e+00,\n",
       "              -2.2693e+00,  3.0054e+00],\n",
       "             [-7.5891e-01,  1.7603e+00, -7.8665e-01,  ...,  1.9673e+00,\n",
       "               3.9123e-01,  7.3473e-01],\n",
       "             ...,\n",
       "             [ 3.7619e+00, -2.0265e-01,  1.4907e+00,  ..., -6.7313e+00,\n",
       "              -3.1277e-02, -9.0139e+00],\n",
       "             [-3.0566e+00, -2.9678e-01,  2.4158e+00,  ..., -3.4503e+00,\n",
       "               5.4973e+00, -5.7316e+00],\n",
       "             [ 2.9029e-01, -3.0781e+00, -3.1896e+00,  ...,  3.0433e+00,\n",
       "               9.3467e-01, -2.8180e+00]]],\n",
       "   \n",
       "   \n",
       "           [[[-2.7055e+00, -2.9682e+00, -4.0125e+00,  ..., -4.8283e+00,\n",
       "               3.2568e-01, -4.1408e+00],\n",
       "             [-2.8814e+00, -3.9508e+00, -4.1251e+00,  ..., -3.8601e+00,\n",
       "              -2.5426e+00, -7.2559e+00],\n",
       "             [-2.4557e+00, -9.5599e-01,  2.3937e+00,  ..., -7.0163e+00,\n",
       "              -3.1075e+00, -2.5018e+00],\n",
       "             ...,\n",
       "             [-9.8069e-01, -1.7770e+00, -6.8310e+00,  ..., -9.9720e-02,\n",
       "              -3.7023e+00, -3.8057e+00],\n",
       "             [-3.0211e+00, -1.7543e+00, -2.6398e+00,  ..., -1.2965e+00,\n",
       "              -8.0811e+00, -5.6374e+00],\n",
       "             [-2.0288e+00, -2.8149e+00, -7.5824e-01,  ..., -3.0861e+00,\n",
       "              -2.7796e+00, -1.4365e+00]],\n",
       "   \n",
       "            [[ 8.0817e-01,  2.8988e+00,  1.4169e+00,  ...,  3.8223e+00,\n",
       "               1.8338e+00,  1.2339e+00],\n",
       "             [ 2.6900e+00,  3.4267e+00,  2.0371e+00,  ...,  2.0778e-01,\n",
       "               3.0841e+00, -6.1988e-01],\n",
       "             [ 3.9596e+00, -2.9424e-01,  2.0792e+00,  ..., -5.9482e-01,\n",
       "              -3.8983e+00,  1.2215e+00],\n",
       "             ...,\n",
       "             [ 3.1773e+00, -2.3632e+00, -1.4899e+00,  ..., -5.8319e-01,\n",
       "               2.3197e+00, -2.5857e+00],\n",
       "             [-1.9742e-01, -1.9178e+00,  3.0932e+00,  ...,  1.5910e+00,\n",
       "               2.6052e+00, -2.8486e+00],\n",
       "             [ 1.4602e+00, -7.9247e-01,  7.6861e-02,  ...,  1.8286e+00,\n",
       "               6.6265e-02, -2.9594e+00]],\n",
       "   \n",
       "            [[-1.4163e+00, -2.9493e+00,  9.4412e-01,  ..., -1.3259e-01,\n",
       "               1.6113e+00, -1.5010e+00],\n",
       "             [-1.0460e+00, -2.7872e+00, -4.0473e+00,  ..., -3.6246e+00,\n",
       "              -1.5957e+00, -2.9245e+00],\n",
       "             [-8.8819e-01, -1.6360e+00, -5.6665e+00,  ..., -7.7301e-01,\n",
       "              -1.5764e+00, -6.4482e+00],\n",
       "             ...,\n",
       "             [ 1.0950e+00, -3.2278e+00, -1.6108e+00,  ..., -6.2019e+00,\n",
       "              -3.9014e+00, -2.8858e+00],\n",
       "             [ 2.0741e-01, -1.9005e+00, -4.4076e+00,  ..., -3.6139e+00,\n",
       "              -2.8243e+00, -2.7363e+00],\n",
       "             [-5.1665e+00, -1.9033e+00, -2.2815e+00,  ..., -4.1895e+00,\n",
       "              -3.6109e+00, -3.7311e+00]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[-2.7916e+00, -2.0888e+00, -1.0192e+00,  ..., -3.0232e+00,\n",
       "              -3.2113e+00, -1.8717e+00],\n",
       "             [-1.5507e+00, -1.2018e+00, -7.3323e-01,  ...,  1.5990e-01,\n",
       "               4.4955e-01, -2.1473e+00],\n",
       "             [-4.2561e-01, -5.0791e+00, -3.9535e+00,  ...,  6.2786e-01,\n",
       "              -5.2223e+00, -5.1306e+00],\n",
       "             ...,\n",
       "             [ 1.2168e+00, -4.6632e+00, -4.0291e+00,  ...,  6.6640e-01,\n",
       "              -4.1169e-02, -1.4875e-01],\n",
       "             [-1.8047e+00, -2.1272e+00,  2.3180e+00,  ..., -2.6971e+00,\n",
       "              -1.3855e+00, -3.1089e+00],\n",
       "             [ 1.3342e+00, -1.8957e+00, -2.4696e+00,  ..., -2.9086e+00,\n",
       "              -1.6784e+00, -2.3956e+00]],\n",
       "   \n",
       "            [[-1.3718e+00, -2.0744e+00, -2.4382e+00,  ..., -1.0601e+00,\n",
       "              -2.4459e+00, -2.4267e-01],\n",
       "             [ 3.9445e-02,  1.6632e+00, -1.2060e+00,  ..., -3.0607e+00,\n",
       "               3.5073e-01, -4.2676e-01],\n",
       "             [-1.8100e+00, -2.4435e-01,  3.5228e+00,  ..., -3.7388e+00,\n",
       "              -1.0888e+00, -2.2755e+00],\n",
       "             ...,\n",
       "             [-1.1041e+00, -2.2785e+00,  5.0061e+00,  ..., -2.4752e+00,\n",
       "              -4.0357e+00, -2.0723e+00],\n",
       "             [-2.3718e+00, -5.6513e-01, -2.3029e+00,  ...,  4.6788e-01,\n",
       "              -1.0574e+00, -3.5521e+00],\n",
       "             [-7.8607e-01, -6.5492e-01, -1.6762e+00,  ..., -9.8919e-01,\n",
       "               2.5741e+00, -1.2843e+00]],\n",
       "   \n",
       "            [[-4.3429e-01, -2.6782e+00, -2.1940e+00,  ..., -1.0102e+00,\n",
       "              -2.4798e+00, -3.2625e+00],\n",
       "             [ 1.6069e+00, -7.8633e+00, -6.4627e+00,  ...,  2.6804e+00,\n",
       "               1.8677e+00, -4.9516e+00],\n",
       "             [ 1.6741e+00, -4.9624e+00, -3.2999e+00,  ..., -4.0894e+00,\n",
       "              -1.6610e-01, -3.3864e+00],\n",
       "             ...,\n",
       "             [ 1.0837e+00, -3.4368e+00,  1.4569e+00,  ...,  6.2346e+00,\n",
       "              -1.8133e+00, -2.3133e+00],\n",
       "             [ 5.0849e-01, -7.4502e+00,  2.2361e+00,  ..., -2.4304e+00,\n",
       "              -4.1313e-01, -6.4545e+00],\n",
       "             [-2.5218e-01, -3.8682e+00, -1.2680e+00,  ..., -3.8325e+00,\n",
       "               2.7099e-01, -2.8941e+00]]]], device='cuda:0',\n",
       "          grad_fn=<AddBackward0>),),\n",
       "  (tensor([[[[ 1.5102e-01, -6.2380e-01,  2.1772e+00,  ..., -1.2779e+00,\n",
       "              -9.6755e-01,  1.5434e+00],\n",
       "             [ 5.6229e-01, -6.5144e-01,  4.3257e+00,  ...,  9.6221e-01,\n",
       "               2.7097e+00, -8.3666e-01],\n",
       "             [ 1.7615e+00, -1.6974e+00, -1.1276e+00,  ...,  3.0866e+00,\n",
       "               2.7432e-01,  8.1410e-01],\n",
       "             ...,\n",
       "             [ 2.0191e+00, -1.7503e+00, -1.2251e-02,  ..., -6.2272e-01,\n",
       "              -3.6655e+00, -1.3813e+00],\n",
       "             [ 2.3274e-01, -3.8816e-01, -7.0272e-01,  ..., -2.5363e+00,\n",
       "              -5.0556e-01, -1.2531e+00],\n",
       "             [ 6.3073e-01, -4.6106e-01, -2.4571e-02,  ...,  7.7816e-01,\n",
       "              -1.0006e+00, -4.3859e-01]],\n",
       "   \n",
       "            [[-8.3244e-01, -1.7080e-03,  8.2922e-01,  ...,  2.4827e+00,\n",
       "               4.8495e-01,  6.5481e-01],\n",
       "             [ 6.3830e-01,  8.3023e-01, -1.1298e+00,  ..., -1.6054e+00,\n",
       "               1.9560e-01,  2.7551e-01],\n",
       "             [-5.2582e-01,  7.6792e-01,  1.2352e+00,  ...,  2.6240e+00,\n",
       "              -2.3572e-01,  1.6417e+00],\n",
       "             ...,\n",
       "             [-1.1291e+00, -2.5074e-01,  1.2211e+00,  ...,  1.9133e+00,\n",
       "              -1.0772e+00,  2.9637e-01],\n",
       "             [ 1.9115e-01,  7.2528e-01,  4.1859e-01,  ..., -1.9615e+00,\n",
       "              -1.7716e+00,  2.7042e-01],\n",
       "             [-5.9614e-01, -3.9462e-01, -2.8210e+00,  ..., -1.8263e-01,\n",
       "              -1.3588e+00,  4.6139e-01]],\n",
       "   \n",
       "            [[-1.7117e-01,  8.6490e-01, -7.6355e-01,  ...,  5.6000e-01,\n",
       "              -4.4600e-01, -7.0985e-01],\n",
       "             [-6.2329e-01, -2.2310e-01, -1.6637e+00,  ..., -1.4000e+00,\n",
       "              -2.4725e+00, -4.3470e+00],\n",
       "             [-3.4084e-01, -1.6406e+00, -2.5351e-01,  ...,  7.4889e-01,\n",
       "               2.4620e+00, -1.0819e+00],\n",
       "             ...,\n",
       "             [-2.5444e-01, -2.7908e+00, -1.3772e+00,  ...,  7.0275e-01,\n",
       "              -2.4438e-01, -4.5834e-01],\n",
       "             [-2.6713e+00, -2.9090e+00,  4.3663e-01,  ..., -6.4375e-01,\n",
       "              -2.9749e+00,  6.4981e-01],\n",
       "             [-1.9407e+00, -2.9244e-02, -2.8008e+00,  ..., -2.0119e+00,\n",
       "              -4.2922e-01, -3.7934e-01]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[-3.9369e-01, -2.7869e+00, -2.6372e-01,  ...,  6.7797e-01,\n",
       "              -1.1093e+00, -9.2388e-01],\n",
       "             [-1.4826e-01, -1.5352e+00,  2.1357e+00,  ...,  6.7704e-01,\n",
       "               7.6117e-01,  1.1876e+00],\n",
       "             [ 7.8864e-01, -2.1541e+00,  1.8863e-01,  ..., -2.2421e+00,\n",
       "               9.2059e-02,  9.6174e-01],\n",
       "             ...,\n",
       "             [ 4.7114e-01,  4.8211e-01,  5.4188e-01,  ..., -5.9986e-02,\n",
       "              -1.2348e-01, -9.6594e-01],\n",
       "             [-4.7002e-01,  6.6093e-02,  2.7281e-01,  ...,  2.7939e+00,\n",
       "              -1.6353e-01, -1.2275e-01],\n",
       "             [ 1.7425e+00,  1.5043e+00, -9.0098e-01,  ...,  8.2058e-01,\n",
       "               9.1579e-01, -2.0482e-02]],\n",
       "   \n",
       "            [[ 2.3961e+00, -7.6165e-01,  1.3440e+00,  ...,  1.8428e+00,\n",
       "               1.7363e+00,  1.5491e+00],\n",
       "             [ 1.3124e+00, -3.0897e-01,  1.2983e+00,  ..., -7.2993e-01,\n",
       "               1.3391e-01,  2.3800e+00],\n",
       "             [ 2.0190e+00,  2.2637e+00, -3.4219e+00,  ...,  2.6596e+00,\n",
       "               1.9689e+00,  1.8497e+00],\n",
       "             ...,\n",
       "             [ 5.3508e-01,  1.2284e-01,  1.9283e+00,  ..., -2.5799e+00,\n",
       "               2.7387e-01,  2.5664e+00],\n",
       "             [ 2.3329e+00,  1.0224e+00, -1.9983e-01,  ...,  1.5813e+00,\n",
       "              -6.8156e-01, -7.2607e-01],\n",
       "             [ 1.8740e-01,  1.1036e+00,  1.3933e+00,  ..., -1.3844e+00,\n",
       "               9.2275e-01,  1.2008e+00]],\n",
       "   \n",
       "            [[ 1.6370e-01, -9.5196e-01, -8.3848e-01,  ...,  2.2825e+00,\n",
       "               1.4861e+00, -9.9312e-02],\n",
       "             [ 1.4059e+00, -7.4656e-01,  1.4288e+00,  ..., -1.8888e+00,\n",
       "              -3.3195e-01, -5.9578e-01],\n",
       "             [-7.8279e-01,  1.9613e+00,  3.0271e+00,  ...,  9.1775e-02,\n",
       "               9.4594e-01, -2.1368e+00],\n",
       "             ...,\n",
       "             [ 1.9289e+00,  2.4933e-01,  2.3924e+00,  ...,  3.3511e-01,\n",
       "              -2.2222e-01, -2.6671e-01],\n",
       "             [-5.5095e-02, -1.1064e+00,  7.2278e-01,  ...,  4.3614e-01,\n",
       "               3.0614e-01, -1.7745e+00],\n",
       "             [ 1.1549e+00, -1.9750e+00,  6.1349e-01,  ...,  3.1788e-01,\n",
       "               6.5657e-01,  3.3851e-01]]],\n",
       "   \n",
       "   \n",
       "           [[[ 4.4802e-01, -6.6671e-01,  1.4611e+00,  ...,  6.7961e-01,\n",
       "               1.2395e+00,  8.8077e-01],\n",
       "             [ 1.3911e+00,  4.0839e-01,  6.2412e-01,  ...,  9.8721e-01,\n",
       "               4.5327e-01,  1.6172e+00],\n",
       "             [ 2.7490e+00,  4.4417e-01,  8.9090e-01,  ...,  1.5013e-01,\n",
       "               3.7068e+00,  1.8220e+00],\n",
       "             ...,\n",
       "             [ 2.1678e+00,  1.6898e+00,  1.3085e+00,  ...,  5.1336e-01,\n",
       "               2.0833e+00,  6.7800e-01],\n",
       "             [ 8.5239e-01,  6.9018e-01,  6.7363e-01,  ..., -2.3860e-01,\n",
       "               4.1064e-01,  4.2882e-01],\n",
       "             [ 1.0534e+00,  1.7619e-01,  1.2352e+00,  ...,  2.2280e-01,\n",
       "               2.2505e+00,  1.1938e+00]],\n",
       "   \n",
       "            [[-2.0990e-02,  3.8003e-01,  8.8884e-01,  ..., -9.8213e-02,\n",
       "               1.2127e+00,  2.8774e-01],\n",
       "             [ 1.3475e+00,  9.2818e-01, -5.1690e-01,  ...,  9.3553e-01,\n",
       "               1.8293e+00, -6.7085e-01],\n",
       "             [ 8.4916e-01,  1.8529e+00, -1.7128e+00,  ...,  8.4929e-01,\n",
       "              -4.7716e-01, -1.4978e+00],\n",
       "             ...,\n",
       "             [ 5.2945e-01,  6.8154e-01, -1.0168e+00,  ..., -2.5208e+00,\n",
       "               1.2181e-01,  1.8626e+00],\n",
       "             [ 5.7439e-01,  5.9190e-01, -4.4428e-01,  ..., -1.7410e+00,\n",
       "              -1.6160e+00, -5.2622e-01],\n",
       "             [ 6.6583e-01,  1.0205e+00,  2.1111e-01,  ..., -5.5657e-02,\n",
       "               3.6197e-01,  1.0955e+00]],\n",
       "   \n",
       "            [[ 6.5127e-01, -7.6110e-01, -8.0564e-01,  ...,  3.7731e-02,\n",
       "              -1.8577e-01,  3.8260e-02],\n",
       "             [-6.9408e-01, -2.1342e-01, -4.2203e-01,  ...,  1.0217e+00,\n",
       "              -1.2050e+00,  9.3134e-01],\n",
       "             [ 4.5405e-01, -9.0151e-01,  6.3067e-01,  ...,  1.4956e+00,\n",
       "              -4.4153e-01, -2.5179e-01],\n",
       "             ...,\n",
       "             [ 1.2690e+00,  1.0906e+00, -1.5333e+00,  ...,  1.0294e+00,\n",
       "               2.4834e+00,  2.5028e-01],\n",
       "             [ 1.6882e-02,  5.8231e-01,  6.2452e-01,  ...,  3.8463e+00,\n",
       "               8.9131e-01,  5.3764e-01],\n",
       "             [-7.8718e-01, -2.0480e+00, -1.2893e+00,  ...,  6.7738e-01,\n",
       "              -1.0285e+00, -1.1448e-01]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[-1.4287e+00, -2.6010e+00, -2.3328e+00,  ..., -1.9180e+00,\n",
       "              -1.0673e+00, -2.3620e+00],\n",
       "             [-9.4513e-01, -2.8898e+00, -8.4992e-01,  ..., -1.6650e+00,\n",
       "              -2.4604e+00, -1.7504e+00],\n",
       "             [-2.2214e+00, -9.0114e-01,  3.0561e-02,  ..., -6.7422e-01,\n",
       "              -1.2574e+00, -8.4030e-01],\n",
       "             ...,\n",
       "             [-6.9558e-02, -2.4797e+00, -3.8221e+00,  ..., -2.6336e+00,\n",
       "              -8.1866e-01, -2.1171e+00],\n",
       "             [-3.1055e-01, -3.0771e+00, -1.6777e+00,  ..., -1.2058e+00,\n",
       "              -1.5647e+00, -5.2948e-01],\n",
       "             [ 9.0330e-02, -8.8034e-01,  6.0101e-01,  ..., -7.8270e-01,\n",
       "              -7.8784e-01, -1.3726e-01]],\n",
       "   \n",
       "            [[ 1.7645e+00,  1.1432e+00,  9.1108e-01,  ..., -7.0554e-02,\n",
       "               1.2549e+00,  2.2824e-01],\n",
       "             [ 4.8023e-01,  4.9837e-02,  7.6539e-01,  ..., -6.6028e-01,\n",
       "              -2.9148e+00,  7.1885e-02],\n",
       "             [-2.3172e-01,  2.3220e-01, -1.3300e+00,  ...,  1.2004e-01,\n",
       "               3.1247e-01, -7.4250e-01],\n",
       "             ...,\n",
       "             [ 2.1586e+00, -1.4038e-01, -2.6698e-01,  ...,  2.5453e+00,\n",
       "              -8.8794e-01,  1.6311e+00],\n",
       "             [ 9.3174e-01,  7.0989e-01,  8.7101e-01,  ...,  2.1244e-01,\n",
       "              -1.2801e+00, -1.9456e-02],\n",
       "             [ 1.6403e+00, -1.7023e-01,  3.7262e-01,  ..., -1.2937e-01,\n",
       "               6.7786e-01,  7.6553e-01]],\n",
       "   \n",
       "            [[-2.3548e-01, -1.3694e-01, -7.0371e-01,  ..., -5.2637e-01,\n",
       "              -1.4625e+00,  8.0278e-01],\n",
       "             [-1.4587e+00, -1.4896e-01, -8.0613e-01,  ..., -3.3114e+00,\n",
       "              -1.0369e+00,  1.1702e-01],\n",
       "             [ 8.1119e-01, -8.5882e-01, -1.9236e+00,  ...,  9.5228e-01,\n",
       "               5.5228e-01,  9.7291e-01],\n",
       "             ...,\n",
       "             [ 4.5338e-01, -1.6153e+00,  1.4262e+00,  ..., -1.0948e+00,\n",
       "               5.7045e-01,  1.4765e+00],\n",
       "             [-3.2072e-01,  2.6672e-02, -7.6212e-01,  ..., -1.9280e+00,\n",
       "              -9.7763e-01,  7.8257e-01],\n",
       "             [-7.5816e-01, -1.0894e+00,  3.7216e-01,  ...,  1.5397e+00,\n",
       "               5.8697e-01,  6.7808e-01]]]], device='cuda:0',\n",
       "          grad_fn=<AddBackward0>),),\n",
       "  (tensor([[[[ 4.1603e-01,  2.4173e+00,  1.4835e+00,  ..., -4.1134e+00,\n",
       "               1.7423e+00, -9.1067e-02],\n",
       "             [ 3.6725e+00, -1.2320e+00,  1.9160e+00,  ...,  4.2611e+00,\n",
       "              -2.5136e-01,  1.0664e-01],\n",
       "             [ 5.1925e-01, -5.4104e-01,  2.7439e+00,  ...,  5.7973e-01,\n",
       "               3.4812e+00,  7.9534e-02],\n",
       "             ...,\n",
       "             [ 2.0945e+00,  2.5181e+00, -2.2700e-01,  ..., -5.8316e+00,\n",
       "               1.8496e+00,  1.3145e+00],\n",
       "             [-3.3821e+00,  7.2463e+00, -5.4400e+00,  ..., -1.1648e+00,\n",
       "               2.0018e+00,  4.9494e+00],\n",
       "             [-4.0335e+00,  1.7109e+00, -2.8154e-01,  ...,  5.8783e-01,\n",
       "              -1.2754e+00,  9.8688e-02]],\n",
       "   \n",
       "            [[-3.3515e+00, -1.1383e-01,  9.9426e-01,  ...,  4.2240e-01,\n",
       "               2.4245e-01, -6.1582e-01],\n",
       "             [ 2.9261e+00, -5.8766e-01,  2.8184e-01,  ...,  5.0451e+00,\n",
       "              -2.6859e+00, -3.9980e+00],\n",
       "             [ 1.8086e+00, -9.6056e+00, -4.0212e+00,  ...,  4.8770e-01,\n",
       "               8.0682e+00,  7.9463e-01],\n",
       "             ...,\n",
       "             [-3.0671e+00,  2.7749e+00,  5.8261e-01,  ..., -4.4104e+00,\n",
       "              -1.6841e+00, -3.8917e+00],\n",
       "             [-2.7466e+00, -1.8965e+00, -7.2450e-01,  ..., -2.7522e+00,\n",
       "              -1.9460e+00, -2.0711e-01],\n",
       "             [-2.3310e+00, -3.1006e+00, -2.3086e+00,  ...,  1.2035e+00,\n",
       "              -1.2539e+00, -3.5410e+00]],\n",
       "   \n",
       "            [[-4.5361e-01, -4.9781e-01,  1.3273e+00,  ..., -8.8179e-01,\n",
       "               2.3289e+00,  2.3022e+00],\n",
       "             [ 3.3678e-01, -1.0946e+00,  3.5726e+00,  ..., -3.4857e+00,\n",
       "              -6.3292e+00,  1.4785e+00],\n",
       "             [ 1.0370e+00,  1.1665e+00,  2.0381e+00,  ...,  4.9656e+00,\n",
       "              -5.3480e+00, -5.5117e+00],\n",
       "             ...,\n",
       "             [ 8.2184e+00,  7.8413e+00, -3.7293e+00,  ...,  1.7739e+00,\n",
       "               4.2463e+00, -1.4224e+00],\n",
       "             [ 3.4043e+00,  1.5364e+00, -5.3209e+00,  ..., -4.8095e+00,\n",
       "               3.8110e+00,  7.6784e-01],\n",
       "             [ 1.4314e+00, -2.3843e+00,  1.8259e+00,  ...,  1.3712e+00,\n",
       "              -1.4370e+00,  3.4509e-01]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[ 3.6612e-01,  1.9958e+00, -1.6345e+00,  ..., -4.2745e+00,\n",
       "              -3.5343e+00, -6.8614e-02],\n",
       "             [ 1.5993e+00, -1.5683e+00, -5.4498e-02,  ...,  3.6596e+00,\n",
       "              -5.3426e+00, -2.2273e+00],\n",
       "             [-1.7837e-01, -4.7824e+00,  2.4220e+00,  ..., -2.7746e+00,\n",
       "              -2.1671e+00, -1.8326e+00],\n",
       "             ...,\n",
       "             [-5.7978e+00, -3.1627e+00, -4.8441e+00,  ..., -5.4722e+00,\n",
       "               3.8902e+00,  5.1899e+00],\n",
       "             [-3.7073e-01, -3.7296e+00, -3.3678e+00,  ..., -3.1993e+00,\n",
       "              -3.0128e+00, -2.0058e+00],\n",
       "             [ 2.7374e-01,  2.4152e+00, -4.8794e-01,  ...,  1.2221e+00,\n",
       "               2.4115e+00, -2.5259e+00]],\n",
       "   \n",
       "            [[-1.2928e+00, -2.3607e+00, -1.4740e+00,  ..., -2.6272e+00,\n",
       "              -2.2143e-01, -2.5931e+00],\n",
       "             [-4.9126e-01,  1.3966e-01,  6.0006e-01,  ..., -3.8751e+00,\n",
       "               3.1320e+00, -1.4010e+00],\n",
       "             [ 1.0066e+00,  2.7673e-02, -1.8517e+00,  ...,  1.9205e+00,\n",
       "              -5.0467e+00, -2.9015e+00],\n",
       "             ...,\n",
       "             [ 1.6029e+00,  1.4273e+00, -5.2593e-01,  ...,  3.4123e+00,\n",
       "              -2.7394e+00, -2.2235e+00],\n",
       "             [-2.5340e+00,  1.1410e+00, -9.0048e-01,  ...,  4.8885e+00,\n",
       "              -1.9878e+00, -6.7320e-01],\n",
       "             [ 2.2147e-02,  1.0389e+00,  2.6049e+00,  ...,  3.2332e+00,\n",
       "               1.5716e-01, -1.9078e+00]],\n",
       "   \n",
       "            [[-1.6069e+00,  2.4427e-01,  2.2579e-02,  ..., -8.0476e-01,\n",
       "               1.2464e-01, -1.9321e+00],\n",
       "             [-1.8389e+00, -4.2239e+00,  6.5182e-01,  ..., -1.3618e+00,\n",
       "               5.1860e-01, -4.0027e+00],\n",
       "             [-1.2539e+00, -1.6999e+00,  3.8482e+00,  ..., -8.3932e+00,\n",
       "              -4.5246e+00, -1.5643e-02],\n",
       "             ...,\n",
       "             [ 5.8714e+00,  3.1372e+00,  7.2096e+00,  ..., -1.5152e+00,\n",
       "              -2.8237e+00, -3.2778e+00],\n",
       "             [ 4.3092e-01, -6.7486e+00,  2.8742e+00,  ...,  7.9496e-01,\n",
       "              -4.2023e+00, -3.1562e-01],\n",
       "             [ 2.4086e+00,  2.8162e-03, -3.8286e+00,  ...,  4.5684e-01,\n",
       "               1.1850e+00,  3.0867e+00]]],\n",
       "   \n",
       "   \n",
       "           [[[-3.0303e-01, -6.8872e-01, -2.4703e-01,  ..., -2.0094e+00,\n",
       "              -6.2736e-01, -1.1124e+00],\n",
       "             [-3.7477e+00, -5.2578e-01,  2.2227e-02,  ..., -4.8317e+00,\n",
       "              -7.1681e-01,  4.7509e-01],\n",
       "             [-5.8389e-01, -4.2244e+00, -5.4847e-01,  ..., -1.9355e+00,\n",
       "               7.4389e-01, -2.4350e+00],\n",
       "             ...,\n",
       "             [-3.7919e+00, -2.8368e+00,  1.6506e+00,  ...,  1.6535e+00,\n",
       "              -1.1095e+00, -1.3479e+00],\n",
       "             [ 2.4516e-01, -2.4862e+00,  7.8781e-01,  ..., -1.7981e+00,\n",
       "              -4.8603e-01,  4.0620e-01],\n",
       "             [-2.7832e+00,  5.6558e-01, -9.2432e-02,  ..., -3.1076e+00,\n",
       "              -3.0283e+00,  1.3400e+00]],\n",
       "   \n",
       "            [[-3.8200e-01, -1.6216e-01, -1.5081e+00,  ..., -3.5685e-01,\n",
       "              -1.2860e+00, -7.2839e-01],\n",
       "             [-1.2776e+00, -7.6843e-01,  8.2036e-01,  ..., -1.9643e+00,\n",
       "               1.6657e+00, -1.6545e+00],\n",
       "             [-1.1925e+00, -2.0474e+00, -1.1183e+00,  ..., -5.6084e-03,\n",
       "              -3.5029e+00, -2.2367e+00],\n",
       "             ...,\n",
       "             [-3.2140e+00, -1.6956e+00, -6.3740e-01,  ..., -2.0540e+00,\n",
       "              -4.7153e-01, -1.7582e+00],\n",
       "             [-1.3778e+00, -1.3154e+00, -5.6438e-01,  ..., -4.1830e-01,\n",
       "               1.2109e+00, -4.8232e-01],\n",
       "             [-6.3400e-01, -3.8720e-01, -1.5651e+00,  ..., -2.8356e+00,\n",
       "              -2.9943e+00, -2.2811e+00]],\n",
       "   \n",
       "            [[ 9.6214e-02, -1.1336e+00, -3.7844e-01,  ...,  1.6870e+00,\n",
       "               1.4215e+00, -9.3336e-01],\n",
       "             [ 7.0012e-01, -2.1627e-01, -4.0426e-01,  ..., -3.5221e+00,\n",
       "              -7.2283e-01, -1.8557e-01],\n",
       "             [ 3.6260e-01, -3.3310e+00, -3.0042e+00,  ...,  1.2230e-01,\n",
       "              -2.4831e-01, -1.8882e+00],\n",
       "             ...,\n",
       "             [ 3.9699e-01, -1.7331e+00, -7.0106e-01,  ...,  1.7413e-01,\n",
       "              -1.0269e+00,  1.3625e+00],\n",
       "             [-8.4953e-01, -2.5603e+00, -6.1546e-02,  ..., -1.8565e+00,\n",
       "              -3.7953e-01,  1.2622e+00],\n",
       "             [-4.0263e-01, -1.4588e+00, -2.3555e+00,  ..., -1.6998e+00,\n",
       "               2.3767e-01, -3.1485e-01]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[ 1.2177e+00, -1.1348e-02, -1.2906e+00,  ...,  9.6105e-01,\n",
       "               4.5084e-01, -2.4610e+00],\n",
       "             [-2.1188e-01,  1.3094e-01,  2.1683e+00,  ...,  3.2958e+00,\n",
       "               3.5828e+00, -8.7430e-01],\n",
       "             [ 6.9995e-01,  1.5845e+00,  3.0030e+00,  ...,  1.7138e+00,\n",
       "               2.5385e+00, -4.6247e-01],\n",
       "             ...,\n",
       "             [-2.3128e+00,  2.0357e+00,  7.0618e-01,  ...,  2.4042e-01,\n",
       "               2.9723e+00,  1.9749e+00],\n",
       "             [ 3.9765e+00,  5.3842e+00,  2.7831e+00,  ...,  2.0185e+00,\n",
       "               1.4429e+00, -1.3827e+00],\n",
       "             [ 2.2177e+00,  2.5760e+00, -3.2560e-01,  ...,  5.3829e-01,\n",
       "               1.5529e+00, -1.4518e+00]],\n",
       "   \n",
       "            [[-2.0169e+00, -8.2787e-01, -2.6328e+00,  ..., -2.0281e+00,\n",
       "              -2.4107e+00, -2.1644e+00],\n",
       "             [ 8.5371e-01, -9.8675e-01,  1.1416e+00,  ..., -1.9645e+00,\n",
       "              -1.7848e+00, -1.4764e+00],\n",
       "             [-1.5518e+00, -2.8276e+00, -1.6772e+00,  ..., -2.3766e+00,\n",
       "              -1.4199e+00, -1.4631e+00],\n",
       "             ...,\n",
       "             [-8.7192e-01, -2.4132e+00, -5.0476e-01,  ..., -1.6262e+00,\n",
       "              -1.4195e+00, -4.6219e+00],\n",
       "             [-1.4650e+00,  1.6600e+00, -2.3967e+00,  ..., -5.0153e+00,\n",
       "               5.3604e-01, -1.1745e+00],\n",
       "             [-2.1207e+00,  2.5095e+00,  1.3552e+00,  ...,  1.3785e+00,\n",
       "               1.2368e+00, -1.9208e+00]],\n",
       "   \n",
       "            [[-2.8385e-01, -2.1299e+00, -9.7402e-01,  ...,  2.8745e-01,\n",
       "              -1.2020e+00, -1.0789e+00],\n",
       "             [-3.7253e-01, -1.7906e+00,  2.9703e+00,  ...,  5.9935e-01,\n",
       "               6.8937e-01,  2.1322e-01],\n",
       "             [ 3.6680e-01, -1.0511e+00, -9.0225e-01,  ...,  4.7325e+00,\n",
       "               2.8390e-01, -2.0006e-01],\n",
       "             ...,\n",
       "             [-1.0284e+00,  3.4711e-01,  1.5198e+00,  ...,  8.2965e-01,\n",
       "               1.5097e+00, -7.4293e-01],\n",
       "             [ 6.9028e-01, -1.8324e+00,  1.8472e+00,  ...,  3.3020e+00,\n",
       "               1.0432e+00, -6.1096e-01],\n",
       "             [-1.4244e-02,  1.2236e+00,  2.5508e+00,  ..., -3.3677e-01,\n",
       "               1.0382e-01, -8.6299e-01]]]], device='cuda:0',\n",
       "          grad_fn=<AddBackward0>),),\n",
       "  (tensor([[[[-2.1020e+00, -5.9885e-01, -2.1732e+00,  ..., -5.2462e+00,\n",
       "               2.5208e+00,  9.5441e-01],\n",
       "             [-5.4615e+00, -2.7698e+00,  1.9665e+00,  ..., -1.0029e+01,\n",
       "              -4.8340e+00,  1.9656e+00],\n",
       "             [ 1.6790e+00,  6.3978e+00,  6.5947e+00,  ...,  7.0570e+00,\n",
       "               9.3481e+00, -4.5388e+00],\n",
       "             ...,\n",
       "             [-2.8846e-01,  1.7937e+00,  1.2316e+01,  ...,  6.3185e+00,\n",
       "               3.1885e+00,  7.3870e-01],\n",
       "             [ 2.4915e-01,  5.1880e+00, -9.4093e+00,  ...,  8.0688e-01,\n",
       "               7.3527e+00, -2.8142e-01],\n",
       "             [-1.9055e+00, -2.1214e+00,  5.5841e+00,  ...,  2.0198e+00,\n",
       "              -5.3418e-01,  1.5478e+00]],\n",
       "   \n",
       "            [[ 1.2969e+00,  2.1528e+00,  6.0513e+00,  ...,  4.6488e+00,\n",
       "              -6.2522e-01,  2.6348e+00],\n",
       "             [ 4.3032e+00,  3.0763e+00,  2.4042e+00,  ...,  3.6487e+00,\n",
       "               1.4271e+00, -4.8222e+00],\n",
       "             [ 2.1501e+00, -5.2981e+00, -1.2772e-01,  ..., -1.6253e+00,\n",
       "              -8.7590e+00, -4.2527e+00],\n",
       "             ...,\n",
       "             [ 7.8728e+00, -2.6690e+00, -1.1936e+00,  ...,  3.4656e+00,\n",
       "              -5.1285e+00,  2.0001e+00],\n",
       "             [ 1.0283e+00,  5.7747e+00,  6.6418e+00,  ..., -2.2571e+00,\n",
       "              -3.3863e+00,  1.2484e+00],\n",
       "             [-9.8376e-01, -1.6221e+00, -3.8445e-01,  ..., -1.4458e+00,\n",
       "              -1.5450e+00,  3.1996e-01]],\n",
       "   \n",
       "            [[-1.3293e+00,  1.3614e+00, -9.0685e-01,  ..., -4.1211e+00,\n",
       "              -5.0159e+00, -3.1656e+00],\n",
       "             [ 1.4928e-01, -7.8108e-02,  6.6692e+00,  ..., -2.1163e+00,\n",
       "               2.2828e-02,  1.4426e+00],\n",
       "             [ 7.7194e-01,  1.8322e+00, -2.8346e+00,  ..., -9.7523e+00,\n",
       "               4.6454e+00, -7.7218e-01],\n",
       "             ...,\n",
       "             [ 1.0311e+01,  7.0634e+00, -1.4714e+00,  ..., -1.7717e+00,\n",
       "               5.1607e+00, -5.9081e-01],\n",
       "             [ 1.7134e+00, -1.8357e+00, -6.2369e+00,  ...,  1.7242e+00,\n",
       "               1.1824e+00,  1.0596e+00],\n",
       "             [-1.8183e+00, -6.4904e-01, -1.8103e+00,  ...,  1.3026e+00,\n",
       "               4.8306e+00, -1.0638e+00]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[-1.9544e+00, -1.2760e+00,  4.7687e-02,  ...,  3.4949e+00,\n",
       "              -1.9943e+00, -2.7522e+00],\n",
       "             [ 1.1053e+00, -3.1985e+00,  4.7873e+00,  ..., -3.1954e+00,\n",
       "              -4.2888e+00,  1.9458e+00],\n",
       "             [ 1.2538e-01,  6.3005e-01, -1.3401e+00,  ...,  5.9374e+00,\n",
       "               1.6038e+00,  3.0979e+00],\n",
       "             ...,\n",
       "             [-9.7325e-03, -4.8760e+00, -4.5642e+00,  ..., -4.7131e+00,\n",
       "              -2.5939e+00, -1.1245e+00],\n",
       "             [-3.4516e-01, -1.7548e+00, -2.4929e-01,  ..., -2.1682e+00,\n",
       "              -6.1546e+00, -1.6099e-01],\n",
       "             [ 1.6929e+00, -3.0305e+00, -3.4008e+00,  ...,  2.2218e+00,\n",
       "              -2.1324e+00,  2.3511e+00]],\n",
       "   \n",
       "            [[-2.8798e+00, -2.7883e+00, -4.0373e+00,  ..., -3.1272e-01,\n",
       "               1.0666e+00,  2.9210e+00],\n",
       "             [-2.3622e+00, -3.4447e+00, -5.5577e-01,  ..., -9.2318e+00,\n",
       "              -1.8673e-01, -9.5987e-01],\n",
       "             [ 8.7977e-01, -1.5637e+00,  5.3978e-01,  ..., -3.8140e+00,\n",
       "              -9.7147e+00, -6.6614e+00],\n",
       "             ...,\n",
       "             [ 3.3047e+00,  3.8687e-01, -3.1392e+00,  ..., -2.4436e+00,\n",
       "               4.0972e+00,  1.8716e+00],\n",
       "             [-7.6511e+00,  1.5073e+00,  6.7785e+00,  ..., -5.2940e+00,\n",
       "               2.8506e+00, -6.1455e+00],\n",
       "             [-7.1532e-01, -6.6455e+00,  2.3245e+00,  ...,  2.0714e+00,\n",
       "               2.0709e+00, -5.4356e-01]],\n",
       "   \n",
       "            [[-3.8081e-01,  3.3026e+00, -1.3528e+00,  ..., -4.9336e-01,\n",
       "              -1.2421e+00,  2.0172e+00],\n",
       "             [-3.7015e-01,  5.1906e+00,  3.7786e+00,  ..., -3.6873e+00,\n",
       "               3.2219e+00, -5.7120e+00],\n",
       "             [-1.6963e+00, -6.0794e+00, -1.0943e+01,  ..., -1.4974e+00,\n",
       "              -4.1507e+00,  2.5044e+00],\n",
       "             ...,\n",
       "             [-1.5626e+00, -1.7778e+00,  7.0646e-01,  ...,  6.9114e+00,\n",
       "               4.2576e+00,  3.7050e+00],\n",
       "             [ 3.7045e+00, -3.5276e+00,  8.6730e+00,  ..., -1.7780e+00,\n",
       "              -1.6705e+00,  3.0333e+00],\n",
       "             [ 2.7549e+00, -6.6547e-02, -1.6231e+00,  ...,  5.4457e-01,\n",
       "               1.0085e+00, -1.6369e+00]]],\n",
       "   \n",
       "   \n",
       "           [[[-2.2661e+00, -2.6153e+00, -2.9743e+00,  ..., -3.1282e+00,\n",
       "              -3.0030e+00, -3.3984e+00],\n",
       "             [-4.5984e+00, -3.6178e+00, -4.8614e+00,  ..., -3.8329e+00,\n",
       "              -3.8083e+00, -2.5465e+00],\n",
       "             [-3.4638e+00, -4.0803e+00, -4.1657e+00,  ..., -3.3807e+00,\n",
       "              -2.0952e+00, -3.4009e+00],\n",
       "             ...,\n",
       "             [-3.6550e+00,  4.0687e-01, -3.5988e-03,  ..., -4.2275e+00,\n",
       "              -2.6221e+00, -3.1753e+00],\n",
       "             [-3.5997e+00, -2.0310e+00, -3.5085e+00,  ..., -3.3226e+00,\n",
       "              -5.1253e+00, -3.2748e+00],\n",
       "             [-3.4661e+00, -1.9049e+00, -1.8326e+00,  ..., -1.9470e+00,\n",
       "              -7.9035e-01, -2.6987e+00]],\n",
       "   \n",
       "            [[ 2.7014e+00,  4.3747e+00,  2.3695e+00,  ...,  5.1454e-01,\n",
       "               2.0471e+00,  3.9914e+00],\n",
       "             [ 3.0403e+00,  1.5930e+00, -6.2197e-01,  ...,  1.3605e-01,\n",
       "               5.0741e-01,  2.5965e+00],\n",
       "             [ 3.1720e+00, -4.1818e-02,  3.1677e+00,  ..., -7.5230e-01,\n",
       "               1.3135e+00,  1.3278e+00],\n",
       "             ...,\n",
       "             [ 1.8003e+00,  1.4201e+00,  1.7003e+00,  ..., -5.2647e-01,\n",
       "               1.9229e+00, -3.3760e-01],\n",
       "             [ 9.6605e-01,  1.3618e+00, -7.4668e-01,  ...,  2.2265e+00,\n",
       "               1.8086e+00,  8.3019e-01],\n",
       "             [ 1.5219e+00,  1.5525e+00, -1.5907e+00,  ...,  1.6144e+00,\n",
       "               4.0126e-01, -1.0106e+00]],\n",
       "   \n",
       "            [[-1.3669e+00, -1.6569e+00, -2.1536e+00,  ..., -2.5419e+00,\n",
       "              -1.6276e+00, -8.4082e-01],\n",
       "             [-1.8461e+00, -9.6170e-02, -2.1797e+00,  ..., -6.9002e-01,\n",
       "              -1.6731e+00, -1.4799e+00],\n",
       "             [-7.8330e-01, -4.9411e+00, -1.8682e+00,  ..., -2.4972e-01,\n",
       "              -2.2489e+00, -1.2017e+00],\n",
       "             ...,\n",
       "             [-1.4976e+00, -3.0960e+00,  1.8096e+00,  ...,  9.3518e-01,\n",
       "               5.4494e-01, -1.7957e+00],\n",
       "             [-1.8543e+00, -1.1832e+00, -1.2872e+00,  ..., -8.1341e-01,\n",
       "              -3.0490e-01, -8.1304e-01],\n",
       "             [-1.6064e+00, -1.3859e+00, -2.4066e+00,  ..., -5.9483e-01,\n",
       "              -2.1842e+00, -3.5303e+00]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[-7.9464e-01, -1.6817e+00, -1.7570e+00,  ..., -7.0127e-01,\n",
       "              -2.0783e+00, -1.7687e+00],\n",
       "             [-5.5274e-01, -2.5992e-01,  6.2869e-01,  ...,  1.3014e+00,\n",
       "              -1.2274e+00, -1.4447e+00],\n",
       "             [ 6.3775e-01, -2.4403e+00, -1.5719e+00,  ..., -8.9245e-01,\n",
       "              -2.6094e+00, -5.8566e-01],\n",
       "             ...,\n",
       "             [-1.3880e+00, -4.2757e-01,  1.6663e+00,  ..., -1.3057e+00,\n",
       "               1.5961e+00, -3.6244e-01],\n",
       "             [-5.6551e-01,  7.1044e-01, -2.5876e+00,  ..., -3.9381e+00,\n",
       "              -4.7653e-02, -1.4372e+00],\n",
       "             [-7.8255e-01,  9.5835e-01,  3.8344e-01,  ..., -6.9852e-01,\n",
       "              -1.1459e+00, -1.3185e+00]],\n",
       "   \n",
       "            [[-3.3547e-01, -2.1268e+00,  4.4252e-01,  ..., -1.4564e+00,\n",
       "              -2.2571e+00, -2.0425e+00],\n",
       "             [-4.6669e-01, -3.6137e-01, -1.2042e-01,  ...,  2.0823e+00,\n",
       "              -1.0418e+00, -1.2641e+00],\n",
       "             [-1.7762e+00, -1.8418e+00, -1.1266e+00,  ..., -2.1348e+00,\n",
       "              -1.9717e-02, -1.1795e+00],\n",
       "             ...,\n",
       "             [-2.0805e+00, -3.2657e+00, -2.8038e+00,  ...,  1.3514e+00,\n",
       "              -7.4835e-01,  6.4227e-01],\n",
       "             [-2.5366e+00, -2.5826e-01, -7.5157e-02,  ..., -9.8813e-01,\n",
       "              -1.1215e+00, -2.4551e+00],\n",
       "             [-2.2502e+00, -1.1873e+00, -2.3211e-01,  ...,  2.6218e-01,\n",
       "              -1.3434e+00, -2.4832e+00]],\n",
       "   \n",
       "            [[ 1.4592e-01, -4.2950e-03,  1.4336e+00,  ..., -2.9163e+00,\n",
       "               9.5719e-02, -2.2380e+00],\n",
       "             [ 8.7995e-01, -5.4301e-01, -7.7844e-01,  ..., -7.1079e-02,\n",
       "              -1.3408e+00, -4.4489e+00],\n",
       "             [-4.9758e-02, -3.6315e+00,  9.8394e-01,  ..., -2.9455e-01,\n",
       "              -3.4860e+00, -4.0835e+00],\n",
       "             ...,\n",
       "             [ 8.7140e-01, -2.6954e+00,  1.2212e+00,  ..., -1.6415e+00,\n",
       "               1.4235e+00, -2.9639e+00],\n",
       "             [ 2.3280e+00,  1.2268e+00,  3.4143e-01,  ..., -6.9517e-01,\n",
       "              -2.3455e+00, -1.6998e+00],\n",
       "             [-1.6886e-01, -2.1429e+00, -2.9255e+00,  ...,  7.1181e-02,\n",
       "               6.5909e-01, -3.2734e+00]]]], device='cuda:0',\n",
       "          grad_fn=<AddBackward0>),),\n",
       "  (tensor([[[[ 1.2714e+00,  4.7323e-01, -2.0353e+00,  ...,  2.0315e-01,\n",
       "              -1.4970e-01, -1.0605e+00],\n",
       "             [ 4.8123e-01, -2.1071e-01, -2.8824e-01,  ...,  5.1598e-01,\n",
       "               1.8872e+00,  1.6238e-01],\n",
       "             [ 1.9040e+00, -1.0055e+00, -3.1055e-01,  ..., -1.4107e+00,\n",
       "              -1.5633e+00,  8.4548e-01],\n",
       "             ...,\n",
       "             [ 4.1758e+00,  6.5257e-01,  2.4533e+00,  ...,  9.3456e-02,\n",
       "              -1.9887e+00,  2.4263e+00],\n",
       "             [-1.2648e+00,  1.3273e-01,  6.0482e+00,  ..., -3.7269e-01,\n",
       "               3.5301e+00,  2.2836e+00],\n",
       "             [ 2.1483e+00, -4.7530e-01,  2.2584e+00,  ...,  2.7098e+00,\n",
       "               1.6149e+00,  1.3524e+00]],\n",
       "   \n",
       "            [[-1.2686e-02,  1.0093e+00, -9.5908e-01,  ..., -1.0259e-01,\n",
       "               6.0960e-01,  1.2557e+00],\n",
       "             [-4.0358e-01, -3.1428e+00, -2.5005e+00,  ...,  8.3307e-01,\n",
       "               9.6611e-01, -5.0938e-01],\n",
       "             [ 2.0402e+00,  1.3903e+00,  8.7457e-01,  ...,  5.6758e-01,\n",
       "               1.3611e+00,  1.1046e+00],\n",
       "             ...,\n",
       "             [ 6.3233e-01,  7.4133e-01, -1.2906e+00,  ..., -1.2633e+00,\n",
       "              -3.5513e+00, -1.4481e+00],\n",
       "             [-2.6354e-01,  1.6908e-01,  1.2644e-01,  ..., -1.9595e+00,\n",
       "               6.3319e-01,  1.1979e+00],\n",
       "             [-9.5121e-01, -1.4882e+00, -1.6315e+00,  ..., -1.3570e+00,\n",
       "               2.7027e+00,  1.2508e+00]],\n",
       "   \n",
       "            [[-2.4795e-01, -1.3779e-02,  7.0545e-02,  ..., -6.7533e-01,\n",
       "               1.0926e-01,  4.9345e-01],\n",
       "             [-3.0059e-01,  1.4346e+00,  2.7110e-01,  ..., -2.1426e-01,\n",
       "               1.1808e+00, -4.6732e-01],\n",
       "             [-9.1301e-01, -4.1491e+00, -1.8088e+00,  ..., -1.6556e+00,\n",
       "               7.0342e-01, -2.6262e+00],\n",
       "             ...,\n",
       "             [-6.8425e-01,  9.0971e-01,  4.7766e+00,  ...,  2.1449e-01,\n",
       "              -3.6222e+00,  1.8609e-04],\n",
       "             [-1.2354e-02,  3.4893e+00, -5.7639e+00,  ...,  2.2713e+00,\n",
       "               5.3822e-01,  1.0770e+00],\n",
       "             [-1.1403e+00,  4.1296e-01,  1.6356e+00,  ...,  6.2001e-01,\n",
       "              -1.3077e+00, -6.5567e-01]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[-8.6025e-01, -2.0545e+00, -2.2772e+00,  ...,  1.3685e-01,\n",
       "              -2.3245e+00, -1.1352e+00],\n",
       "             [-1.6081e+00, -1.6759e+00, -7.9690e-01,  ...,  1.6194e+00,\n",
       "              -1.7338e+00, -2.6813e-01],\n",
       "             [ 5.3164e-01,  2.5006e+00,  7.6617e-01,  ..., -1.3551e+00,\n",
       "              -5.4613e-01, -2.1158e+00],\n",
       "             ...,\n",
       "             [-1.4781e-02,  2.4490e+00,  5.6003e+00,  ..., -6.3241e-01,\n",
       "              -2.0265e+00,  3.1875e+00],\n",
       "             [-2.1788e+00,  5.8125e-01,  7.9802e-01,  ...,  2.4748e+00,\n",
       "               3.3166e+00,  2.9834e-01],\n",
       "             [ 3.9482e-01, -9.4019e-01, -2.0093e+00,  ..., -4.8722e-01,\n",
       "               1.6984e+00,  3.0745e-01]],\n",
       "   \n",
       "            [[ 1.7725e+00,  1.8749e+00,  3.9118e-01,  ..., -7.5505e-01,\n",
       "               2.1947e+00, -1.1429e+00],\n",
       "             [ 1.7123e+00,  9.7985e-02, -2.2722e+00,  ...,  2.1474e+00,\n",
       "               2.2105e+00,  1.1975e+00],\n",
       "             [ 4.4725e+00, -1.9964e+00,  1.1979e+00,  ...,  9.1244e-01,\n",
       "              -6.8301e-01,  5.8183e-01],\n",
       "             ...,\n",
       "             [ 1.3426e+00, -9.5045e-01,  8.5678e-01,  ...,  7.5555e+00,\n",
       "               6.1601e+00,  6.1722e-01],\n",
       "             [-2.3263e+00,  3.5272e-01, -3.6866e+00,  ...,  6.4762e-01,\n",
       "               2.1874e+00, -3.3379e-02],\n",
       "             [-6.3339e-01, -5.4037e-01,  1.9945e+00,  ...,  2.7911e-01,\n",
       "               1.2087e+00,  1.8035e+00]],\n",
       "   \n",
       "            [[ 1.0194e+00,  1.4556e+00, -2.4902e+00,  ...,  1.8174e+00,\n",
       "              -1.3367e+00,  2.0190e-01],\n",
       "             [ 5.9079e-01,  1.8211e+00,  5.0664e-01,  ..., -8.4246e-01,\n",
       "               2.5574e+00,  9.6433e-01],\n",
       "             [ 2.2509e-03,  1.0272e+00, -2.5131e+00,  ...,  3.6789e+00,\n",
       "              -2.4234e+00, -4.6123e-02],\n",
       "             ...,\n",
       "             [-2.1131e+00, -3.5424e+00, -2.8034e+00,  ..., -3.6301e+00,\n",
       "              -2.2326e+00, -8.5250e-01],\n",
       "             [-2.2901e+00,  2.3657e+00,  5.7040e-01,  ..., -4.9789e-01,\n",
       "              -7.8153e-01, -5.1692e-01],\n",
       "             [ 7.7960e-03, -2.7199e+00,  2.5404e-01,  ..., -3.0720e+00,\n",
       "               2.2469e-01, -2.3272e-01]]],\n",
       "   \n",
       "   \n",
       "           [[[-6.8444e-02,  3.3765e-01, -5.4153e-02,  ..., -3.0051e-01,\n",
       "               2.9445e-02,  1.0834e+00],\n",
       "             [ 1.0230e+00,  1.2583e+00,  1.7882e+00,  ...,  8.1295e-01,\n",
       "               1.3796e+00,  1.2141e+00],\n",
       "             [ 9.6063e-01,  8.3792e-01,  4.4059e-01,  ...,  9.2033e-01,\n",
       "               1.5389e+00,  1.5570e+00],\n",
       "             ...,\n",
       "             [ 2.5645e-01,  6.7392e-01,  6.1106e-01,  ..., -2.5896e-01,\n",
       "               1.6196e+00,  6.8551e-01],\n",
       "             [ 6.9706e-01,  7.4397e-01,  1.0574e+00,  ...,  4.4291e-01,\n",
       "               1.5536e+00,  1.3574e+00],\n",
       "             [ 1.4497e+00,  1.3113e+00,  1.3475e+00,  ...,  4.1391e-01,\n",
       "               7.7712e-01,  6.0354e-01]],\n",
       "   \n",
       "            [[ 2.1690e-02,  8.5943e-01, -1.0647e-01,  ...,  8.3847e-01,\n",
       "               3.8606e-01,  5.6693e-01],\n",
       "             [ 9.7601e-01,  8.5876e-01, -2.2918e-01,  ...,  9.0088e-01,\n",
       "               1.0813e+00,  7.5195e-01],\n",
       "             [ 4.4061e-01,  1.3913e+00, -2.0174e-01,  ..., -5.2766e-02,\n",
       "               9.5539e-01,  4.6910e-01],\n",
       "             ...,\n",
       "             [ 3.6405e-01,  1.8768e-01,  3.9183e-01,  ..., -1.2016e-02,\n",
       "               3.8585e-01,  1.4933e+00],\n",
       "             [ 6.2985e-01,  6.6104e-01,  3.5374e-01,  ..., -1.9444e-01,\n",
       "              -2.0713e-01,  6.7363e-01],\n",
       "             [ 6.0278e-01,  3.0687e-01, -9.5426e-01,  ...,  5.6438e-01,\n",
       "               3.9169e-01,  4.9007e-01]],\n",
       "   \n",
       "            [[-4.8383e-01, -9.4708e-01, -5.5432e-01,  ..., -8.3063e-01,\n",
       "              -4.0864e-01, -2.1611e-02],\n",
       "             [ 1.6716e-01,  2.8819e-01,  1.5370e+00,  ..., -2.6362e-01,\n",
       "               6.0799e-02,  9.7039e-01],\n",
       "             [-8.5728e-01, -5.2608e-01,  1.1393e+00,  ...,  8.3126e-01,\n",
       "               1.8055e-01,  6.3401e-01],\n",
       "             ...,\n",
       "             [ 3.3407e-01,  1.0581e-02,  1.1360e-01,  ...,  5.4396e-01,\n",
       "              -5.6379e-01,  2.8693e-01],\n",
       "             [-1.4314e-01,  2.8750e-01,  2.4230e-01,  ...,  4.4297e-02,\n",
       "               5.7167e-02,  6.9615e-02],\n",
       "             [-5.7166e-01, -5.9109e-01, -4.1008e-01,  ..., -9.9247e-01,\n",
       "              -1.0539e+00,  2.6892e-01]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[-1.4695e+00, -1.8713e+00, -1.5265e+00,  ..., -2.8912e+00,\n",
       "              -2.0240e+00, -1.6991e+00],\n",
       "             [-1.0153e+00, -1.3553e+00, -2.4564e+00,  ..., -2.3734e+00,\n",
       "              -2.3606e+00, -5.4701e-01],\n",
       "             [-1.2287e+00, -1.6316e+00, -5.6685e-01,  ..., -2.3543e+00,\n",
       "              -1.4672e+00, -1.4552e+00],\n",
       "             ...,\n",
       "             [-5.8912e-01, -1.5753e+00, -2.6264e+00,  ..., -1.8959e+00,\n",
       "              -2.4874e+00, -9.3754e-01],\n",
       "             [-8.9614e-01, -1.0723e+00, -1.2028e+00,  ..., -5.2825e-02,\n",
       "              -2.2786e+00, -1.2434e+00],\n",
       "             [ 2.1796e-02, -3.1445e-01, -3.2004e-01,  ..., -9.5977e-01,\n",
       "              -8.7963e-01, -3.9408e-01]],\n",
       "   \n",
       "            [[ 1.2523e+00,  6.1105e-01,  5.6491e-01,  ...,  5.7934e-01,\n",
       "               3.5902e-01,  5.6957e-01],\n",
       "             [ 5.0056e-01,  1.9998e-01,  9.2163e-01,  ...,  8.5833e-01,\n",
       "              -1.0084e-01,  6.2840e-01],\n",
       "             [ 1.1353e+00, -3.4522e-01,  1.1839e+00,  ...,  8.8226e-01,\n",
       "               7.4942e-01,  3.9968e-01],\n",
       "             ...,\n",
       "             [ 6.0998e-01,  4.6707e-01,  3.4150e-01,  ..., -4.4026e-01,\n",
       "               9.5647e-01,  6.4055e-01],\n",
       "             [ 3.3770e-01,  4.1266e-01,  5.4057e-01,  ...,  1.4283e-02,\n",
       "               1.9461e-01,  2.6853e-01],\n",
       "             [ 6.2547e-01, -8.1968e-01,  8.1255e-01,  ..., -1.9547e-01,\n",
       "              -8.3769e-02,  6.5133e-01]],\n",
       "   \n",
       "            [[-5.2173e-01, -2.5438e-01,  4.0754e-01,  ..., -1.0026e+00,\n",
       "              -1.3131e+00, -6.0732e-01],\n",
       "             [-1.3578e+00, -8.2466e-01,  9.5344e-01,  ..., -2.2363e-01,\n",
       "              -1.1627e+00,  2.7356e-01],\n",
       "             [-7.9185e-02, -3.2543e-01,  7.8972e-01,  ...,  7.2666e-01,\n",
       "              -3.6842e-01,  1.3739e+00],\n",
       "             ...,\n",
       "             [-7.1905e-01,  4.2277e-01,  1.0367e+00,  ...,  3.0800e-02,\n",
       "              -3.1296e-01,  2.1598e-03],\n",
       "             [-7.6309e-01,  2.8470e-01, -1.8272e-01,  ..., -4.5930e-01,\n",
       "               3.1324e-01,  1.3591e+00],\n",
       "             [-1.6972e-01,  4.0200e-02,  7.8492e-02,  ...,  5.0327e-04,\n",
       "               2.1018e-01,  1.0284e+00]]]], device='cuda:0',\n",
       "          grad_fn=<AddBackward0>),)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92928aac-b58f-4381-9a14-198ce30fc6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23601/4093688214.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# a[2][0].shape\n",
    "# a[5][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc168b3-d2bb-40f0-8c86-868aca0db046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = timm.create_model ('efficientnetv2_s',\n",
    "#                                           pretrained=False, \n",
    "#                                           drop_rate = 0.2, \n",
    "#                                           drop_path_rate = 0.1,\n",
    "#                                           num_classes=512\n",
    "#                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f63caa-b218-4839-a100-aed9710ba0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n , m in net.named_children():\n",
    "#     print(n)\n",
    "#     for n1 , m1 in m.named_children():\n",
    "#         print(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739ffb9-b1ce-4fb0-9927-ae87a6b84fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "# from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652768f5-aaed-435b-aa5c-059f43f59643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summary(net, (1, 3, 1024, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15016818-45ac-49d4-8791-c7156fd9e8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
